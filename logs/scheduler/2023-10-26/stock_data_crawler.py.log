[2023-10-26T08:05:53.456+0800] {processor.py:157} INFO - Started process (PID=3174) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T08:05:53.481+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T08:05:53.495+0800] {logging_mixin.py:151} INFO - [2023-10-26T08:05:53.487+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T08:05:54.348+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T08:05:54.364+0800] {logging_mixin.py:151} INFO - [2023-10-26T08:05:54.364+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T08:05:54.393+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.956 seconds
[2023-10-26T08:07:12.776+0800] {processor.py:157} INFO - Started process (PID=3193) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T08:07:12.778+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T08:07:12.779+0800] {logging_mixin.py:151} INFO - [2023-10-26T08:07:12.778+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T08:07:13.909+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T08:07:13.932+0800] {logging_mixin.py:151} INFO - [2023-10-26T08:07:13.932+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T08:07:13.961+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.189 seconds
[2023-10-26T08:23:57.604+0800] {processor.py:157} INFO - Started process (PID=3214) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T08:23:57.605+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T08:23:57.606+0800] {logging_mixin.py:151} INFO - [2023-10-26T08:23:57.606+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T08:23:58.132+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T08:23:58.144+0800] {logging_mixin.py:151} INFO - [2023-10-26T08:23:58.144+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T08:23:58.163+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.563 seconds
[2023-10-26T08:25:17.439+0800] {processor.py:157} INFO - Started process (PID=3233) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T08:25:17.442+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T08:25:17.443+0800] {logging_mixin.py:151} INFO - [2023-10-26T08:25:17.442+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T08:25:17.989+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T08:25:18.000+0800] {logging_mixin.py:151} INFO - [2023-10-26T08:25:18.000+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T08:25:18.018+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.595 seconds
[2023-10-26T08:41:12.933+0800] {processor.py:157} INFO - Started process (PID=3252) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T08:41:12.936+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T08:41:12.939+0800] {logging_mixin.py:151} INFO - [2023-10-26T08:41:12.939+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T08:41:14.125+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T08:41:14.140+0800] {logging_mixin.py:151} INFO - [2023-10-26T08:41:14.139+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T08:41:14.178+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.264 seconds
[2023-10-26T08:42:57.382+0800] {processor.py:157} INFO - Started process (PID=3271) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T08:42:57.384+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T08:42:57.386+0800] {logging_mixin.py:151} INFO - [2023-10-26T08:42:57.385+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T08:42:57.998+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T08:42:58.010+0800] {logging_mixin.py:151} INFO - [2023-10-26T08:42:58.010+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T08:42:58.027+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.653 seconds
[2023-10-26T08:44:17.408+0800] {processor.py:157} INFO - Started process (PID=3290) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T08:44:17.411+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T08:44:17.413+0800] {logging_mixin.py:151} INFO - [2023-10-26T08:44:17.412+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T08:44:18.008+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T08:44:18.021+0800] {logging_mixin.py:151} INFO - [2023-10-26T08:44:18.020+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T08:44:18.037+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.636 seconds
[2023-10-26T09:05:30.895+0800] {processor.py:157} INFO - Started process (PID=3311) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T09:05:30.897+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T09:05:30.899+0800] {logging_mixin.py:151} INFO - [2023-10-26T09:05:30.898+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T09:05:31.808+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T09:05:31.822+0800] {logging_mixin.py:151} INFO - [2023-10-26T09:05:31.822+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T09:05:31.842+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.953 seconds
[2023-10-26T09:07:15.359+0800] {processor.py:157} INFO - Started process (PID=3330) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T09:07:15.366+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T09:07:15.373+0800] {logging_mixin.py:151} INFO - [2023-10-26T09:07:15.370+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T09:07:15.929+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T09:07:15.940+0800] {logging_mixin.py:151} INFO - [2023-10-26T09:07:15.940+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T09:07:15.959+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.608 seconds
[2023-10-26T09:24:33.687+0800] {processor.py:157} INFO - Started process (PID=3350) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T09:24:33.690+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T09:24:33.700+0800] {logging_mixin.py:151} INFO - [2023-10-26T09:24:33.700+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T09:24:35.115+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T09:24:35.137+0800] {logging_mixin.py:151} INFO - [2023-10-26T09:24:35.136+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T09:24:35.159+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.478 seconds
[2023-10-26T09:26:18.293+0800] {processor.py:157} INFO - Started process (PID=3369) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T09:26:18.302+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T09:26:18.306+0800] {logging_mixin.py:151} INFO - [2023-10-26T09:26:18.304+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T09:26:18.830+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T09:26:18.840+0800] {logging_mixin.py:151} INFO - [2023-10-26T09:26:18.840+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T09:26:18.857+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.570 seconds
[2023-10-26T09:27:38.148+0800] {processor.py:157} INFO - Started process (PID=3388) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T09:27:38.151+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T09:27:38.152+0800] {logging_mixin.py:151} INFO - [2023-10-26T09:27:38.151+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T09:27:38.823+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T09:27:38.834+0800] {logging_mixin.py:151} INFO - [2023-10-26T09:27:38.834+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T09:27:38.857+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.716 seconds
[2023-10-26T09:29:22.925+0800] {processor.py:157} INFO - Started process (PID=3409) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T09:29:22.927+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T09:29:22.927+0800] {logging_mixin.py:151} INFO - [2023-10-26T09:29:22.927+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T09:29:23.588+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T09:29:23.601+0800] {logging_mixin.py:151} INFO - [2023-10-26T09:29:23.600+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T09:29:23.620+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.699 seconds
[2023-10-26T09:34:21.519+0800] {processor.py:157} INFO - Started process (PID=3428) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T09:34:21.523+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T09:34:21.524+0800] {logging_mixin.py:151} INFO - [2023-10-26T09:34:21.524+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T09:34:22.106+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T09:34:22.117+0800] {logging_mixin.py:151} INFO - [2023-10-26T09:34:22.117+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T09:34:22.134+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.634 seconds
[2023-10-26T09:40:35.949+0800] {processor.py:157} INFO - Started process (PID=3447) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T09:40:35.955+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T09:40:35.959+0800] {logging_mixin.py:151} INFO - [2023-10-26T09:40:35.958+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T09:40:37.409+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T09:40:37.437+0800] {logging_mixin.py:151} INFO - [2023-10-26T09:40:37.437+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T09:40:37.512+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.608 seconds
[2023-10-26T09:49:39.989+0800] {processor.py:157} INFO - Started process (PID=3468) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T09:49:39.997+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T09:49:39.999+0800] {logging_mixin.py:151} INFO - [2023-10-26T09:49:39.999+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T09:49:41.005+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T09:49:41.021+0800] {logging_mixin.py:151} INFO - [2023-10-26T09:49:41.020+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T09:49:41.039+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.059 seconds
[2023-10-26T09:58:44.134+0800] {processor.py:157} INFO - Started process (PID=3487) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T09:58:44.135+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T09:58:44.136+0800] {logging_mixin.py:151} INFO - [2023-10-26T09:58:44.136+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T09:58:45.156+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T09:58:45.186+0800] {logging_mixin.py:151} INFO - [2023-10-26T09:58:45.186+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T09:58:45.256+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.129 seconds
[2023-10-26T10:04:46.776+0800] {processor.py:157} INFO - Started process (PID=3508) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T10:04:46.785+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T10:04:46.788+0800] {logging_mixin.py:151} INFO - [2023-10-26T10:04:46.788+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T10:04:47.751+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T10:04:47.762+0800] {logging_mixin.py:151} INFO - [2023-10-26T10:04:47.761+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T10:04:47.779+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.018 seconds
[2023-10-26T10:13:56.429+0800] {processor.py:157} INFO - Started process (PID=3527) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T10:13:56.436+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T10:13:56.444+0800] {logging_mixin.py:151} INFO - [2023-10-26T10:13:56.443+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T10:13:57.441+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T10:13:57.455+0800] {logging_mixin.py:151} INFO - [2023-10-26T10:13:57.454+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T10:13:57.475+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.050 seconds
[2023-10-26T10:22:57.935+0800] {processor.py:157} INFO - Started process (PID=3545) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T10:22:57.945+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T10:22:57.953+0800] {logging_mixin.py:151} INFO - [2023-10-26T10:22:57.953+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T10:22:58.851+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T10:22:58.863+0800] {logging_mixin.py:151} INFO - [2023-10-26T10:22:58.863+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T10:22:58.888+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.973 seconds
[2023-10-26T10:29:10.563+0800] {processor.py:157} INFO - Started process (PID=3564) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T10:29:10.565+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T10:29:10.566+0800] {logging_mixin.py:151} INFO - [2023-10-26T10:29:10.566+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T10:29:11.211+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T10:29:11.224+0800] {logging_mixin.py:151} INFO - [2023-10-26T10:29:11.223+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T10:29:11.255+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.698 seconds
[2023-10-26T10:38:09.212+0800] {processor.py:157} INFO - Started process (PID=3583) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T10:38:09.215+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T10:38:09.216+0800] {logging_mixin.py:151} INFO - [2023-10-26T10:38:09.216+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T10:38:10.323+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T10:38:10.335+0800] {logging_mixin.py:151} INFO - [2023-10-26T10:38:10.335+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T10:38:10.353+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.150 seconds
[2023-10-26T10:47:15.183+0800] {processor.py:157} INFO - Started process (PID=3604) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T10:47:15.184+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T10:47:15.185+0800] {logging_mixin.py:151} INFO - [2023-10-26T10:47:15.185+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T10:47:16.273+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T10:47:16.336+0800] {logging_mixin.py:151} INFO - [2023-10-26T10:47:16.335+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T10:47:16.415+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.240 seconds
[2023-10-26T11:06:25.942+0800] {processor.py:157} INFO - Started process (PID=3623) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T11:06:25.951+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T11:06:25.955+0800] {logging_mixin.py:151} INFO - [2023-10-26T11:06:25.954+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T11:06:27.010+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T11:06:27.029+0800] {logging_mixin.py:151} INFO - [2023-10-26T11:06:27.029+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T11:06:27.052+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.130 seconds
[2023-10-26T11:08:09.755+0800] {processor.py:157} INFO - Started process (PID=3642) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T11:08:09.758+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T11:08:09.759+0800] {logging_mixin.py:151} INFO - [2023-10-26T11:08:09.758+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T11:08:10.317+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T11:08:10.329+0800] {logging_mixin.py:151} INFO - [2023-10-26T11:08:10.328+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T11:08:10.352+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.604 seconds
[2023-10-26T11:09:29.657+0800] {processor.py:157} INFO - Started process (PID=3661) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T11:09:29.660+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T11:09:29.665+0800] {logging_mixin.py:151} INFO - [2023-10-26T11:09:29.663+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T11:09:30.209+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T11:09:30.221+0800] {logging_mixin.py:151} INFO - [2023-10-26T11:09:30.221+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T11:09:30.239+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.587 seconds
[2023-10-26T11:27:58.779+0800] {processor.py:157} INFO - Started process (PID=3682) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T11:27:58.782+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T11:27:58.784+0800] {logging_mixin.py:151} INFO - [2023-10-26T11:27:58.783+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T11:28:00.368+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T11:28:00.392+0800] {logging_mixin.py:151} INFO - [2023-10-26T11:28:00.392+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T11:28:00.423+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.663 seconds
[2023-10-26T11:29:43.588+0800] {processor.py:157} INFO - Started process (PID=3701) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T11:29:43.591+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T11:29:43.595+0800] {logging_mixin.py:151} INFO - [2023-10-26T11:29:43.594+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T11:29:44.142+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T11:29:44.155+0800] {logging_mixin.py:151} INFO - [2023-10-26T11:29:44.155+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T11:29:44.175+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.595 seconds
[2023-10-26T11:31:27.420+0800] {processor.py:157} INFO - Started process (PID=3720) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T11:31:27.422+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T11:31:27.424+0800] {logging_mixin.py:151} INFO - [2023-10-26T11:31:27.424+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T11:31:28.552+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T11:31:28.587+0800] {logging_mixin.py:151} INFO - [2023-10-26T11:31:28.587+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T11:31:28.614+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.200 seconds
[2023-10-26T11:48:12.189+0800] {processor.py:157} INFO - Started process (PID=3739) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T11:48:12.192+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T11:48:12.193+0800] {logging_mixin.py:151} INFO - [2023-10-26T11:48:12.192+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T11:48:12.889+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T11:48:12.925+0800] {logging_mixin.py:151} INFO - [2023-10-26T11:48:12.925+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T11:48:12.994+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.818 seconds
[2023-10-26T11:49:07.165+0800] {processor.py:157} INFO - Started process (PID=3758) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T11:49:07.172+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T11:49:07.176+0800] {logging_mixin.py:151} INFO - [2023-10-26T11:49:07.175+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T11:49:07.704+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T11:49:07.719+0800] {logging_mixin.py:151} INFO - [2023-10-26T11:49:07.719+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T11:49:07.739+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.581 seconds
[2023-10-26T12:07:41.304+0800] {processor.py:157} INFO - Started process (PID=3777) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T12:07:41.308+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T12:07:41.314+0800] {logging_mixin.py:151} INFO - [2023-10-26T12:07:41.312+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T12:07:42.272+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T12:07:42.297+0800] {logging_mixin.py:151} INFO - [2023-10-26T12:07:42.297+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T12:07:42.368+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.071 seconds
[2023-10-26T12:09:01.779+0800] {processor.py:157} INFO - Started process (PID=3798) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T12:09:01.781+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T12:09:01.783+0800] {logging_mixin.py:151} INFO - [2023-10-26T12:09:01.782+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T12:09:02.969+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T12:09:02.986+0800] {logging_mixin.py:151} INFO - [2023-10-26T12:09:02.986+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T12:09:03.008+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.234 seconds
[2023-10-26T12:11:11.523+0800] {processor.py:157} INFO - Started process (PID=3817) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T12:11:11.527+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T12:11:11.528+0800] {logging_mixin.py:151} INFO - [2023-10-26T12:11:11.527+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T12:11:12.418+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T12:11:12.430+0800] {logging_mixin.py:151} INFO - [2023-10-26T12:11:12.430+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T12:11:12.450+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.949 seconds
[2023-10-26T12:30:01.670+0800] {processor.py:157} INFO - Started process (PID=3836) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T12:30:01.672+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T12:30:01.673+0800] {logging_mixin.py:151} INFO - [2023-10-26T12:30:01.672+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T12:30:02.842+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T12:30:02.908+0800] {logging_mixin.py:151} INFO - [2023-10-26T12:30:02.906+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T12:30:02.989+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.324 seconds
[2023-10-26T12:31:21.221+0800] {processor.py:157} INFO - Started process (PID=3855) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T12:31:21.224+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T12:31:21.227+0800] {logging_mixin.py:151} INFO - [2023-10-26T12:31:21.226+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T12:31:21.998+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T12:31:22.011+0800] {logging_mixin.py:151} INFO - [2023-10-26T12:31:22.011+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T12:31:22.045+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.830 seconds
[2023-10-26T12:33:06.175+0800] {processor.py:157} INFO - Started process (PID=3876) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T12:33:06.177+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T12:33:06.178+0800] {logging_mixin.py:151} INFO - [2023-10-26T12:33:06.178+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T12:33:06.721+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T12:33:06.733+0800] {logging_mixin.py:151} INFO - [2023-10-26T12:33:06.733+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T12:33:06.750+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.581 seconds
[2023-10-26T12:51:06.119+0800] {processor.py:157} INFO - Started process (PID=3895) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T12:51:06.128+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T12:51:06.134+0800] {logging_mixin.py:151} INFO - [2023-10-26T12:51:06.133+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T12:51:07.174+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T12:51:07.192+0800] {logging_mixin.py:151} INFO - [2023-10-26T12:51:07.191+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T12:51:07.220+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.114 seconds
[2023-10-26T13:08:46.195+0800] {processor.py:157} INFO - Started process (PID=3914) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T13:08:46.197+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T13:08:46.198+0800] {logging_mixin.py:151} INFO - [2023-10-26T13:08:46.198+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T13:08:47.096+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T13:08:47.142+0800] {logging_mixin.py:151} INFO - [2023-10-26T13:08:47.141+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T13:08:47.205+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.016 seconds
[2023-10-26T13:10:31.018+0800] {processor.py:157} INFO - Started process (PID=3935) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T13:10:31.021+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T13:10:31.022+0800] {logging_mixin.py:151} INFO - [2023-10-26T13:10:31.022+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T13:10:31.593+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T13:10:31.604+0800] {logging_mixin.py:151} INFO - [2023-10-26T13:10:31.604+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T13:10:31.622+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.611 seconds
[2023-10-26T13:26:26.062+0800] {processor.py:157} INFO - Started process (PID=3954) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T13:26:26.067+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T13:26:26.069+0800] {logging_mixin.py:151} INFO - [2023-10-26T13:26:26.068+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T13:26:27.109+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T13:26:27.122+0800] {logging_mixin.py:151} INFO - [2023-10-26T13:26:27.122+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T13:26:27.142+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.095 seconds
[2023-10-26T13:27:45.457+0800] {processor.py:157} INFO - Started process (PID=3974) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T13:27:45.461+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T13:27:45.466+0800] {logging_mixin.py:151} INFO - [2023-10-26T13:27:45.464+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T13:27:46.034+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T13:27:46.045+0800] {logging_mixin.py:151} INFO - [2023-10-26T13:27:46.045+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T13:27:46.061+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.611 seconds
[2023-10-26T13:44:20.679+0800] {processor.py:157} INFO - Started process (PID=3993) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T13:44:20.687+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T13:44:20.692+0800] {logging_mixin.py:151} INFO - [2023-10-26T13:44:20.690+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T13:44:21.766+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T13:44:21.780+0800] {logging_mixin.py:151} INFO - [2023-10-26T13:44:21.780+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T13:44:21.805+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.154 seconds
[2023-10-26T13:45:16.062+0800] {processor.py:157} INFO - Started process (PID=4012) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T13:45:16.067+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T13:45:16.068+0800] {logging_mixin.py:151} INFO - [2023-10-26T13:45:16.068+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T13:45:16.620+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T13:45:16.631+0800] {logging_mixin.py:151} INFO - [2023-10-26T13:45:16.631+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T13:45:16.649+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.597 seconds
[2023-10-26T13:54:15.221+0800] {processor.py:157} INFO - Started process (PID=4031) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T13:54:15.229+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T13:54:15.231+0800] {logging_mixin.py:151} INFO - [2023-10-26T13:54:15.231+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T13:54:16.259+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T13:54:16.288+0800] {logging_mixin.py:151} INFO - [2023-10-26T13:54:16.287+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T13:54:16.310+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.107 seconds
[2023-10-26T14:10:34.606+0800] {processor.py:157} INFO - Started process (PID=4052) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T14:10:34.608+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T14:10:34.610+0800] {logging_mixin.py:151} INFO - [2023-10-26T14:10:34.609+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T14:10:35.559+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T14:10:35.571+0800] {logging_mixin.py:151} INFO - [2023-10-26T14:10:35.570+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T14:10:35.664+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.066 seconds
[2023-10-26T14:11:53.952+0800] {processor.py:157} INFO - Started process (PID=4071) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T14:11:53.955+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T14:11:53.956+0800] {logging_mixin.py:151} INFO - [2023-10-26T14:11:53.956+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T14:11:54.514+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T14:11:54.526+0800] {logging_mixin.py:151} INFO - [2023-10-26T14:11:54.526+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T14:11:54.546+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.600 seconds
[2023-10-26T14:28:13.844+0800] {processor.py:157} INFO - Started process (PID=4090) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T14:28:13.846+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T14:28:13.847+0800] {logging_mixin.py:151} INFO - [2023-10-26T14:28:13.847+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T14:28:14.391+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T14:28:14.402+0800] {logging_mixin.py:151} INFO - [2023-10-26T14:28:14.402+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T14:28:14.418+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.585 seconds
[2023-10-26T14:44:59.547+0800] {processor.py:157} INFO - Started process (PID=4109) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T14:44:59.553+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T14:44:59.555+0800] {logging_mixin.py:151} INFO - [2023-10-26T14:44:59.554+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T14:45:00.683+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T14:45:00.696+0800] {logging_mixin.py:151} INFO - [2023-10-26T14:45:00.695+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T14:45:00.715+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.188 seconds
[2023-10-26T14:54:32.773+0800] {processor.py:157} INFO - Started process (PID=4130) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T14:54:32.782+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T14:54:32.790+0800] {logging_mixin.py:151} INFO - [2023-10-26T14:54:32.788+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T14:54:33.880+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T14:54:33.895+0800] {logging_mixin.py:151} INFO - [2023-10-26T14:54:33.895+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T14:54:33.930+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.169 seconds
[2023-10-26T15:10:52.635+0800] {processor.py:157} INFO - Started process (PID=4149) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T15:10:52.641+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T15:10:52.646+0800] {logging_mixin.py:151} INFO - [2023-10-26T15:10:52.644+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T15:10:53.715+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T15:10:53.753+0800] {logging_mixin.py:151} INFO - [2023-10-26T15:10:53.752+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T15:10:53.818+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.192 seconds
[2023-10-26T15:11:24.067+0800] {processor.py:157} INFO - Started process (PID=4168) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T15:11:24.069+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T15:11:24.071+0800] {logging_mixin.py:151} INFO - [2023-10-26T15:11:24.070+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T15:11:25.180+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T15:11:25.194+0800] {logging_mixin.py:151} INFO - [2023-10-26T15:11:25.194+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T15:11:25.227+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.166 seconds
[2023-10-26T15:16:41.259+0800] {processor.py:157} INFO - Started process (PID=4188) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T15:16:41.272+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T15:16:41.275+0800] {logging_mixin.py:151} INFO - [2023-10-26T15:16:41.274+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T15:16:42.616+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T15:16:42.631+0800] {logging_mixin.py:151} INFO - [2023-10-26T15:16:42.630+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T15:16:42.651+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.409 seconds
[2023-10-26T16:26:07.823+0800] {processor.py:157} INFO - Started process (PID=4207) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:26:07.825+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T16:26:07.826+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:26:07.826+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:26:08.574+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:26:08.628+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:26:08.626+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T16:26:08.694+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.876 seconds
[2023-10-26T16:30:38.440+0800] {processor.py:157} INFO - Started process (PID=4226) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:30:38.442+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T16:30:38.445+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:30:38.443+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:30:39.512+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:30:39.573+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:30:39.572+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T16:30:39.714+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.280 seconds
[2023-10-26T16:31:44.218+0800] {processor.py:157} INFO - Started process (PID=4247) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:31:44.223+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T16:31:44.224+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:31:44.224+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:31:45.164+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:31:45.180+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:31:45.180+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T16:31:45.210+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.002 seconds
[2023-10-26T16:32:15.847+0800] {processor.py:157} INFO - Started process (PID=4266) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:32:15.850+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T16:32:15.851+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:32:15.850+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:32:16.547+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:32:16.569+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:32:16.568+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T16:32:16.622+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.784 seconds
[2023-10-26T16:32:46.925+0800] {processor.py:157} INFO - Started process (PID=4285) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:32:46.928+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T16:32:46.929+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:32:46.929+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:32:47.658+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:32:47.679+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:32:47.678+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T16:32:47.705+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.785 seconds
[2023-10-26T16:33:18.514+0800] {processor.py:157} INFO - Started process (PID=4304) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:33:18.526+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T16:33:18.538+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:33:18.530+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:33:19.615+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:33:19.675+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:33:19.675+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T16:33:19.850+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.348 seconds
[2023-10-26T16:33:50.303+0800] {processor.py:157} INFO - Started process (PID=4327) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:33:50.313+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T16:33:50.321+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:33:50.320+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:33:51.886+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:33:51.919+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:33:51.919+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T16:33:52.038+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.758 seconds
[2023-10-26T16:34:22.344+0800] {processor.py:157} INFO - Started process (PID=4342) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:34:22.347+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T16:34:22.351+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:34:22.349+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:34:23.084+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:34:23.096+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:34:23.096+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T16:34:23.118+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.782 seconds
[2023-10-26T16:34:53.698+0800] {processor.py:157} INFO - Started process (PID=4361) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:34:53.701+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T16:34:53.704+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:34:53.703+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:34:55.136+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:34:55.155+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:34:55.155+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T16:34:55.185+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.507 seconds
[2023-10-26T16:35:25.651+0800] {processor.py:157} INFO - Started process (PID=4380) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:35:25.653+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T16:35:25.654+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:35:25.654+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:35:27.002+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:35:27.044+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:35:27.044+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T16:35:27.064+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:35:27.064+0800] {dag.py:3722} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T16:35:27.085+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.443 seconds
[2023-10-26T16:35:57.286+0800] {processor.py:157} INFO - Started process (PID=4399) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:35:57.288+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T16:35:57.289+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:35:57.289+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:35:57.880+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:35:57.892+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:35:57.892+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T16:35:57.903+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:35:57.903+0800] {dag.py:3722} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T16:35:57.917+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.638 seconds
[2023-10-26T16:36:28.326+0800] {processor.py:157} INFO - Started process (PID=4418) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:36:28.329+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T16:36:28.330+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:36:28.330+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:36:28.948+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:36:28.963+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:36:28.963+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T16:36:28.982+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:36:28.981+0800] {dag.py:3722} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T16:36:28.993+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.690 seconds
[2023-10-26T16:36:59.345+0800] {processor.py:157} INFO - Started process (PID=4437) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:36:59.349+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T16:36:59.353+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:36:59.352+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:36:59.919+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:36:59.934+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:36:59.934+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T16:36:59.946+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:36:59.945+0800] {dag.py:3722} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T16:36:59.955+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.617 seconds
[2023-10-26T16:37:30.345+0800] {processor.py:157} INFO - Started process (PID=4456) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:37:30.351+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T16:37:30.351+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:37:30.351+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:37:30.922+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:37:30.933+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:37:30.933+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T16:37:30.954+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.617 seconds
[2023-10-26T16:38:01.469+0800] {processor.py:157} INFO - Started process (PID=4475) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:38:01.476+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T16:38:01.478+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:38:01.477+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:38:02.382+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:38:02.397+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:38:02.397+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T16:38:02.424+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.971 seconds
[2023-10-26T16:38:32.857+0800] {processor.py:157} INFO - Started process (PID=4494) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:38:32.863+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T16:38:32.867+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:38:32.865+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:38:33.755+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:38:33.790+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:38:33.790+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T16:38:33.820+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.970 seconds
[2023-10-26T16:39:04.089+0800] {processor.py:157} INFO - Started process (PID=4513) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:39:04.093+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T16:39:04.096+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:39:04.095+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:39:04.765+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:39:04.784+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:39:04.784+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T16:39:04.808+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.725 seconds
[2023-10-26T16:39:35.415+0800] {processor.py:157} INFO - Started process (PID=4531) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:39:35.422+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T16:39:35.423+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:39:35.423+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:39:36.640+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:39:36.667+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:39:36.666+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T16:39:36.707+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.298 seconds
[2023-10-26T16:40:07.240+0800] {processor.py:157} INFO - Started process (PID=4549) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:40:07.247+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T16:40:07.251+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:40:07.249+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:40:07.993+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:40:08.007+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:40:08.007+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T16:40:08.027+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.793 seconds
[2023-10-26T16:40:38.412+0800] {processor.py:157} INFO - Started process (PID=4568) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:40:38.416+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T16:40:38.419+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:40:38.419+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:40:39.270+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:40:39.283+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:40:39.283+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T16:40:39.310+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.904 seconds
[2023-10-26T16:41:09.703+0800] {processor.py:157} INFO - Started process (PID=4587) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:41:09.707+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T16:41:09.709+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:41:09.709+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:41:10.285+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:41:10.297+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:41:10.297+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T16:41:10.321+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.630 seconds
[2023-10-26T16:41:40.914+0800] {processor.py:157} INFO - Started process (PID=4606) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:41:40.920+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T16:41:40.921+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:41:40.921+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:41:41.811+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:41:41.845+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:41:41.845+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T16:41:41.871+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.974 seconds
[2023-10-26T16:42:12.302+0800] {processor.py:157} INFO - Started process (PID=4632) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:42:12.307+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T16:42:12.308+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:42:12.308+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:42:13.115+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:42:13.128+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:42:13.128+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T16:42:13.148+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.857 seconds
[2023-10-26T16:42:43.580+0800] {processor.py:157} INFO - Started process (PID=4651) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:42:43.583+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T16:42:43.584+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:42:43.584+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:42:44.935+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:42:45.000+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:42:45.000+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T16:42:45.033+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.462 seconds
[2023-10-26T16:43:15.224+0800] {processor.py:157} INFO - Started process (PID=4670) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:43:15.227+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T16:43:15.230+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:43:15.230+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:43:16.557+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:43:16.575+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:43:16.575+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T16:43:16.600+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.396 seconds
[2023-10-26T16:43:47.025+0800] {processor.py:157} INFO - Started process (PID=4689) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:43:47.028+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T16:43:47.032+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:43:47.032+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:43:47.697+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:43:47.721+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:43:47.721+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T16:43:47.745+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.742 seconds
[2023-10-26T16:44:18.582+0800] {processor.py:157} INFO - Started process (PID=4708) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:44:18.592+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T16:44:18.597+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:44:18.596+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:44:20.214+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:44:20.239+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:44:20.238+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T16:44:20.277+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.706 seconds
[2023-10-26T16:44:51.514+0800] {processor.py:157} INFO - Started process (PID=4727) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:44:52.194+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T16:44:52.253+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:44:52.249+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:44:56.161+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:44:56.195+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:44:56.194+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T16:44:56.300+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 4.919 seconds
[2023-10-26T16:45:26.667+0800] {processor.py:157} INFO - Started process (PID=4746) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:45:26.691+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T16:45:26.696+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:45:26.694+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:45:29.710+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:45:29.806+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:45:29.804+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T16:45:29.977+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 3.340 seconds
[2023-10-26T16:46:00.815+0800] {processor.py:157} INFO - Started process (PID=4769) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:46:00.825+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T16:46:00.827+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:46:00.827+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:46:03.036+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:46:03.073+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:46:03.072+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T16:46:03.122+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 2.321 seconds
[2023-10-26T16:46:33.600+0800] {processor.py:157} INFO - Started process (PID=4790) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:46:33.603+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T16:46:33.604+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:46:33.604+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:46:34.121+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:46:34.143+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:46:34.142+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T16:46:34.160+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:46:34.160+0800] {dag.py:3722} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T16:46:34.172+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.575 seconds
[2023-10-26T16:47:04.260+0800] {processor.py:157} INFO - Started process (PID=4807) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:47:04.265+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T16:47:04.266+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:47:04.265+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:47:05.449+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:47:05.504+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:47:05.503+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T16:47:05.549+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:47:05.549+0800] {dag.py:3722} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T16:47:05.586+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.330 seconds
[2023-10-26T16:47:36.014+0800] {processor.py:157} INFO - Started process (PID=4828) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:47:36.017+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T16:47:36.018+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:47:36.018+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:47:36.983+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:47:37.018+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:47:37.017+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T16:47:37.053+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:47:37.052+0800] {dag.py:3722} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T16:47:37.067+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.057 seconds
[2023-10-26T16:48:07.196+0800] {processor.py:157} INFO - Started process (PID=4846) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:48:07.200+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T16:48:07.202+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:48:07.201+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:48:07.515+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:48:07.528+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:48:07.528+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T16:48:07.539+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:48:07.539+0800] {dag.py:3722} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T16:48:07.548+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.355 seconds
[2023-10-26T16:48:37.739+0800] {processor.py:157} INFO - Started process (PID=4859) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:48:37.743+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T16:48:37.747+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:48:37.746+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:48:39.125+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:48:39.150+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:48:39.150+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T16:48:39.166+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:48:39.166+0800] {dag.py:3722} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T16:48:39.177+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.446 seconds
[2023-10-26T16:49:09.778+0800] {processor.py:157} INFO - Started process (PID=4878) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:49:09.785+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T16:49:09.792+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:49:09.791+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:49:10.436+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:49:10.450+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:49:10.450+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T16:49:10.471+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:49:10.470+0800] {dag.py:3722} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T16:49:10.480+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.714 seconds
[2023-10-26T16:49:40.952+0800] {processor.py:157} INFO - Started process (PID=4897) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:49:40.962+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T16:49:40.963+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:49:40.963+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:49:41.593+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:49:41.606+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:49:41.606+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T16:49:41.616+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:49:41.616+0800] {dag.py:3722} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T16:49:41.626+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.691 seconds
[2023-10-26T16:50:12.346+0800] {processor.py:157} INFO - Started process (PID=4916) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:50:12.353+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T16:50:12.357+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:50:12.357+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:50:12.957+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:50:12.968+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:50:12.967+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T16:50:12.978+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:50:12.978+0800] {dag.py:3722} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T16:50:12.989+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.653 seconds
[2023-10-26T16:50:43.445+0800] {processor.py:157} INFO - Started process (PID=4938) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:50:43.453+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T16:50:43.458+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:50:43.455+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:50:44.404+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:50:44.418+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:50:44.417+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T16:50:44.431+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:50:44.431+0800] {dag.py:3722} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T16:50:44.441+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.996 seconds
[2023-10-26T16:51:15.010+0800] {processor.py:157} INFO - Started process (PID=4963) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:51:15.020+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T16:51:15.021+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:51:15.020+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:51:15.687+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:51:15.701+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:51:15.701+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T16:51:15.721+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:51:15.721+0800] {dag.py:3722} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T16:51:15.739+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.746 seconds
[2023-10-26T16:51:46.168+0800] {processor.py:157} INFO - Started process (PID=4988) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:51:46.175+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T16:51:46.176+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:51:46.175+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:51:47.222+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:51:47.237+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:51:47.237+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T16:51:47.256+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:51:47.256+0800] {dag.py:3722} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T16:51:47.268+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.107 seconds
[2023-10-26T16:52:17.817+0800] {processor.py:157} INFO - Started process (PID=5007) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:52:17.823+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T16:52:17.826+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:52:17.825+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:52:18.374+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:52:18.385+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:52:18.385+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T16:52:18.398+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:52:18.398+0800] {dag.py:3722} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T16:52:18.407+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.607 seconds
[2023-10-26T16:52:48.801+0800] {processor.py:157} INFO - Started process (PID=5026) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:52:48.805+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T16:52:48.806+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:52:48.806+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:52:49.995+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:52:50.013+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:52:50.013+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T16:52:50.029+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:52:50.029+0800] {dag.py:3722} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T16:52:50.042+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.249 seconds
[2023-10-26T16:53:20.681+0800] {processor.py:157} INFO - Started process (PID=5046) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:53:20.686+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T16:53:20.688+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:53:20.687+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:53:21.661+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:53:21.678+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:53:21.677+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T16:53:21.701+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:53:21.701+0800] {dag.py:3722} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T16:53:21.715+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.046 seconds
[2023-10-26T16:53:52.219+0800] {processor.py:157} INFO - Started process (PID=5065) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:53:52.223+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T16:53:52.227+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:53:52.226+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:53:52.829+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:53:52.841+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:53:52.841+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T16:53:52.853+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:53:52.853+0800] {dag.py:3722} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T16:53:52.861+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.647 seconds
[2023-10-26T16:54:23.438+0800] {processor.py:157} INFO - Started process (PID=5087) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:54:23.480+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T16:54:23.489+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:54:23.487+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:54:24.651+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:54:24.675+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:54:24.674+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T16:54:24.693+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:54:24.692+0800] {dag.py:3722} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T16:54:24.705+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.294 seconds
[2023-10-26T16:54:55.386+0800] {processor.py:157} INFO - Started process (PID=5113) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:54:55.390+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T16:54:55.391+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:54:55.391+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:54:55.921+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:54:55.947+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:54:55.946+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T16:54:56.353+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:54:56.353+0800] {dag.py:3722} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T16:54:56.381+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.005 seconds
[2023-10-26T16:55:27.202+0800] {processor.py:157} INFO - Started process (PID=5141) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:55:27.207+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T16:55:27.209+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:55:27.209+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:55:27.925+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:55:27.947+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:55:27.946+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T16:55:27.965+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:55:27.965+0800] {dag.py:3722} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T16:55:27.978+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.795 seconds
[2023-10-26T16:55:58.232+0800] {processor.py:157} INFO - Started process (PID=5174) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:55:58.237+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T16:55:58.238+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:55:58.238+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:55:58.629+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:55:58.667+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:55:58.665+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T16:55:58.713+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:55:58.712+0800] {dag.py:3722} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T16:55:58.735+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.512 seconds
[2023-10-26T16:56:29.670+0800] {processor.py:157} INFO - Started process (PID=5193) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:56:29.674+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T16:56:29.675+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:56:29.674+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:56:30.170+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:56:30.193+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:56:30.192+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T16:56:30.598+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:56:30.598+0800] {dag.py:3722} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T16:56:30.610+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.948 seconds
[2023-10-26T16:57:01.003+0800] {processor.py:157} INFO - Started process (PID=5212) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:57:01.009+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T16:57:01.010+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:57:01.009+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:57:01.426+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:57:01.471+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:57:01.470+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T16:57:01.498+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:57:01.498+0800] {dag.py:3722} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T16:57:01.520+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.527 seconds
[2023-10-26T16:57:31.838+0800] {processor.py:157} INFO - Started process (PID=5231) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:57:31.844+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T16:57:31.849+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:57:31.846+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:57:32.231+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:57:32.249+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:57:32.248+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T16:57:32.264+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:57:32.264+0800] {dag.py:3722} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T16:57:32.275+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.442 seconds
[2023-10-26T16:58:03.122+0800] {processor.py:157} INFO - Started process (PID=5249) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:58:03.130+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T16:58:03.131+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:58:03.131+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:58:04.382+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:58:04.434+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:58:04.433+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T16:58:04.485+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:58:04.485+0800] {dag.py:3722} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T16:58:04.516+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.407 seconds
[2023-10-26T16:58:35.041+0800] {processor.py:157} INFO - Started process (PID=5268) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:58:35.045+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T16:58:35.046+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:58:35.045+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:58:35.458+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:58:35.479+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:58:35.479+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T16:58:36.951+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:58:36.951+0800] {dag.py:3722} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T16:58:36.981+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.949 seconds
[2023-10-26T16:59:07.393+0800] {processor.py:157} INFO - Started process (PID=5287) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:59:07.398+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T16:59:07.399+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:59:07.399+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:59:07.784+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:59:07.807+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:59:07.807+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T16:59:07.908+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:59:07.907+0800] {dag.py:3722} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T16:59:07.924+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.539 seconds
[2023-10-26T16:59:38.446+0800] {processor.py:157} INFO - Started process (PID=5306) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:59:38.451+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T16:59:38.453+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:59:38.452+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:59:38.996+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T16:59:39.020+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:59:39.019+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T16:59:39.045+0800] {logging_mixin.py:151} INFO - [2023-10-26T16:59:39.045+0800] {dag.py:3722} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T16:59:39.060+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.623 seconds
[2023-10-26T17:00:09.904+0800] {processor.py:157} INFO - Started process (PID=5325) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:00:09.925+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:00:09.928+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:00:09.926+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:00:10.892+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:00:10.933+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:00:10.932+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T17:00:10.975+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:00:10.975+0800] {dag.py:3722} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T17:00:10.999+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.107 seconds
[2023-10-26T17:00:41.644+0800] {processor.py:157} INFO - Started process (PID=5344) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:00:41.655+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:00:41.663+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:00:41.661+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:01:01.369+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:01:01.044+0800] {variable.py:281} ERROR - Unable to retrieve variable from secrets backend (MetastoreBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 644, in connect
    sock = socket.create_connection(
  File "/usr/local/lib/python3.8/socket.py", line 787, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "/usr/local/lib/python3.8/socket.py", line 918, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno -3] Temporary failure in name resolution

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 358, in __init__
    self.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 711, in connect
    raise exc
pymysql.err.OperationalError: (2003, "Can't connect to MySQL server on 'mysql' ([Errno -3] Temporary failure in name resolution)")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/variable.py", line 277, in get_variable_from_secrets
    var_val = secrets_backend.get_variable(key=key)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 77, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/metastore.py", line 69, in get_variable
    var_value = session.scalar(select(Variable).where(Variable.key == key).limit(1))
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/future/engine.py", line 406, in connect
    return super(Engine, self).connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 358, in __init__
    self.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 711, in connect
    raise exc
sqlalchemy.exc.OperationalError: (pymysql.err.OperationalError) (2003, "Can't connect to MySQL server on 'mysql' ([Errno -3] Temporary failure in name resolution)")
(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2023-10-26T17:01:01.534+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:01:01.387+0800] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 10, in <module>
    from functions.backend import db
  File "/opt/airflow/dags/functions/backend/db/__init__.py", line 3, in <module>
    r = router.Router()
  File "/opt/airflow/dags/functions/backend/db/router.py", line 45, in __init__
    clients.get_mysql_conn()
  File "/opt/airflow/dags/functions/backend/db/clients.py", line 6, in get_mysql_conn
    mysql_config = json.loads(Variable.get('mysql_config'))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/variable.py", line 140, in get
    raise KeyError(f"Variable {key} does not exist")
KeyError: 'Variable mysql_config does not exist'
[2023-10-26T17:01:01.578+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:01:12.007+0800] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 644, in connect
    sock = socket.create_connection(
  File "/usr/local/lib/python3.8/socket.py", line 787, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "/usr/local/lib/python3.8/socket.py", line 918, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno -3] Temporary failure in name resolution

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 358, in __init__
    self.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 711, in connect
    raise exc
pymysql.err.OperationalError: (2003, "Can't connect to MySQL server on 'mysql' ([Errno -3] Temporary failure in name resolution)")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 77, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 842, in process_file
    DagFileProcessor.update_import_errors(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 625, in update_import_errors
    existing_import_error_files = [x.filename for x in session.query(errors.ImportError.filename).all()]
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2773, in all
    return self._iter().all()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2916, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/future/engine.py", line 406, in connect
    return super(Engine, self).connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 358, in __init__
    self.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/pymysql/connections.py", line 711, in connect
    raise exc
sqlalchemy.exc.OperationalError: (pymysql.err.OperationalError) (2003, "Can't connect to MySQL server on 'mysql' ([Errno -3] Temporary failure in name resolution)")
(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2023-10-26T17:01:46.700+0800] {processor.py:157} INFO - Started process (PID=5363) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:01:46.706+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:01:46.708+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:01:46.707+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:01:48.348+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:01:48.399+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:01:48.398+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T17:01:48.435+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:01:48.435+0800] {dag.py:3722} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T17:01:48.475+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.786 seconds
[2023-10-26T17:02:19.431+0800] {processor.py:157} INFO - Started process (PID=5382) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:02:19.488+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:02:19.504+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:02:19.501+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:02:26.818+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:02:27.025+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:02:27.017+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T17:02:27.281+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:02:27.280+0800] {dag.py:3722} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T17:02:27.556+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 8.246 seconds
[2023-10-26T17:02:58.091+0800] {processor.py:157} INFO - Started process (PID=5401) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:02:58.095+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:02:58.097+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:02:58.096+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:02:58.657+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:02:58.684+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:02:58.683+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T17:02:58.706+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:02:58.706+0800] {dag.py:3722} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T17:02:59.921+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.836 seconds
[2023-10-26T17:03:30.224+0800] {processor.py:157} INFO - Started process (PID=5420) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:03:30.232+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:03:30.234+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:03:30.233+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:03:30.701+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:03:30.720+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:03:30.720+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T17:03:30.964+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:03:30.964+0800] {dag.py:3722} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T17:03:30.980+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.763 seconds
[2023-10-26T17:04:02.031+0800] {processor.py:157} INFO - Started process (PID=5439) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:04:02.037+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:04:02.038+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:04:02.038+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:04:02.668+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:04:02.726+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:04:02.726+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T17:04:02.777+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:04:02.776+0800] {dag.py:3722} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T17:04:02.826+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.801 seconds
[2023-10-26T17:04:33.077+0800] {processor.py:157} INFO - Started process (PID=5457) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:04:33.081+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:04:33.082+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:04:33.082+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:04:33.535+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:04:33.556+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:04:33.556+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T17:04:33.580+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:04:33.580+0800] {dag.py:3722} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T17:04:33.594+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.522 seconds
[2023-10-26T17:05:04.077+0800] {processor.py:157} INFO - Started process (PID=5476) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:05:04.082+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:05:04.084+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:05:04.084+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:05:04.586+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:05:04.609+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:05:04.609+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T17:05:04.670+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:05:04.670+0800] {dag.py:3722} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T17:05:05.125+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.072 seconds
[2023-10-26T17:05:35.527+0800] {processor.py:157} INFO - Started process (PID=5495) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:05:35.533+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:05:35.534+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:05:35.534+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:05:35.944+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:05:35.965+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:05:35.965+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T17:05:36.194+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:05:36.194+0800] {dag.py:3722} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T17:05:36.207+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.688 seconds
[2023-10-26T17:06:07.320+0800] {processor.py:157} INFO - Started process (PID=5514) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:06:07.329+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:06:07.331+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:06:07.331+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:06:07.793+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:06:07.810+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:06:07.810+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T17:06:08.106+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:06:08.106+0800] {dag.py:3722} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T17:06:08.119+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.806 seconds
[2023-10-26T17:06:38.650+0800] {processor.py:157} INFO - Started process (PID=5533) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:06:38.657+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:06:38.658+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:06:38.658+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:06:39.068+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:06:39.110+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:06:39.109+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T17:06:39.142+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:06:39.142+0800] {dag.py:3722} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T17:06:39.163+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.518 seconds
[2023-10-26T17:07:09.510+0800] {processor.py:157} INFO - Started process (PID=5559) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:07:09.520+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:07:09.523+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:07:09.521+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:07:09.896+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:07:09.912+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:07:09.911+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T17:07:09.938+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:07:09.938+0800] {dag.py:3722} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T17:07:10.193+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.687 seconds
[2023-10-26T17:07:40.776+0800] {processor.py:157} INFO - Started process (PID=5578) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:07:40.786+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:07:40.787+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:07:40.786+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:07:41.121+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:07:41.136+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:07:41.136+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T17:07:41.337+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:07:41.337+0800] {dag.py:3722} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T17:07:41.356+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.584 seconds
[2023-10-26T17:08:11.510+0800] {processor.py:157} INFO - Started process (PID=5597) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:08:11.514+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:08:11.515+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:08:11.515+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:08:12.037+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:08:12.355+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:08:12.354+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T17:08:12.376+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:08:12.375+0800] {dag.py:3722} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T17:08:12.392+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.888 seconds
[2023-10-26T17:08:43.177+0800] {processor.py:157} INFO - Started process (PID=5616) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:08:43.179+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:08:43.181+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:08:43.180+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:08:43.527+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:08:43.545+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:08:43.545+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T17:08:43.573+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:08:43.573+0800] {dag.py:3722} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T17:08:43.587+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.416 seconds
[2023-10-26T17:09:13.798+0800] {processor.py:157} INFO - Started process (PID=5635) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:09:13.823+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:09:13.832+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:09:13.830+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:09:14.461+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:09:14.503+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:09:14.502+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T17:09:14.540+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:09:14.540+0800] {dag.py:3722} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T17:09:14.827+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.046 seconds
[2023-10-26T17:09:45.343+0800] {processor.py:157} INFO - Started process (PID=5654) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:09:45.350+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:09:45.351+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:09:45.350+0800] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:09:45.688+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:09:45.704+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:09:45.703+0800] {dag.py:2941} INFO - Sync 1 DAGs
[2023-10-26T17:09:45.917+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:09:45.917+0800] {dag.py:3722} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T17:09:45.928+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.590 seconds
[2023-10-26T17:10:11.852+0800] {processor.py:157} INFO - Started process (PID=165) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:10:11.879+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:10:11.888+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:10:11.884+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:10:13.244+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:10:13.243+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 12, in <module>
    from functions.stock_app.stock_functions import send_message_to_slack
  File "/opt/airflow/dags/functions/stock_app/stock_functions.py", line 4, in <module>
    import gspread
ModuleNotFoundError: No module named 'gspread'
[2023-10-26T17:10:13.245+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:10:13.252+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.423 seconds
[2023-10-26T17:10:43.648+0800] {processor.py:157} INFO - Started process (PID=184) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:10:43.652+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:10:43.656+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:10:43.656+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:10:44.238+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:10:44.237+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 12, in <module>
    from functions.stock_app.stock_functions import send_message_to_slack
  File "/opt/airflow/dags/functions/stock_app/stock_functions.py", line 4, in <module>
    import gspread
ModuleNotFoundError: No module named 'gspread'
[2023-10-26T17:10:44.238+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:10:44.245+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.602 seconds
[2023-10-26T17:11:14.701+0800] {processor.py:157} INFO - Started process (PID=203) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:11:14.707+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:11:14.708+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:11:14.708+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:11:15.280+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:11:15.279+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 12, in <module>
    from functions.stock_app.stock_functions import send_message_to_slack
  File "/opt/airflow/dags/functions/stock_app/stock_functions.py", line 4, in <module>
    import gspread
ModuleNotFoundError: No module named 'gspread'
[2023-10-26T17:11:15.281+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:11:15.287+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.603 seconds
[2023-10-26T17:11:45.713+0800] {processor.py:157} INFO - Started process (PID=222) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:11:45.796+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:11:45.854+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:11:45.853+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:11:46.386+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:11:46.385+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 12, in <module>
    from functions.stock_app.stock_functions import send_message_to_slack
  File "/opt/airflow/dags/functions/stock_app/stock_functions.py", line 4, in <module>
    import gspread
ModuleNotFoundError: No module named 'gspread'
[2023-10-26T17:11:46.387+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:11:46.397+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.703 seconds
[2023-10-26T17:12:16.885+0800] {processor.py:157} INFO - Started process (PID=241) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:12:16.898+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:12:16.902+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:12:16.901+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:12:17.414+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:12:17.411+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 12, in <module>
    from functions.stock_app.stock_functions import send_message_to_slack
  File "/opt/airflow/dags/functions/stock_app/stock_functions.py", line 4, in <module>
    import gspread
ModuleNotFoundError: No module named 'gspread'
[2023-10-26T17:12:17.414+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:12:17.421+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.557 seconds
[2023-10-26T17:12:47.893+0800] {processor.py:157} INFO - Started process (PID=260) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:12:47.897+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:12:47.899+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:12:47.898+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:12:48.447+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:12:48.446+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 12, in <module>
    from functions.stock_app.stock_functions import send_message_to_slack
  File "/opt/airflow/dags/functions/stock_app/stock_functions.py", line 4, in <module>
    import gspread
ModuleNotFoundError: No module named 'gspread'
[2023-10-26T17:12:48.448+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:12:48.454+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.579 seconds
[2023-10-26T17:13:18.888+0800] {processor.py:157} INFO - Started process (PID=279) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:13:18.896+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:13:18.898+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:13:18.897+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:13:19.375+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:13:19.373+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 12, in <module>
    from functions.stock_app.stock_functions import send_message_to_slack
  File "/opt/airflow/dags/functions/stock_app/stock_functions.py", line 4, in <module>
    import gspread
ModuleNotFoundError: No module named 'gspread'
[2023-10-26T17:13:19.375+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:13:19.387+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.524 seconds
[2023-10-26T17:13:49.864+0800] {processor.py:157} INFO - Started process (PID=299) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:13:49.873+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:13:49.882+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:13:49.876+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:13:50.361+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:13:50.360+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 12, in <module>
    from functions.stock_app.stock_functions import send_message_to_slack
  File "/opt/airflow/dags/functions/stock_app/stock_functions.py", line 4, in <module>
    import gspread
ModuleNotFoundError: No module named 'gspread'
[2023-10-26T17:13:50.362+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:13:50.367+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.517 seconds
[2023-10-26T17:14:20.886+0800] {processor.py:157} INFO - Started process (PID=318) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:14:20.891+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:14:20.899+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:14:20.899+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:14:21.389+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:14:21.388+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 12, in <module>
    from functions.stock_app.stock_functions import send_message_to_slack
  File "/opt/airflow/dags/functions/stock_app/stock_functions.py", line 4, in <module>
    import gspread
ModuleNotFoundError: No module named 'gspread'
[2023-10-26T17:14:21.389+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:14:21.398+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.538 seconds
[2023-10-26T17:14:51.812+0800] {processor.py:157} INFO - Started process (PID=337) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:14:51.819+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:14:51.828+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:14:51.822+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:14:52.319+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:14:52.318+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 12, in <module>
    from functions.stock_app.stock_functions import send_message_to_slack
  File "/opt/airflow/dags/functions/stock_app/stock_functions.py", line 4, in <module>
    import gspread
ModuleNotFoundError: No module named 'gspread'
[2023-10-26T17:14:52.319+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:14:52.324+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.519 seconds
[2023-10-26T17:15:22.978+0800] {processor.py:157} INFO - Started process (PID=356) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:15:23.023+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:15:23.067+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:15:23.066+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:15:23.643+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:15:23.641+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 12, in <module>
    from functions.stock_app.stock_functions import send_message_to_slack
  File "/opt/airflow/dags/functions/stock_app/stock_functions.py", line 4, in <module>
    import gspread
ModuleNotFoundError: No module named 'gspread'
[2023-10-26T17:15:23.644+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:15:23.651+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.702 seconds
[2023-10-26T17:15:54.086+0800] {processor.py:157} INFO - Started process (PID=375) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:15:54.098+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:15:54.104+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:15:54.101+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:15:54.616+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:15:54.615+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 12, in <module>
    from functions.stock_app.stock_functions import send_message_to_slack
  File "/opt/airflow/dags/functions/stock_app/stock_functions.py", line 4, in <module>
    import gspread
ModuleNotFoundError: No module named 'gspread'
[2023-10-26T17:15:54.617+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:15:54.626+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.545 seconds
[2023-10-26T17:16:25.121+0800] {processor.py:157} INFO - Started process (PID=394) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:16:25.137+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:16:25.138+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:16:25.138+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:16:25.620+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:16:25.619+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 12, in <module>
    from functions.stock_app.stock_functions import send_message_to_slack
  File "/opt/airflow/dags/functions/stock_app/stock_functions.py", line 4, in <module>
    import gspread
ModuleNotFoundError: No module named 'gspread'
[2023-10-26T17:16:25.620+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:16:25.627+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.512 seconds
[2023-10-26T17:16:56.008+0800] {processor.py:157} INFO - Started process (PID=413) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:16:56.010+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:16:56.012+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:16:56.011+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:16:56.493+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:16:56.492+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 12, in <module>
    from functions.stock_app.stock_functions import send_message_to_slack
  File "/opt/airflow/dags/functions/stock_app/stock_functions.py", line 4, in <module>
    import gspread
ModuleNotFoundError: No module named 'gspread'
[2023-10-26T17:16:56.493+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:16:56.499+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.496 seconds
[2023-10-26T17:17:26.970+0800] {processor.py:157} INFO - Started process (PID=432) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:17:26.973+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:17:26.974+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:17:26.973+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:17:27.468+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:17:27.467+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 12, in <module>
    from functions.stock_app.stock_functions import send_message_to_slack
  File "/opt/airflow/dags/functions/stock_app/stock_functions.py", line 4, in <module>
    import gspread
ModuleNotFoundError: No module named 'gspread'
[2023-10-26T17:17:27.469+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:17:27.475+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.510 seconds
[2023-10-26T17:17:57.919+0800] {processor.py:157} INFO - Started process (PID=451) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:17:57.923+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:17:57.926+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:17:57.925+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:17:58.396+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:17:58.395+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 12, in <module>
    from functions.stock_app.stock_functions import send_message_to_slack
  File "/opt/airflow/dags/functions/stock_app/stock_functions.py", line 4, in <module>
    import gspread
ModuleNotFoundError: No module named 'gspread'
[2023-10-26T17:17:58.397+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:17:58.416+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.514 seconds
[2023-10-26T17:18:28.896+0800] {processor.py:157} INFO - Started process (PID=470) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:18:28.902+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:18:28.906+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:18:28.905+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:18:29.376+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:18:29.375+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 12, in <module>
    from functions.stock_app.stock_functions import send_message_to_slack
  File "/opt/airflow/dags/functions/stock_app/stock_functions.py", line 4, in <module>
    import gspread
ModuleNotFoundError: No module named 'gspread'
[2023-10-26T17:18:29.376+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:18:29.381+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.501 seconds
[2023-10-26T17:18:59.864+0800] {processor.py:157} INFO - Started process (PID=489) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:18:59.870+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:18:59.876+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:18:59.875+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:19:00.411+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:19:00.403+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 12, in <module>
    from functions.stock_app.stock_functions import send_message_to_slack
  File "/opt/airflow/dags/functions/stock_app/stock_functions.py", line 4, in <module>
    import gspread
ModuleNotFoundError: No module named 'gspread'
[2023-10-26T17:19:00.412+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:19:00.430+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.573 seconds
[2023-10-26T17:19:30.810+0800] {processor.py:157} INFO - Started process (PID=508) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:19:30.813+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:19:30.814+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:19:30.814+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:19:31.312+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:19:31.310+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 12, in <module>
    from functions.stock_app.stock_functions import send_message_to_slack
  File "/opt/airflow/dags/functions/stock_app/stock_functions.py", line 4, in <module>
    import gspread
ModuleNotFoundError: No module named 'gspread'
[2023-10-26T17:19:31.312+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:19:31.319+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.516 seconds
[2023-10-26T17:20:01.843+0800] {processor.py:157} INFO - Started process (PID=527) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:20:01.849+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:20:01.851+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:20:01.851+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:20:02.366+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:20:02.365+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 12, in <module>
    from functions.stock_app.stock_functions import send_message_to_slack
  File "/opt/airflow/dags/functions/stock_app/stock_functions.py", line 4, in <module>
    import gspread
ModuleNotFoundError: No module named 'gspread'
[2023-10-26T17:20:02.366+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:20:02.371+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.534 seconds
[2023-10-26T17:20:32.830+0800] {processor.py:157} INFO - Started process (PID=547) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:20:32.834+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:20:32.836+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:20:32.836+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:20:33.286+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:20:33.285+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 12, in <module>
    from functions.stock_app.stock_functions import send_message_to_slack
  File "/opt/airflow/dags/functions/stock_app/stock_functions.py", line 4, in <module>
    import gspread
ModuleNotFoundError: No module named 'gspread'
[2023-10-26T17:20:33.286+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:20:33.296+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.470 seconds
[2023-10-26T17:21:03.816+0800] {processor.py:157} INFO - Started process (PID=567) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:21:03.818+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:21:03.822+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:21:03.821+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:21:04.282+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:21:04.281+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 12, in <module>
    from functions.stock_app.stock_functions import send_message_to_slack
  File "/opt/airflow/dags/functions/stock_app/stock_functions.py", line 4, in <module>
    import gspread
ModuleNotFoundError: No module named 'gspread'
[2023-10-26T17:21:04.282+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:21:04.289+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.477 seconds
[2023-10-26T17:21:34.761+0800] {processor.py:157} INFO - Started process (PID=587) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:21:34.766+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:21:34.767+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:21:34.767+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:21:35.234+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:21:35.233+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 12, in <module>
    from functions.stock_app.stock_functions import send_message_to_slack
  File "/opt/airflow/dags/functions/stock_app/stock_functions.py", line 4, in <module>
    import gspread
ModuleNotFoundError: No module named 'gspread'
[2023-10-26T17:21:35.235+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:21:35.240+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.486 seconds
[2023-10-26T17:22:05.677+0800] {processor.py:157} INFO - Started process (PID=606) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:22:05.681+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:22:05.682+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:22:05.682+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:22:06.208+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:22:06.206+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 12, in <module>
    from functions.stock_app.stock_functions import send_message_to_slack
  File "/opt/airflow/dags/functions/stock_app/stock_functions.py", line 4, in <module>
    import gspread
ModuleNotFoundError: No module named 'gspread'
[2023-10-26T17:22:06.208+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:22:06.213+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.544 seconds
[2023-10-26T17:22:36.630+0800] {processor.py:157} INFO - Started process (PID=632) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:22:36.641+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:22:36.646+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:22:36.645+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:22:37.095+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:22:37.094+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 12, in <module>
    from functions.stock_app.stock_functions import send_message_to_slack
  File "/opt/airflow/dags/functions/stock_app/stock_functions.py", line 4, in <module>
    import gspread
ModuleNotFoundError: No module named 'gspread'
[2023-10-26T17:22:37.096+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:22:37.101+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.477 seconds
[2023-10-26T17:23:07.556+0800] {processor.py:157} INFO - Started process (PID=651) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:23:07.563+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:23:07.568+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:23:07.567+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:23:08.259+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:23:08.256+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 12, in <module>
    from functions.stock_app.stock_functions import send_message_to_slack
  File "/opt/airflow/dags/functions/stock_app/stock_functions.py", line 4, in <module>
    import gspread
ModuleNotFoundError: No module named 'gspread'
[2023-10-26T17:23:08.260+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:23:08.283+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.731 seconds
[2023-10-26T17:23:38.675+0800] {processor.py:157} INFO - Started process (PID=671) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:23:38.682+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:23:38.689+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:23:38.688+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:23:39.391+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:23:39.390+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 12, in <module>
    from functions.stock_app.stock_functions import send_message_to_slack
  File "/opt/airflow/dags/functions/stock_app/stock_functions.py", line 4, in <module>
    import gspread
ModuleNotFoundError: No module named 'gspread'
[2023-10-26T17:23:39.392+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:23:39.397+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.728 seconds
[2023-10-26T17:24:09.883+0800] {processor.py:157} INFO - Started process (PID=689) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:24:09.891+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:24:09.896+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:24:09.895+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:24:10.394+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:24:10.392+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 12, in <module>
    from functions.stock_app.stock_functions import send_message_to_slack
  File "/opt/airflow/dags/functions/stock_app/stock_functions.py", line 4, in <module>
    import gspread
ModuleNotFoundError: No module named 'gspread'
[2023-10-26T17:24:10.394+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:24:10.401+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.524 seconds
[2023-10-26T17:24:40.893+0800] {processor.py:157} INFO - Started process (PID=708) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:24:40.899+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:24:40.904+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:24:40.903+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:24:41.402+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:24:41.401+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 12, in <module>
    from functions.stock_app.stock_functions import send_message_to_slack
  File "/opt/airflow/dags/functions/stock_app/stock_functions.py", line 4, in <module>
    import gspread
ModuleNotFoundError: No module named 'gspread'
[2023-10-26T17:24:41.403+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:24:41.410+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.523 seconds
[2023-10-26T17:25:11.898+0800] {processor.py:157} INFO - Started process (PID=727) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:25:11.907+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:25:11.909+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:25:11.908+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:25:12.386+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:25:12.385+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 12, in <module>
    from functions.stock_app.stock_functions import send_message_to_slack
  File "/opt/airflow/dags/functions/stock_app/stock_functions.py", line 4, in <module>
    import gspread
ModuleNotFoundError: No module named 'gspread'
[2023-10-26T17:25:12.386+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:25:12.392+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.509 seconds
[2023-10-26T17:25:42.895+0800] {processor.py:157} INFO - Started process (PID=746) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:25:42.905+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:25:42.909+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:25:42.909+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:25:43.388+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:25:43.387+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 12, in <module>
    from functions.stock_app.stock_functions import send_message_to_slack
  File "/opt/airflow/dags/functions/stock_app/stock_functions.py", line 4, in <module>
    import gspread
ModuleNotFoundError: No module named 'gspread'
[2023-10-26T17:25:43.389+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:25:43.394+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.503 seconds
[2023-10-26T17:26:13.969+0800] {processor.py:157} INFO - Started process (PID=766) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:26:13.978+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:26:13.982+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:26:13.981+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:26:14.654+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:26:14.652+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 12, in <module>
    from functions.stock_app.stock_functions import send_message_to_slack
  File "/opt/airflow/dags/functions/stock_app/stock_functions.py", line 4, in <module>
    import gspread
ModuleNotFoundError: No module named 'gspread'
[2023-10-26T17:26:14.655+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:26:14.661+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.698 seconds
[2023-10-26T17:26:45.139+0800] {processor.py:157} INFO - Started process (PID=785) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:26:45.151+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:26:45.153+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:26:45.152+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:26:45.611+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:26:45.610+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 12, in <module>
    from functions.stock_app.stock_functions import send_message_to_slack
  File "/opt/airflow/dags/functions/stock_app/stock_functions.py", line 4, in <module>
    import gspread
ModuleNotFoundError: No module named 'gspread'
[2023-10-26T17:26:45.612+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:26:45.617+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.490 seconds
[2023-10-26T17:27:16.060+0800] {processor.py:157} INFO - Started process (PID=804) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:27:16.065+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:27:16.066+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:27:16.065+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:27:16.580+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:27:16.579+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 12, in <module>
    from functions.stock_app.stock_functions import send_message_to_slack
  File "/opt/airflow/dags/functions/stock_app/stock_functions.py", line 4, in <module>
    import gspread
ModuleNotFoundError: No module named 'gspread'
[2023-10-26T17:27:16.581+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:27:16.591+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.549 seconds
[2023-10-26T17:27:47.056+0800] {processor.py:157} INFO - Started process (PID=824) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:27:47.063+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:27:47.068+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:27:47.067+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:27:47.567+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:27:47.566+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 12, in <module>
    from functions.stock_app.stock_functions import send_message_to_slack
  File "/opt/airflow/dags/functions/stock_app/stock_functions.py", line 4, in <module>
    import gspread
ModuleNotFoundError: No module named 'gspread'
[2023-10-26T17:27:47.568+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:27:47.573+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.521 seconds
[2023-10-26T17:28:17.999+0800] {processor.py:157} INFO - Started process (PID=843) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:28:18.004+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:28:18.008+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:28:18.007+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:28:18.503+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:28:18.501+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 12, in <module>
    from functions.stock_app.stock_functions import send_message_to_slack
  File "/opt/airflow/dags/functions/stock_app/stock_functions.py", line 4, in <module>
    import gspread
ModuleNotFoundError: No module named 'gspread'
[2023-10-26T17:28:18.503+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:28:18.509+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.516 seconds
[2023-10-26T17:28:48.894+0800] {processor.py:157} INFO - Started process (PID=862) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:28:48.901+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:28:48.903+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:28:48.902+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:28:50.151+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:28:50.149+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 12, in <module>
    from functions.stock_app.stock_functions import send_message_to_slack
  File "/opt/airflow/dags/functions/stock_app/stock_functions.py", line 4, in <module>
    import gspread
ModuleNotFoundError: No module named 'gspread'
[2023-10-26T17:28:50.152+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:28:50.162+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.282 seconds
[2023-10-26T17:29:20.527+0800] {processor.py:157} INFO - Started process (PID=881) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:29:20.531+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:29:20.535+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:29:20.534+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:29:21.165+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:29:21.164+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 12, in <module>
    from functions.stock_app.stock_functions import send_message_to_slack
  File "/opt/airflow/dags/functions/stock_app/stock_functions.py", line 4, in <module>
    import gspread
ModuleNotFoundError: No module named 'gspread'
[2023-10-26T17:29:21.165+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:29:21.171+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.651 seconds
[2023-10-26T17:29:51.561+0800] {processor.py:157} INFO - Started process (PID=900) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:29:51.564+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:29:51.566+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:29:51.565+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:29:52.083+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:29:52.081+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 12, in <module>
    from functions.stock_app.stock_functions import send_message_to_slack
  File "/opt/airflow/dags/functions/stock_app/stock_functions.py", line 4, in <module>
    import gspread
ModuleNotFoundError: No module named 'gspread'
[2023-10-26T17:29:52.083+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:29:52.089+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.534 seconds
[2023-10-26T17:30:22.718+0800] {processor.py:157} INFO - Started process (PID=919) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:30:22.721+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:30:22.723+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:30:22.723+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:30:23.226+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:30:23.225+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 12, in <module>
    from functions.stock_app.stock_functions import send_message_to_slack
  File "/opt/airflow/dags/functions/stock_app/stock_functions.py", line 4, in <module>
    import gspread
ModuleNotFoundError: No module named 'gspread'
[2023-10-26T17:30:23.226+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:30:23.231+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.519 seconds
[2023-10-26T17:30:53.742+0800] {processor.py:157} INFO - Started process (PID=938) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:30:53.745+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:30:53.750+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:30:53.749+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:30:54.272+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:30:54.270+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 12, in <module>
    from functions.stock_app.stock_functions import send_message_to_slack
  File "/opt/airflow/dags/functions/stock_app/stock_functions.py", line 4, in <module>
    import gspread
ModuleNotFoundError: No module named 'gspread'
[2023-10-26T17:30:54.274+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:30:54.289+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.553 seconds
[2023-10-26T17:31:24.773+0800] {processor.py:157} INFO - Started process (PID=957) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:31:24.778+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:31:24.788+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:31:24.786+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:31:25.298+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:31:25.296+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 12, in <module>
    from functions.stock_app.stock_functions import send_message_to_slack
  File "/opt/airflow/dags/functions/stock_app/stock_functions.py", line 4, in <module>
    import gspread
ModuleNotFoundError: No module named 'gspread'
[2023-10-26T17:31:25.298+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:31:25.304+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.539 seconds
[2023-10-26T17:31:55.779+0800] {processor.py:157} INFO - Started process (PID=976) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:31:55.788+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:31:55.789+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:31:55.789+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:31:56.279+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:31:56.278+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 12, in <module>
    from functions.stock_app.stock_functions import send_message_to_slack
  File "/opt/airflow/dags/functions/stock_app/stock_functions.py", line 4, in <module>
    import gspread
ModuleNotFoundError: No module named 'gspread'
[2023-10-26T17:31:56.279+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:31:56.285+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.511 seconds
[2023-10-26T17:32:26.770+0800] {processor.py:157} INFO - Started process (PID=995) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:32:26.779+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:32:26.781+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:32:26.780+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:32:27.274+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:32:27.273+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 12, in <module>
    from functions.stock_app.stock_functions import send_message_to_slack
  File "/opt/airflow/dags/functions/stock_app/stock_functions.py", line 4, in <module>
    import gspread
ModuleNotFoundError: No module named 'gspread'
[2023-10-26T17:32:27.275+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:32:27.279+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.518 seconds
[2023-10-26T17:32:57.796+0800] {processor.py:157} INFO - Started process (PID=1014) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:32:57.802+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:32:57.806+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:32:57.805+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:32:58.309+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:32:58.308+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 12, in <module>
    from functions.stock_app.stock_functions import send_message_to_slack
  File "/opt/airflow/dags/functions/stock_app/stock_functions.py", line 4, in <module>
    import gspread
ModuleNotFoundError: No module named 'gspread'
[2023-10-26T17:32:58.310+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:32:58.316+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.526 seconds
[2023-10-26T17:33:28.786+0800] {processor.py:157} INFO - Started process (PID=1033) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:33:28.802+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:33:28.803+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:33:28.803+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:33:29.303+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:33:29.302+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 12, in <module>
    from functions.stock_app.stock_functions import send_message_to_slack
  File "/opt/airflow/dags/functions/stock_app/stock_functions.py", line 4, in <module>
    import gspread
ModuleNotFoundError: No module named 'gspread'
[2023-10-26T17:33:29.303+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:33:29.313+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.546 seconds
[2023-10-26T17:33:59.783+0800] {processor.py:157} INFO - Started process (PID=1051) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:33:59.794+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:33:59.795+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:33:59.795+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:34:00.321+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:34:00.320+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 12, in <module>
    from functions.stock_app.stock_functions import send_message_to_slack
  File "/opt/airflow/dags/functions/stock_app/stock_functions.py", line 4, in <module>
    import gspread
ModuleNotFoundError: No module named 'gspread'
[2023-10-26T17:34:00.322+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:34:00.327+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.556 seconds
[2023-10-26T17:34:31.239+0800] {processor.py:157} INFO - Started process (PID=1070) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:34:31.247+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:34:31.252+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:34:31.250+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:34:32.556+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:34:32.532+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 12, in <module>
    from functions.stock_app.stock_functions import send_message_to_slack
  File "/opt/airflow/dags/functions/stock_app/stock_functions.py", line 4, in <module>
    import gspread
ModuleNotFoundError: No module named 'gspread'
[2023-10-26T17:34:32.562+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:34:32.576+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.348 seconds
[2023-10-26T17:35:03.335+0800] {processor.py:157} INFO - Started process (PID=1089) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:35:03.338+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:35:03.347+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:35:03.346+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:35:04.047+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:35:04.046+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 12, in <module>
    from functions.stock_app.stock_functions import send_message_to_slack
  File "/opt/airflow/dags/functions/stock_app/stock_functions.py", line 4, in <module>
    import gspread
ModuleNotFoundError: No module named 'gspread'
[2023-10-26T17:35:04.048+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:35:04.056+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.741 seconds
[2023-10-26T17:35:34.860+0800] {processor.py:157} INFO - Started process (PID=1108) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:35:34.884+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:35:34.893+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:35:34.888+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:35:35.909+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:35:35.905+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 12, in <module>
    from functions.stock_app.stock_functions import send_message_to_slack
  File "/opt/airflow/dags/functions/stock_app/stock_functions.py", line 4, in <module>
    import gspread
ModuleNotFoundError: No module named 'gspread'
[2023-10-26T17:35:35.911+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:35:35.922+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.073 seconds
[2023-10-26T17:36:06.413+0800] {processor.py:157} INFO - Started process (PID=1127) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:36:06.419+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:36:06.424+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:36:06.423+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:36:07.896+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:36:07.889+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 12, in <module>
    from functions.stock_app.stock_functions import send_message_to_slack
  File "/opt/airflow/dags/functions/stock_app/stock_functions.py", line 4, in <module>
    import gspread
ModuleNotFoundError: No module named 'gspread'
[2023-10-26T17:36:07.897+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:36:07.906+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.501 seconds
[2023-10-26T17:36:38.507+0800] {processor.py:157} INFO - Started process (PID=1146) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:36:38.588+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:36:38.599+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:36:38.595+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:36:40.930+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:36:40.924+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 12, in <module>
    from functions.stock_app.stock_functions import send_message_to_slack
  File "/opt/airflow/dags/functions/stock_app/stock_functions.py", line 4, in <module>
    import gspread
ModuleNotFoundError: No module named 'gspread'
[2023-10-26T17:36:40.932+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:36:40.942+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 2.509 seconds
[2023-10-26T17:37:11.476+0800] {processor.py:157} INFO - Started process (PID=1172) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:37:11.525+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:37:11.529+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:37:11.527+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:37:13.158+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:37:13.154+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 12, in <module>
    from functions.stock_app.stock_functions import send_message_to_slack
  File "/opt/airflow/dags/functions/stock_app/stock_functions.py", line 4, in <module>
    import gspread
ModuleNotFoundError: No module named 'gspread'
[2023-10-26T17:37:13.159+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:37:13.179+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.716 seconds
[2023-10-26T17:37:43.836+0800] {processor.py:157} INFO - Started process (PID=1191) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:37:43.839+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:37:43.841+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:37:43.840+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:37:44.319+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:37:44.318+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 12, in <module>
    from functions.stock_app.stock_functions import send_message_to_slack
  File "/opt/airflow/dags/functions/stock_app/stock_functions.py", line 4, in <module>
    import gspread
ModuleNotFoundError: No module named 'gspread'
[2023-10-26T17:37:44.319+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:37:44.325+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.496 seconds
[2023-10-26T17:38:14.715+0800] {processor.py:157} INFO - Started process (PID=1210) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:38:14.720+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:38:14.726+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:38:14.725+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:38:15.224+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:38:15.222+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 12, in <module>
    from functions.stock_app.stock_functions import send_message_to_slack
  File "/opt/airflow/dags/functions/stock_app/stock_functions.py", line 4, in <module>
    import gspread
ModuleNotFoundError: No module named 'gspread'
[2023-10-26T17:38:15.224+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:38:15.233+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.524 seconds
[2023-10-26T17:38:33.757+0800] {processor.py:157} INFO - Started process (PID=165) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:38:33.759+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:38:33.763+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:38:33.761+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:38:35.333+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:38:35.329+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 12, in <module>
    from functions.stock_app.stock_functions import send_message_to_slack
  File "/opt/airflow/dags/functions/stock_app/stock_functions.py", line 5, in <module>
    from oauth2client.service_account import ServiceAccountCredentials
ModuleNotFoundError: No module named 'oauth2client'
[2023-10-26T17:38:35.334+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:38:35.358+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.606 seconds
[2023-10-26T17:39:05.731+0800] {processor.py:157} INFO - Started process (PID=184) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:39:05.736+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:39:05.738+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:39:05.737+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:39:06.427+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:39:06.422+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 12, in <module>
    from functions.stock_app.stock_functions import send_message_to_slack
  File "/opt/airflow/dags/functions/stock_app/stock_functions.py", line 5, in <module>
    from oauth2client.service_account import ServiceAccountCredentials
ModuleNotFoundError: No module named 'oauth2client'
[2023-10-26T17:39:06.427+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:39:06.435+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.712 seconds
[2023-10-26T17:39:37.077+0800] {processor.py:157} INFO - Started process (PID=203) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:39:37.080+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:39:37.082+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:39:37.081+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:39:37.955+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:39:37.952+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 12, in <module>
    from functions.stock_app.stock_functions import send_message_to_slack
  File "/opt/airflow/dags/functions/stock_app/stock_functions.py", line 5, in <module>
    from oauth2client.service_account import ServiceAccountCredentials
ModuleNotFoundError: No module named 'oauth2client'
[2023-10-26T17:39:37.955+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:39:37.968+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.897 seconds
[2023-10-26T17:40:09.062+0800] {processor.py:157} INFO - Started process (PID=221) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:40:09.080+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:40:09.083+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:40:09.081+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:40:10.527+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:40:10.525+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 12, in <module>
    from functions.stock_app.stock_functions import send_message_to_slack
  File "/opt/airflow/dags/functions/stock_app/stock_functions.py", line 5, in <module>
    from oauth2client.service_account import ServiceAccountCredentials
ModuleNotFoundError: No module named 'oauth2client'
[2023-10-26T17:40:10.528+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:40:10.543+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.489 seconds
[2023-10-26T17:40:40.846+0800] {processor.py:157} INFO - Started process (PID=240) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:40:40.865+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:40:40.875+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:40:40.872+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:40:42.957+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:40:42.954+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 12, in <module>
    from functions.stock_app.stock_functions import send_message_to_slack
  File "/opt/airflow/dags/functions/stock_app/stock_functions.py", line 5, in <module>
    from oauth2client.service_account import ServiceAccountCredentials
ModuleNotFoundError: No module named 'oauth2client'
[2023-10-26T17:40:42.958+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:40:42.984+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 2.157 seconds
[2023-10-26T17:41:34.967+0800] {processor.py:157} INFO - Started process (PID=165) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:41:34.985+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:41:34.991+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:41:34.989+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:41:37.745+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:41:37.965+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:41:37.964+0800] {security.py:708} INFO - Not syncing DAG-level permissions for DAG 'DAG:stock_data_crawler' as access control is unset.
[2023-10-26T17:41:37.966+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:41:37.966+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T17:41:38.016+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:41:38.016+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T17:41:38.074+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 3.116 seconds
[2023-10-26T17:42:08.390+0800] {processor.py:157} INFO - Started process (PID=190) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:42:08.391+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:42:08.392+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:42:08.391+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:42:08.754+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:42:08.768+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:42:08.767+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T17:42:08.785+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:42:08.784+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T17:42:08.794+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.406 seconds
[2023-10-26T17:42:39.096+0800] {processor.py:157} INFO - Started process (PID=203) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:42:39.104+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:42:39.110+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:42:39.109+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:42:39.871+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:42:39.892+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:42:39.892+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T17:42:39.904+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:42:39.904+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T17:42:39.913+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.839 seconds
[2023-10-26T17:43:10.348+0800] {processor.py:157} INFO - Started process (PID=223) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:43:10.352+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:43:10.354+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:43:10.353+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:43:10.931+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:43:10.943+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:43:10.943+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T17:43:10.954+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:43:10.954+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T17:43:10.964+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.624 seconds
[2023-10-26T17:43:41.417+0800] {processor.py:157} INFO - Started process (PID=242) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:43:41.434+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:43:41.438+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:43:41.437+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:43:41.987+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:43:41.999+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:43:41.999+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T17:43:42.012+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:43:42.012+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T17:43:42.021+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.612 seconds
[2023-10-26T17:44:12.470+0800] {processor.py:157} INFO - Started process (PID=261) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:44:12.474+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:44:12.477+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:44:12.476+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:44:13.130+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:44:13.142+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:44:13.142+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T17:44:13.154+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:44:13.154+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T17:44:13.163+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.698 seconds
[2023-10-26T17:44:43.577+0800] {processor.py:157} INFO - Started process (PID=289) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:44:43.600+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:44:43.603+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:44:43.601+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:44:44.627+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:44:44.660+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:44:44.660+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T17:44:44.679+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:44:44.679+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T17:44:44.693+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.131 seconds
[2023-10-26T17:45:15.127+0800] {processor.py:157} INFO - Started process (PID=308) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:45:15.131+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:45:15.132+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:45:15.132+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:45:15.667+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:45:15.680+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:45:15.680+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T17:45:15.691+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:45:15.691+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T17:45:15.699+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.590 seconds
[2023-10-26T17:45:46.105+0800] {processor.py:157} INFO - Started process (PID=327) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:45:46.120+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:45:46.124+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:45:46.123+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:45:46.735+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:45:46.749+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:45:46.749+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T17:45:46.762+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:45:46.761+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T17:45:46.774+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.680 seconds
[2023-10-26T17:46:17.377+0800] {processor.py:157} INFO - Started process (PID=345) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:46:17.393+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:46:17.401+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:46:17.399+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:46:18.086+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:46:18.100+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:46:18.100+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T17:46:18.112+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:46:18.112+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T17:46:18.123+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.770 seconds
[2023-10-26T17:46:48.552+0800] {processor.py:157} INFO - Started process (PID=364) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:46:48.565+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:46:48.571+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:46:48.570+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:46:49.180+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:46:49.193+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:46:49.193+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T17:46:49.208+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:46:49.208+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T17:46:49.217+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.673 seconds
[2023-10-26T17:47:19.633+0800] {processor.py:157} INFO - Started process (PID=388) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:47:19.645+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:47:19.650+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:47:19.649+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:47:20.274+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:47:20.289+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:47:20.288+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T17:47:20.305+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:47:20.305+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T17:47:20.315+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.691 seconds
[2023-10-26T17:47:50.875+0800] {processor.py:157} INFO - Started process (PID=407) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:47:50.889+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:47:50.897+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:47:50.896+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:47:51.501+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:47:51.518+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:47:51.517+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T17:47:51.535+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:47:51.534+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T17:47:51.544+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.683 seconds
[2023-10-26T17:48:22.071+0800] {processor.py:157} INFO - Started process (PID=426) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:48:22.087+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:48:22.095+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:48:22.092+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:48:22.757+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:48:22.770+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:48:22.770+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T17:48:22.784+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:48:22.784+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T17:48:22.794+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.734 seconds
[2023-10-26T17:48:53.253+0800] {processor.py:157} INFO - Started process (PID=445) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:48:53.270+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:48:53.276+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:48:53.275+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:48:53.867+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:48:53.879+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:48:53.879+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T17:48:53.891+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:48:53.891+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T17:48:53.899+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.654 seconds
[2023-10-26T17:49:24.163+0800] {processor.py:157} INFO - Started process (PID=464) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:49:24.166+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:49:24.168+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:49:24.167+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:49:24.877+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:49:24.889+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:49:24.889+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T17:49:24.901+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:49:24.901+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T17:49:24.915+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.757 seconds
[2023-10-26T17:49:55.261+0800] {processor.py:157} INFO - Started process (PID=483) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:49:55.280+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:49:55.281+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:49:55.281+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:49:55.922+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:49:55.943+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:49:55.943+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T17:49:55.966+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:49:55.965+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T17:49:55.981+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.726 seconds
[2023-10-26T17:50:26.336+0800] {processor.py:157} INFO - Started process (PID=508) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:50:26.355+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:50:26.357+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:50:26.356+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:50:26.964+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:50:26.977+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:50:26.977+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T17:50:26.988+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:50:26.988+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T17:50:26.996+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.672 seconds
[2023-10-26T17:50:57.459+0800] {processor.py:157} INFO - Started process (PID=528) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:50:57.471+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:50:57.478+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:50:57.477+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:50:58.465+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:50:58.497+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:50:58.496+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T17:50:58.511+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:50:58.511+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T17:50:58.522+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.078 seconds
[2023-10-26T17:51:29.035+0800] {processor.py:157} INFO - Started process (PID=547) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:51:29.057+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:51:29.059+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:51:29.058+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:51:29.860+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:51:29.875+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:51:29.875+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T17:51:29.888+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:51:29.888+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T17:51:29.898+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.890 seconds
[2023-10-26T17:52:00.499+0800] {processor.py:157} INFO - Started process (PID=566) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:52:00.519+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:52:00.520+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:52:00.520+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:52:01.130+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:52:01.146+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:52:01.146+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T17:52:01.168+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:52:01.168+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T17:52:01.182+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.688 seconds
[2023-10-26T17:52:31.577+0800] {processor.py:157} INFO - Started process (PID=585) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:52:31.603+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:52:31.606+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:52:31.605+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:52:32.374+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:52:32.389+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:52:32.388+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T17:52:32.400+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:52:32.400+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T17:52:32.411+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.849 seconds
[2023-10-26T17:53:02.684+0800] {processor.py:157} INFO - Started process (PID=604) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:53:02.693+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:53:02.697+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:53:02.696+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:53:03.272+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:53:03.284+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:53:03.283+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T17:53:03.295+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:53:03.294+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T17:53:03.303+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.630 seconds
[2023-10-26T17:53:33.795+0800] {processor.py:157} INFO - Started process (PID=623) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:53:33.808+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:53:33.813+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:53:33.813+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:53:34.405+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:53:34.418+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:53:34.417+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T17:53:34.429+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:53:34.428+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T17:53:34.438+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.651 seconds
[2023-10-26T17:54:04.854+0800] {processor.py:157} INFO - Started process (PID=642) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:54:04.860+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:54:04.864+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:54:04.864+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:54:05.454+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:54:05.465+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:54:05.465+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T17:54:05.476+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:54:05.476+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T17:54:05.485+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.638 seconds
[2023-10-26T17:54:35.883+0800] {processor.py:157} INFO - Started process (PID=661) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:54:35.889+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:54:35.894+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:54:35.893+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:54:36.431+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:54:36.443+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:54:36.443+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T17:54:36.454+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:54:36.454+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T17:54:36.463+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.591 seconds
[2023-10-26T17:55:06.774+0800] {processor.py:157} INFO - Started process (PID=680) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:55:06.792+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:55:06.793+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:55:06.793+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:55:07.447+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:55:07.464+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:55:07.463+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T17:55:07.478+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:55:07.478+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T17:55:07.490+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.740 seconds
[2023-10-26T17:55:37.955+0800] {processor.py:157} INFO - Started process (PID=699) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:55:37.959+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:55:37.961+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:55:37.960+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:55:38.738+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:55:38.754+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:55:38.754+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T17:55:38.769+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:55:38.769+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T17:55:38.781+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.846 seconds
[2023-10-26T17:56:09.248+0800] {processor.py:157} INFO - Started process (PID=718) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:56:09.261+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:56:09.265+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:56:09.265+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:56:09.822+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:56:09.839+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:56:09.839+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T17:56:09.850+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:56:09.850+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T17:56:09.860+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.631 seconds
[2023-10-26T17:56:40.536+0800] {processor.py:157} INFO - Started process (PID=742) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:56:40.551+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:56:40.565+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:56:40.561+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:56:41.404+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:56:41.421+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:56:41.420+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T17:56:41.439+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:56:41.439+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T17:56:41.468+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.940 seconds
[2023-10-26T17:57:11.980+0800] {processor.py:157} INFO - Started process (PID=766) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:57:11.996+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:57:12.002+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:57:12.001+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:57:12.710+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:57:12.725+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:57:12.725+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T17:57:12.737+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:57:12.737+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T17:57:12.750+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.784 seconds
[2023-10-26T17:57:43.405+0800] {processor.py:157} INFO - Started process (PID=790) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:57:43.426+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:57:43.427+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:57:43.427+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:57:44.031+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:57:44.047+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:57:44.046+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T17:57:44.063+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:57:44.063+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T17:57:44.073+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.674 seconds
[2023-10-26T17:58:14.584+0800] {processor.py:157} INFO - Started process (PID=815) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:58:14.607+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:58:14.608+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:58:14.608+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:58:15.272+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:58:15.291+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:58:15.290+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T17:58:15.303+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:58:15.303+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T17:58:15.315+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.743 seconds
[2023-10-26T17:58:45.800+0800] {processor.py:157} INFO - Started process (PID=839) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:58:45.816+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:58:45.822+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:58:45.821+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:58:46.376+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:58:46.388+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:58:46.387+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T17:58:46.398+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:58:46.398+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T17:58:46.407+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.621 seconds
[2023-10-26T17:59:16.850+0800] {processor.py:157} INFO - Started process (PID=863) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:59:16.857+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:59:16.862+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:59:16.861+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:59:17.428+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:59:17.441+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:59:17.441+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T17:59:17.451+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:59:17.451+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T17:59:17.462+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.619 seconds
[2023-10-26T17:59:47.941+0800] {processor.py:157} INFO - Started process (PID=888) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:59:47.953+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T17:59:47.955+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:59:47.954+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:59:48.573+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T17:59:48.586+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:59:48.586+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T17:59:48.599+0800] {logging_mixin.py:151} INFO - [2023-10-26T17:59:48.599+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-25T10:00:00+00:00, run_after=2023-10-26T10:00:00+00:00
[2023-10-26T17:59:48.609+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.684 seconds
[2023-10-26T18:00:19.228+0800] {processor.py:157} INFO - Started process (PID=918) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:00:19.275+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:00:19.305+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:00:19.300+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:00:21.434+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:00:21.457+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:00:21.457+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:00:21.477+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:00:21.477+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:00:21.491+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 2.314 seconds
[2023-10-26T18:00:51.803+0800] {processor.py:157} INFO - Started process (PID=945) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:00:51.811+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:00:51.818+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:00:51.817+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:00:52.407+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:00:52.420+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:00:52.420+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:00:52.430+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:00:52.430+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:00:52.440+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.651 seconds
[2023-10-26T18:01:22.929+0800] {processor.py:157} INFO - Started process (PID=969) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:01:22.938+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:01:22.944+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:01:22.941+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:01:23.591+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:01:23.615+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:01:23.615+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:01:23.628+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:01:23.628+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:01:23.637+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.717 seconds
[2023-10-26T18:01:54.226+0800] {processor.py:157} INFO - Started process (PID=993) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:01:54.243+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:01:54.244+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:01:54.244+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:01:54.805+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:01:54.818+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:01:54.818+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:01:54.838+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:01:54.837+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:01:54.849+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.646 seconds
[2023-10-26T18:02:25.373+0800] {processor.py:157} INFO - Started process (PID=1017) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:02:25.392+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:02:25.394+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:02:25.393+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:02:25.955+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:02:25.967+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:02:25.967+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:02:25.983+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:02:25.983+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:02:25.991+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.624 seconds
[2023-10-26T18:02:56.413+0800] {processor.py:157} INFO - Started process (PID=1041) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:02:56.425+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:02:56.430+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:02:56.429+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:02:57.047+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:02:57.060+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:02:57.060+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:02:57.070+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:02:57.070+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:02:57.079+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.674 seconds
[2023-10-26T18:03:27.457+0800] {processor.py:157} INFO - Started process (PID=1065) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:03:27.467+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:03:27.473+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:03:27.473+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:03:28.157+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:03:28.186+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:03:28.185+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:03:28.203+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:03:28.203+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:03:28.213+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.768 seconds
[2023-10-26T18:03:58.743+0800] {processor.py:157} INFO - Started process (PID=1090) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:03:58.758+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:03:58.759+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:03:58.758+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:03:59.376+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:03:59.400+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:03:59.400+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:03:59.413+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:03:59.413+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:03:59.426+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.690 seconds
[2023-10-26T18:04:30.088+0800] {processor.py:157} INFO - Started process (PID=1114) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:04:30.103+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:04:30.110+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:04:30.106+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:04:30.928+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:04:30.954+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:04:30.953+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:04:30.977+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:04:30.977+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:04:30.989+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.911 seconds
[2023-10-26T18:05:01.339+0800] {processor.py:157} INFO - Started process (PID=1145) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:05:01.346+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:05:01.352+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:05:01.352+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:05:01.925+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:05:01.948+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:05:01.948+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:05:01.967+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:05:01.967+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:05:01.978+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.644 seconds
[2023-10-26T18:05:32.455+0800] {processor.py:157} INFO - Started process (PID=1168) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:05:32.469+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:05:32.475+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:05:32.475+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:05:33.300+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:05:33.315+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:05:33.315+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:05:33.329+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:05:33.329+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:05:33.339+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.891 seconds
[2023-10-26T18:06:03.812+0800] {processor.py:157} INFO - Started process (PID=1192) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:06:03.819+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:06:03.825+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:06:03.825+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:06:04.624+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:06:04.638+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:06:04.638+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:06:04.652+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:06:04.652+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:06:04.661+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.857 seconds
[2023-10-26T18:06:35.201+0800] {processor.py:157} INFO - Started process (PID=1216) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:06:35.210+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:06:35.214+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:06:35.213+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:06:35.892+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:06:35.906+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:06:35.905+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:06:35.918+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:06:35.918+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:06:35.928+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.733 seconds
[2023-10-26T18:07:06.621+0800] {processor.py:157} INFO - Started process (PID=1240) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:07:06.632+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:07:06.638+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:07:06.637+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:07:07.376+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:07:07.394+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:07:07.393+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:07:07.415+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:07:07.415+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:07:07.427+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.821 seconds
[2023-10-26T18:07:37.689+0800] {processor.py:157} INFO - Started process (PID=1266) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:07:37.704+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:07:37.706+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:07:37.705+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:07:38.457+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:07:38.469+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:07:38.468+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:07:38.494+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:07:38.493+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:07:38.505+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.828 seconds
[2023-10-26T18:08:08.975+0800] {processor.py:157} INFO - Started process (PID=1293) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:08:08.992+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:08:08.993+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:08:08.992+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:08:09.568+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:08:09.581+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:08:09.580+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:08:09.593+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:08:09.593+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:08:09.613+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.649 seconds
[2023-10-26T18:08:40.185+0800] {processor.py:157} INFO - Started process (PID=1316) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:08:40.198+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:08:40.200+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:08:40.199+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:08:40.911+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:08:40.928+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:08:40.927+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:08:40.960+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:08:40.959+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:08:40.992+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.819 seconds
[2023-10-26T18:09:11.626+0800] {processor.py:157} INFO - Started process (PID=1342) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:09:11.629+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:09:11.630+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:09:11.629+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:09:12.285+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:09:12.295+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:09:12.295+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:09:12.309+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:09:12.309+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:09:12.317+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.700 seconds
[2023-10-26T18:09:42.872+0800] {processor.py:157} INFO - Started process (PID=1368) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:09:42.877+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:09:42.880+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:09:42.879+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:09:44.012+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:09:44.039+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:09:44.037+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:09:44.061+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:09:44.061+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:09:44.077+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.211 seconds
[2023-10-26T18:10:14.403+0800] {processor.py:157} INFO - Started process (PID=1392) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:10:14.409+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:10:14.411+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:10:14.410+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:10:15.056+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:10:15.069+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:10:15.068+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:10:15.080+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:10:15.080+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:10:15.091+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.695 seconds
[2023-10-26T18:10:45.589+0800] {processor.py:157} INFO - Started process (PID=1416) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:10:45.595+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:10:45.602+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:10:45.601+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:10:46.269+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:10:46.285+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:10:46.285+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:10:46.299+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:10:46.299+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:10:46.317+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.739 seconds
[2023-10-26T18:11:16.904+0800] {processor.py:157} INFO - Started process (PID=1441) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:11:16.912+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:11:16.914+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:11:16.913+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:11:18.179+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:11:18.194+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:11:18.194+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:11:18.209+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:11:18.209+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:11:18.219+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.324 seconds
[2023-10-26T18:11:48.913+0800] {processor.py:157} INFO - Started process (PID=1465) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:11:48.919+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:11:48.921+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:11:48.920+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:11:49.573+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:11:49.586+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:11:49.585+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:11:49.596+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:11:49.596+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:11:49.605+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.697 seconds
[2023-10-26T18:12:20.102+0800] {processor.py:157} INFO - Started process (PID=1494) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:12:20.108+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:12:20.112+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:12:20.112+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:12:20.898+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:12:20.912+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:12:20.911+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:12:20.941+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:12:20.940+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:12:20.954+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.858 seconds
[2023-10-26T18:12:51.608+0800] {processor.py:157} INFO - Started process (PID=1520) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:12:51.632+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:12:51.633+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:12:51.633+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:12:53.027+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:12:53.063+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:12:53.062+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:12:53.080+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:12:53.080+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:12:53.093+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.493 seconds
[2023-10-26T18:13:23.604+0800] {processor.py:157} INFO - Started process (PID=1546) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:13:23.607+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:13:23.609+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:13:23.608+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:13:24.991+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:13:25.012+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:13:25.011+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:13:25.034+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:13:25.034+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:13:25.050+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.455 seconds
[2023-10-26T18:13:55.548+0800] {processor.py:157} INFO - Started process (PID=1569) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:13:55.555+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:13:55.556+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:13:55.555+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:13:56.836+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:13:56.860+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:13:56.860+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:13:56.875+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:13:56.875+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:13:56.887+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.357 seconds
[2023-10-26T18:14:27.282+0800] {processor.py:157} INFO - Started process (PID=1594) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:14:27.288+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:14:27.290+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:14:27.289+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:14:27.937+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:14:27.957+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:14:27.957+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:14:27.980+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:14:27.980+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:14:27.992+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.722 seconds
[2023-10-26T18:14:58.558+0800] {processor.py:157} INFO - Started process (PID=1618) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:14:58.561+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:14:58.562+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:14:58.562+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:14:59.165+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:14:59.176+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:14:59.175+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:14:59.187+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:14:59.187+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:14:59.196+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.644 seconds
[2023-10-26T18:15:29.612+0800] {processor.py:157} INFO - Started process (PID=1642) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:15:29.621+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:15:29.628+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:15:29.628+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:15:30.159+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:15:30.169+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:15:30.169+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:15:30.180+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:15:30.180+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:15:30.190+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.583 seconds
[2023-10-26T18:16:00.654+0800] {processor.py:157} INFO - Started process (PID=1666) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:16:00.662+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:16:00.669+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:16:00.669+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:16:01.218+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:16:01.228+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:16:01.228+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:16:01.239+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:16:01.238+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:16:01.247+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.600 seconds
[2023-10-26T18:16:31.802+0800] {processor.py:157} INFO - Started process (PID=1690) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:16:31.805+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:16:31.806+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:16:31.806+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:16:32.385+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:16:32.396+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:16:32.396+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:16:32.406+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:16:32.405+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:16:32.415+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.626 seconds
[2023-10-26T18:17:03.042+0800] {processor.py:157} INFO - Started process (PID=1714) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:17:03.046+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:17:03.047+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:17:03.046+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:17:03.611+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:17:03.621+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:17:03.621+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:17:03.631+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:17:03.631+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:17:03.641+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.604 seconds
[2023-10-26T18:17:34.107+0800] {processor.py:157} INFO - Started process (PID=1738) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:17:34.110+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:17:34.111+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:17:34.111+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:17:34.693+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:17:34.704+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:17:34.703+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:17:34.716+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:17:34.716+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:17:34.734+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.632 seconds
[2023-10-26T18:18:05.143+0800] {processor.py:157} INFO - Started process (PID=1762) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:18:05.146+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:18:05.148+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:18:05.148+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:18:05.782+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:18:05.792+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:18:05.792+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:18:05.802+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:18:05.802+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:18:05.811+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.673 seconds
[2023-10-26T18:18:36.257+0800] {processor.py:157} INFO - Started process (PID=1793) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:18:36.262+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:18:36.270+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:18:36.269+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:18:36.867+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:18:36.879+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:18:36.879+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:18:36.890+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:18:36.889+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:18:36.900+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.649 seconds
[2023-10-26T18:19:07.340+0800] {processor.py:157} INFO - Started process (PID=1817) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:19:07.343+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:19:07.345+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:19:07.344+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:19:07.898+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:19:07.910+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:19:07.910+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:19:07.920+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:19:07.920+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:19:07.930+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.597 seconds
[2023-10-26T18:19:38.454+0800] {processor.py:157} INFO - Started process (PID=1842) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:19:38.513+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:19:38.533+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:19:38.532+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:19:39.059+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:19:39.072+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:19:39.071+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:19:39.086+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:19:39.086+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:19:39.096+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.667 seconds
[2023-10-26T18:20:09.642+0800] {processor.py:157} INFO - Started process (PID=1869) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:20:09.649+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:20:09.650+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:20:09.649+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:20:10.109+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:20:10.124+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:20:10.123+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:20:10.145+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:20:10.145+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:20:10.158+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.521 seconds
[2023-10-26T18:20:40.745+0800] {processor.py:157} INFO - Started process (PID=1892) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:20:40.753+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:20:40.759+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:20:40.755+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:20:41.221+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:20:41.237+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:20:41.237+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:20:41.252+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:20:41.252+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:20:41.262+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.523 seconds
[2023-10-26T18:21:11.738+0800] {processor.py:157} INFO - Started process (PID=1917) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:21:11.746+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:21:11.747+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:21:11.747+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:21:12.081+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:21:12.092+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:21:12.092+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:21:12.102+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:21:12.102+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:21:12.112+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.376 seconds
[2023-10-26T18:21:42.569+0800] {processor.py:157} INFO - Started process (PID=1941) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:21:42.579+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:21:42.583+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:21:42.582+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:21:43.023+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:21:43.045+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:21:43.044+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:21:43.074+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:21:43.074+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:21:43.089+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.526 seconds
[2023-10-26T18:22:13.571+0800] {processor.py:157} INFO - Started process (PID=1965) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:22:13.587+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:22:13.589+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:22:13.588+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:22:14.026+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:22:14.038+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:22:14.038+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:22:14.051+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:22:14.051+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:22:14.068+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.500 seconds
[2023-10-26T18:22:44.607+0800] {processor.py:157} INFO - Started process (PID=1988) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:22:44.616+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:22:44.617+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:22:44.617+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:22:44.953+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:22:44.965+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:22:44.965+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:22:44.981+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:22:44.981+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:22:44.993+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.392 seconds
[2023-10-26T18:23:15.606+0800] {processor.py:157} INFO - Started process (PID=2013) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:23:15.614+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:23:15.616+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:23:15.615+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:23:16.132+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:23:16.143+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:23:16.143+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:23:16.155+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:23:16.155+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:23:16.174+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.571 seconds
[2023-10-26T18:23:46.613+0800] {processor.py:157} INFO - Started process (PID=2037) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:23:46.619+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:23:46.620+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:23:46.620+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:23:47.240+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:23:47.281+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:23:47.280+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:23:47.301+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:23:47.301+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:23:47.314+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.705 seconds
[2023-10-26T18:24:17.805+0800] {processor.py:157} INFO - Started process (PID=2062) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:24:17.811+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:24:17.812+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:24:17.812+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:24:18.499+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:24:18.545+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:24:18.545+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:24:18.579+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:24:18.578+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:24:18.623+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.822 seconds
[2023-10-26T18:24:49.074+0800] {processor.py:157} INFO - Started process (PID=2088) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:24:49.081+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:24:49.083+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:24:49.082+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:24:49.440+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:24:49.452+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:24:49.452+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:24:49.476+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:24:49.475+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:24:49.487+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.421 seconds
[2023-10-26T18:25:19.831+0800] {processor.py:157} INFO - Started process (PID=2112) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:25:19.841+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:25:19.842+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:25:19.841+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:25:20.173+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:25:20.183+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:25:20.183+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:25:20.194+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:25:20.193+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:25:20.202+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.376 seconds
[2023-10-26T18:25:50.631+0800] {processor.py:157} INFO - Started process (PID=2136) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:25:50.643+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:25:50.644+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:25:50.644+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:25:50.999+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:25:51.024+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:25:51.023+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:25:51.039+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:25:51.039+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:25:51.051+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.425 seconds
[2023-10-26T18:26:21.626+0800] {processor.py:157} INFO - Started process (PID=2160) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:26:21.635+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:26:21.646+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:26:21.643+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:26:22.090+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:26:22.106+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:26:22.105+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:26:22.128+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:26:22.128+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:26:22.945+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.369 seconds
[2023-10-26T18:26:53.408+0800] {processor.py:157} INFO - Started process (PID=2191) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:26:53.413+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:26:53.415+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:26:53.415+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:26:53.783+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:26:53.800+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:26:53.799+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:26:53.815+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:26:53.814+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:26:53.826+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.426 seconds
[2023-10-26T18:27:24.211+0800] {processor.py:157} INFO - Started process (PID=2215) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:27:24.215+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:27:24.217+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:27:24.216+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:27:24.461+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:27:24.475+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:27:24.474+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:27:24.487+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:27:24.487+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:27:24.498+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.293 seconds
[2023-10-26T18:27:54.960+0800] {processor.py:157} INFO - Started process (PID=2239) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:27:54.972+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:27:54.973+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:27:54.973+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:27:55.253+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:27:55.266+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:27:55.266+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:27:55.279+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:27:55.279+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:27:55.534+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.580 seconds
[2023-10-26T18:28:25.792+0800] {processor.py:157} INFO - Started process (PID=2263) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:28:25.804+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:28:25.806+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:28:25.805+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:28:26.088+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:28:26.102+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:28:26.101+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:28:26.116+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:28:26.116+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:28:26.128+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.342 seconds
[2023-10-26T18:28:56.442+0800] {processor.py:157} INFO - Started process (PID=2287) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:28:56.450+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:28:56.451+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:28:56.451+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:28:56.734+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:28:56.748+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:28:56.747+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:28:56.761+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:28:56.761+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:28:56.772+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.337 seconds
[2023-10-26T18:29:27.181+0800] {processor.py:157} INFO - Started process (PID=2311) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:29:27.193+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:29:27.195+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:29:27.194+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:29:27.460+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:29:27.490+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:29:27.485+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:29:27.507+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:29:27.506+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:29:27.763+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.603 seconds
[2023-10-26T18:29:58.369+0800] {processor.py:157} INFO - Started process (PID=2335) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:29:58.378+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:29:58.380+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:29:58.379+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:29:58.629+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:29:58.641+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:29:58.641+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:29:58.858+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:29:58.858+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:29:58.872+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.510 seconds
[2023-10-26T18:30:29.119+0800] {processor.py:157} INFO - Started process (PID=2359) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:30:29.125+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:30:29.126+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:30:29.126+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:30:29.441+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:30:29.457+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:30:29.456+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:30:29.479+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:30:29.479+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:30:29.496+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.382 seconds
[2023-10-26T18:30:59.923+0800] {processor.py:157} INFO - Started process (PID=2383) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:30:59.929+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:30:59.930+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:30:59.929+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:31:00.249+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:31:00.268+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:31:00.268+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:31:00.282+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:31:00.282+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:31:00.504+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.586 seconds
[2023-10-26T18:31:30.656+0800] {processor.py:157} INFO - Started process (PID=2407) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:31:30.666+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:31:30.667+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:31:30.667+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:31:30.910+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:31:30.921+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:31:30.921+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:31:31.116+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:31:31.115+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:31:31.130+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.479 seconds
[2023-10-26T18:32:01.421+0800] {processor.py:157} INFO - Started process (PID=2431) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:32:01.431+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:32:01.432+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:32:01.432+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:32:01.690+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:32:01.702+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:32:01.701+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:32:01.714+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:32:01.714+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:32:01.726+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.313 seconds
[2023-10-26T18:32:32.217+0800] {processor.py:157} INFO - Started process (PID=2455) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:32:32.225+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:32:32.226+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:32:32.225+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:32:32.565+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:32:32.577+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:32:32.577+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:32:32.606+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:32:32.606+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:32:32.818+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.605 seconds
[2023-10-26T18:33:03.051+0800] {processor.py:157} INFO - Started process (PID=2479) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:33:03.059+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:33:03.061+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:33:03.060+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:33:03.411+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:33:03.433+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:33:03.433+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:33:03.669+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:33:03.669+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:33:03.680+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.633 seconds
[2023-10-26T18:33:34.306+0800] {processor.py:157} INFO - Started process (PID=2502) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:33:34.315+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:33:34.317+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:33:34.316+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:33:34.652+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:33:34.667+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:33:34.667+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:33:34.681+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:33:34.681+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:33:34.699+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.402 seconds
[2023-10-26T18:34:04.997+0800] {processor.py:157} INFO - Started process (PID=2526) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:34:05.006+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:34:05.007+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:34:05.007+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:34:05.276+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:34:05.289+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:34:05.289+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:34:05.301+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:34:05.301+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:34:05.524+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.532 seconds
[2023-10-26T18:34:35.833+0800] {processor.py:157} INFO - Started process (PID=2550) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:34:35.841+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:34:35.842+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:34:35.841+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:34:36.274+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:34:36.289+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:34:36.288+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:34:36.672+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:34:36.672+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:34:36.690+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.865 seconds
[2023-10-26T18:35:07.275+0800] {processor.py:157} INFO - Started process (PID=2574) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:35:07.279+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:35:07.280+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:35:07.280+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:35:07.504+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:35:07.697+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:35:07.697+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:35:07.709+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:35:07.709+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:35:07.718+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.445 seconds
[2023-10-26T18:35:38.128+0800] {processor.py:157} INFO - Started process (PID=2598) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:35:38.135+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:35:38.137+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:35:38.136+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:35:38.390+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:35:38.403+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:35:38.403+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:35:38.417+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:35:38.417+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:35:38.433+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.313 seconds
[2023-10-26T18:36:08.850+0800] {processor.py:157} INFO - Started process (PID=2622) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:36:08.855+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:36:08.856+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:36:08.855+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:36:09.121+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:36:09.134+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:36:09.134+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:36:09.146+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:36:09.146+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:36:09.328+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.483 seconds
[2023-10-26T18:36:39.561+0800] {processor.py:157} INFO - Started process (PID=2646) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:36:39.564+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:36:39.566+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:36:39.565+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:36:39.906+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:36:39.920+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:36:39.920+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:36:40.147+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:36:40.147+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:36:40.158+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.603 seconds
[2023-10-26T18:37:10.270+0800] {processor.py:157} INFO - Started process (PID=2670) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:37:10.277+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:37:10.278+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:37:10.277+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:37:10.542+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:37:10.736+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:37:10.736+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:37:10.747+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:37:10.747+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:37:10.757+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.494 seconds
[2023-10-26T18:37:40.876+0800] {processor.py:157} INFO - Started process (PID=2694) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:37:40.884+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:37:40.885+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:37:40.884+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:37:41.177+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:37:41.189+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:37:41.189+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:37:41.201+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:37:41.201+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:37:41.211+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.339 seconds
[2023-10-26T18:38:11.690+0800] {processor.py:157} INFO - Started process (PID=2725) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:38:11.698+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:38:11.699+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:38:11.699+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:38:11.982+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:38:11.995+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:38:11.995+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:38:12.010+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:38:12.010+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:38:12.227+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.543 seconds
[2023-10-26T18:38:42.576+0800] {processor.py:157} INFO - Started process (PID=2749) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:38:42.584+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:38:42.585+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:38:42.584+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:38:42.999+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:38:43.012+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:38:43.012+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:38:43.217+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:38:43.216+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:38:43.228+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.658 seconds
[2023-10-26T18:39:13.898+0800] {processor.py:157} INFO - Started process (PID=2773) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:39:13.905+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:39:13.907+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:39:13.906+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:39:14.259+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:39:14.461+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:39:14.461+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:39:14.480+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:39:14.480+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:39:14.489+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.600 seconds
[2023-10-26T18:39:45.083+0800] {processor.py:157} INFO - Started process (PID=2797) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:39:45.089+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:39:45.090+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:39:45.090+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:39:45.344+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:39:45.357+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:39:45.357+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:39:45.370+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:39:45.370+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:39:45.380+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.303 seconds
[2023-10-26T18:40:15.935+0800] {processor.py:157} INFO - Started process (PID=2820) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:40:15.943+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:40:15.944+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:40:15.943+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:40:16.195+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:40:16.208+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:40:16.207+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:40:16.222+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:40:16.222+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:40:16.478+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.550 seconds
[2023-10-26T18:40:46.767+0800] {processor.py:157} INFO - Started process (PID=2843) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:40:46.773+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:40:46.774+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:40:46.774+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:40:47.032+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:40:47.049+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:40:47.049+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:40:47.269+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:40:47.269+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:40:47.281+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.519 seconds
[2023-10-26T18:41:17.551+0800] {processor.py:157} INFO - Started process (PID=2867) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:41:17.556+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:41:17.556+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:41:17.556+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:41:17.817+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:41:18.013+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:41:18.012+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:41:18.023+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:41:18.023+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:41:18.033+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.490 seconds
[2023-10-26T18:41:48.301+0800] {processor.py:157} INFO - Started process (PID=2891) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:41:48.309+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:41:48.310+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:41:48.310+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:41:48.568+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:41:48.581+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:41:48.581+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:41:48.596+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:41:48.596+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:41:48.608+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.316 seconds
[2023-10-26T18:42:19.081+0800] {processor.py:157} INFO - Started process (PID=2915) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:42:19.086+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:42:19.087+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:42:19.087+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:42:19.392+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:42:19.405+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:42:19.404+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:42:19.613+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:42:19.613+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:42:19.623+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.548 seconds
[2023-10-26T18:42:49.858+0800] {processor.py:157} INFO - Started process (PID=2939) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:42:49.865+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:42:49.867+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:42:49.866+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:42:50.162+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:42:50.178+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:42:50.178+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:42:50.394+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:42:50.394+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:42:50.411+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.561 seconds
[2023-10-26T18:43:20.573+0800] {processor.py:157} INFO - Started process (PID=2963) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:43:20.582+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:43:20.583+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:43:20.582+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:43:20.879+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:43:21.083+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:43:21.083+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:43:21.107+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:43:21.107+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:43:21.118+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.552 seconds
[2023-10-26T18:43:51.373+0800] {processor.py:157} INFO - Started process (PID=2987) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:43:51.385+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:43:51.393+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:43:51.390+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:43:51.653+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:43:51.665+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:43:51.665+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:43:51.679+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:43:51.679+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:43:51.689+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.324 seconds
[2023-10-26T18:44:22.139+0800] {processor.py:157} INFO - Started process (PID=3010) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:44:22.147+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:44:22.148+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:44:22.148+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:44:22.442+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:44:22.455+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:44:22.454+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:44:22.680+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:44:22.680+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:44:22.693+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.566 seconds
[2023-10-26T18:44:52.867+0800] {processor.py:157} INFO - Started process (PID=3034) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:44:52.874+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:44:52.875+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:44:52.875+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:44:53.136+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:44:53.158+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:44:53.158+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:44:53.404+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:44:53.404+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:44:53.420+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.557 seconds
[2023-10-26T18:45:23.711+0800] {processor.py:157} INFO - Started process (PID=3058) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:45:23.718+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:45:23.719+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:45:23.719+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:45:23.976+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:45:24.203+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:45:24.202+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:45:24.215+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:45:24.215+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:45:24.224+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.519 seconds
[2023-10-26T18:45:54.452+0800] {processor.py:157} INFO - Started process (PID=3082) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:45:54.460+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:45:54.461+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:45:54.461+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:45:54.798+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:45:54.811+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:45:54.811+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:45:54.824+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:45:54.824+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:45:54.836+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.390 seconds
[2023-10-26T18:46:25.278+0800] {processor.py:157} INFO - Started process (PID=3106) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:46:25.287+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:46:25.288+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:46:25.288+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:46:25.589+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:46:25.602+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:46:25.602+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:46:25.830+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:46:25.829+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:46:25.841+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.570 seconds
[2023-10-26T18:46:56.530+0800] {processor.py:157} INFO - Started process (PID=3130) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:46:56.539+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:46:56.540+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:46:56.540+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:46:56.897+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:46:57.091+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:46:56.911+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:46:57.104+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:46:57.104+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:46:57.115+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.596 seconds
[2023-10-26T18:47:27.670+0800] {processor.py:157} INFO - Started process (PID=3154) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:47:27.678+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:47:27.679+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:47:27.679+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:47:28.116+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:47:28.128+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:47:28.128+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:47:28.139+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:47:28.139+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:47:28.148+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.485 seconds
[2023-10-26T18:47:58.456+0800] {processor.py:157} INFO - Started process (PID=3179) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:47:58.464+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:47:58.465+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:47:58.465+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:47:58.748+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:47:58.761+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:47:58.761+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:47:58.774+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:47:58.774+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:47:58.981+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.532 seconds
[2023-10-26T18:48:29.183+0800] {processor.py:157} INFO - Started process (PID=3202) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:48:29.192+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:48:29.193+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:48:29.192+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:48:29.441+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:48:29.458+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:48:29.457+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:48:29.665+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:48:29.665+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:48:29.675+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.497 seconds
[2023-10-26T18:49:00.105+0800] {processor.py:157} INFO - Started process (PID=3226) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:49:00.115+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:49:00.116+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:49:00.116+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:49:00.465+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:49:00.660+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:49:00.477+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:49:00.671+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:49:00.671+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:49:00.681+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.586 seconds
[2023-10-26T18:49:31.262+0800] {processor.py:157} INFO - Started process (PID=3250) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:49:31.275+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:49:31.276+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:49:31.276+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:49:31.733+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:49:31.746+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:49:31.745+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:49:31.766+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:49:31.766+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:49:31.778+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.521 seconds
[2023-10-26T18:50:02.028+0800] {processor.py:157} INFO - Started process (PID=3274) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:50:02.038+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:50:02.039+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:50:02.039+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:50:02.328+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:50:02.342+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:50:02.341+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:50:02.358+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:50:02.357+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:50:02.600+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.578 seconds
[2023-10-26T18:50:32.855+0800] {processor.py:157} INFO - Started process (PID=3298) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:50:32.864+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:50:32.865+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:50:32.864+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:50:33.096+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:50:33.107+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:50:33.107+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:50:33.330+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:50:33.330+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:50:33.342+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.493 seconds
[2023-10-26T18:51:03.639+0800] {processor.py:157} INFO - Started process (PID=3322) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:51:03.649+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:51:03.650+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:51:03.650+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:51:04.012+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:51:04.206+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:51:04.025+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:51:04.218+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:51:04.217+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:51:04.228+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.595 seconds
[2023-10-26T18:51:34.441+0800] {processor.py:157} INFO - Started process (PID=3346) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:51:34.445+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:51:34.447+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:51:34.446+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:51:34.912+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:51:34.923+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:51:34.923+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:51:34.936+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:51:34.936+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:51:34.946+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.513 seconds
[2023-10-26T18:52:05.030+0800] {processor.py:157} INFO - Started process (PID=3370) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:52:05.036+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:52:05.037+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:52:05.037+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:52:05.346+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:52:05.359+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:52:05.359+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:52:05.373+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:52:05.373+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:52:05.569+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.546 seconds
[2023-10-26T18:52:36.191+0800] {processor.py:157} INFO - Started process (PID=3394) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:52:36.199+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:52:36.200+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:52:36.200+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:52:36.546+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:52:36.558+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:52:36.558+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:52:36.773+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:52:36.773+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:52:36.786+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.601 seconds
[2023-10-26T18:53:07.469+0800] {processor.py:157} INFO - Started process (PID=3418) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:53:07.477+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:53:07.478+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:53:07.477+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:53:07.839+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:53:08.040+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:53:08.040+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:53:08.051+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:53:08.051+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:53:08.066+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.602 seconds
[2023-10-26T18:53:38.699+0800] {processor.py:157} INFO - Started process (PID=3442) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:53:38.708+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:53:38.709+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:53:38.708+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:53:39.220+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:53:39.231+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:53:39.230+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:53:39.242+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:53:39.242+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:53:39.251+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.558 seconds
[2023-10-26T18:54:09.482+0800] {processor.py:157} INFO - Started process (PID=3466) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:54:09.490+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:54:09.491+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:54:09.490+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:54:09.867+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:54:09.879+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:54:09.879+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:54:09.894+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:54:09.894+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:54:10.092+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.616 seconds
[2023-10-26T18:54:40.722+0800] {processor.py:157} INFO - Started process (PID=3490) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:54:40.730+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:54:40.731+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:54:40.731+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:54:41.072+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:54:41.085+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:54:41.085+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:54:41.270+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:54:41.270+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:54:41.289+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.575 seconds
[2023-10-26T18:55:11.585+0800] {processor.py:157} INFO - Started process (PID=3514) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:55:11.596+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:55:11.602+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:55:11.600+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:55:11.945+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:55:12.150+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:55:12.149+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:55:12.161+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:55:12.161+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:55:12.172+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.593 seconds
[2023-10-26T18:55:42.406+0800] {processor.py:157} INFO - Started process (PID=3539) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:55:42.414+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:55:42.415+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:55:42.415+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:55:42.940+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:55:42.951+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:55:42.951+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:55:42.962+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:55:42.962+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:55:42.972+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.580 seconds
[2023-10-26T18:56:13.159+0800] {processor.py:157} INFO - Started process (PID=3563) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:56:13.170+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:56:13.176+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:56:13.173+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:56:13.671+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:56:13.682+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:56:13.682+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:56:13.694+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:56:13.694+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:56:13.704+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.550 seconds
[2023-10-26T18:56:44.042+0800] {processor.py:157} INFO - Started process (PID=3587) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:56:44.046+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:56:44.047+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:56:44.046+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:56:44.391+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:56:44.404+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:56:44.404+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:56:44.616+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:56:44.616+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:56:44.628+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.593 seconds
[2023-10-26T18:57:15.294+0800] {processor.py:157} INFO - Started process (PID=3610) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:57:15.298+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:57:15.300+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:57:15.299+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:57:15.643+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:57:15.839+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:57:15.839+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:57:15.851+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:57:15.851+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:57:15.861+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.574 seconds
[2023-10-26T18:57:46.488+0800] {processor.py:157} INFO - Started process (PID=3634) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:57:46.495+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:57:46.497+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:57:46.496+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:57:47.088+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:57:47.111+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:57:47.110+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:57:47.133+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:57:47.133+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:57:47.145+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.662 seconds
[2023-10-26T18:58:17.761+0800] {processor.py:157} INFO - Started process (PID=3665) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:58:17.766+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:58:17.768+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:58:17.767+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:58:18.287+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:58:18.298+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:58:18.297+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:58:18.308+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:58:18.308+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:58:18.318+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.565 seconds
[2023-10-26T18:58:48.980+0800] {processor.py:157} INFO - Started process (PID=3689) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:58:48.985+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:58:48.986+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:58:48.985+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:58:49.313+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:58:49.325+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:58:49.325+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:58:49.536+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:58:49.535+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:58:49.548+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.581 seconds
[2023-10-26T18:59:20.222+0800] {processor.py:157} INFO - Started process (PID=3713) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:59:20.229+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:59:20.232+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:59:20.230+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:59:20.582+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:59:20.795+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:59:20.795+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:59:20.807+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:59:20.807+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:59:20.819+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.614 seconds
[2023-10-26T18:59:51.311+0800] {processor.py:157} INFO - Started process (PID=3736) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:59:51.325+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T18:59:51.330+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:59:51.329+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:59:51.826+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T18:59:51.837+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:59:51.837+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T18:59:51.850+0800] {logging_mixin.py:151} INFO - [2023-10-26T18:59:51.850+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T18:59:51.859+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.556 seconds
[2023-10-26T19:00:22.184+0800] {processor.py:157} INFO - Started process (PID=3760) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:00:22.198+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:00:22.201+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:00:22.199+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:00:22.711+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:00:22.724+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:00:22.724+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:00:22.736+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:00:22.736+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:00:22.748+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.579 seconds
[2023-10-26T19:00:52.875+0800] {processor.py:157} INFO - Started process (PID=3784) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:00:52.880+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:00:52.881+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:00:52.881+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:00:53.362+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:00:53.373+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:00:53.373+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:00:53.385+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:00:53.385+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:00:53.398+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.529 seconds
[2023-10-26T19:01:23.769+0800] {processor.py:157} INFO - Started process (PID=3808) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:01:23.776+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:01:23.778+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:01:23.777+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:01:24.080+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:01:24.287+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:01:24.287+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:01:24.298+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:01:24.297+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:01:24.308+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.546 seconds
[2023-10-26T19:01:54.972+0800] {processor.py:157} INFO - Started process (PID=3833) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:01:54.979+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:01:54.981+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:01:54.980+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:01:55.487+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:01:55.499+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:01:55.499+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:01:55.510+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:01:55.510+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:01:55.519+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.555 seconds
[2023-10-26T19:02:25.790+0800] {processor.py:157} INFO - Started process (PID=3857) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:02:25.793+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:02:25.795+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:02:25.794+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:02:26.289+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:02:26.303+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:02:26.302+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:02:26.314+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:02:26.314+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:02:26.326+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.542 seconds
[2023-10-26T19:02:56.611+0800] {processor.py:157} INFO - Started process (PID=3881) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:02:56.615+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:02:56.617+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:02:56.616+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:02:56.916+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:02:56.928+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:02:56.928+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:02:57.115+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:02:57.115+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:02:57.127+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.531 seconds
[2023-10-26T19:03:27.418+0800] {processor.py:157} INFO - Started process (PID=3905) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:03:27.420+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:03:27.421+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:03:27.421+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:03:27.767+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:03:27.930+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:03:27.930+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:03:27.940+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:03:27.940+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:03:27.950+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.537 seconds
[2023-10-26T19:03:58.142+0800] {processor.py:157} INFO - Started process (PID=3930) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:03:58.144+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:03:58.145+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:03:58.145+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:03:58.847+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:03:58.865+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:03:58.864+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:03:58.892+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:03:58.892+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:03:58.904+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.767 seconds
[2023-10-26T19:04:29.499+0800] {processor.py:157} INFO - Started process (PID=3954) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:04:29.503+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:04:29.504+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:04:29.504+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:04:30.081+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:04:30.094+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:04:30.094+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:04:30.123+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:04:30.123+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:04:30.137+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.643 seconds
[2023-10-26T19:05:00.755+0800] {processor.py:157} INFO - Started process (PID=3978) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:05:00.762+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:05:00.763+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:05:00.763+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:05:01.355+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:05:01.367+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:05:01.367+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:05:01.379+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:05:01.379+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:05:01.389+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.639 seconds
[2023-10-26T19:05:32.033+0800] {processor.py:157} INFO - Started process (PID=4002) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:05:32.039+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:05:32.041+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:05:32.040+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:05:32.427+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:05:32.660+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:05:32.660+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:05:32.671+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:05:32.671+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:05:32.683+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.657 seconds
[2023-10-26T19:06:03.314+0800] {processor.py:157} INFO - Started process (PID=4026) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:06:03.323+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:06:03.327+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:06:03.325+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:06:03.926+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:06:03.939+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:06:03.939+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:06:03.952+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:06:03.952+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:06:03.963+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.654 seconds
[2023-10-26T19:06:34.675+0800] {processor.py:157} INFO - Started process (PID=4050) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:06:34.682+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:06:34.683+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:06:34.683+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:06:35.265+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:06:35.279+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:06:35.279+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:06:35.292+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:06:35.292+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:06:35.302+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.633 seconds
[2023-10-26T19:07:05.469+0800] {processor.py:157} INFO - Started process (PID=4074) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:07:05.476+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:07:05.477+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:07:05.477+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:07:06.015+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:07:06.026+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:07:06.025+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:07:06.037+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:07:06.036+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:07:06.048+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.585 seconds
[2023-10-26T19:07:36.564+0800] {processor.py:157} INFO - Started process (PID=4098) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:07:36.573+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:07:36.574+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:07:36.573+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:07:37.111+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:07:37.122+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:07:37.121+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:07:37.132+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:07:37.132+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:07:37.140+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.600 seconds
[2023-10-26T19:08:07.425+0800] {processor.py:157} INFO - Started process (PID=4122) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:08:07.435+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:08:07.438+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:08:07.436+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:08:08.021+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:08:08.032+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:08:08.031+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:08:08.043+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:08:08.043+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:08:08.053+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.634 seconds
[2023-10-26T19:08:38.703+0800] {processor.py:157} INFO - Started process (PID=4147) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:08:38.712+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:08:38.713+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:08:38.713+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:08:39.243+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:08:39.253+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:08:39.253+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:08:39.264+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:08:39.264+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:08:39.273+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.589 seconds
[2023-10-26T19:09:09.929+0800] {processor.py:157} INFO - Started process (PID=4171) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:09:09.947+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:09:09.948+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:09:09.947+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:09:10.507+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:09:10.520+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:09:10.519+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:09:10.531+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:09:10.531+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:09:10.541+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.621 seconds
[2023-10-26T19:09:41.208+0800] {processor.py:157} INFO - Started process (PID=4197) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:09:41.217+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:09:41.220+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:09:41.218+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:09:41.779+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:09:41.790+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:09:41.790+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:09:41.800+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:09:41.800+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:09:41.809+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.606 seconds
[2023-10-26T19:10:12.014+0800] {processor.py:157} INFO - Started process (PID=4223) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:10:12.016+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:10:12.017+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:10:12.016+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:10:12.540+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:10:12.550+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:10:12.550+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:10:12.560+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:10:12.560+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:10:12.570+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.558 seconds
[2023-10-26T19:10:42.677+0800] {processor.py:157} INFO - Started process (PID=4247) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:10:42.679+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:10:42.680+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:10:42.680+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:10:43.168+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:10:43.178+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:10:43.178+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:10:43.190+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:10:43.189+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:10:43.199+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.525 seconds
[2023-10-26T19:11:13.264+0800] {processor.py:157} INFO - Started process (PID=4271) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:11:13.266+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:11:13.267+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:11:13.267+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:11:13.757+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:11:13.769+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:11:13.768+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:11:13.779+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:11:13.778+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:11:13.788+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.525 seconds
[2023-10-26T19:11:43.912+0800] {processor.py:157} INFO - Started process (PID=4296) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:11:43.918+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:11:43.919+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:11:43.918+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:11:44.469+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:11:44.482+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:11:44.481+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:11:44.494+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:11:44.494+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:11:44.504+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.593 seconds
[2023-10-26T19:12:15.417+0800] {processor.py:157} INFO - Started process (PID=4320) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:12:15.426+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:12:15.427+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:12:15.426+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:12:15.925+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:12:15.936+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:12:15.936+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:12:15.956+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:12:15.956+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:12:15.965+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.553 seconds
[2023-10-26T19:12:46.120+0800] {processor.py:157} INFO - Started process (PID=4344) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:12:46.124+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:12:46.125+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:12:46.125+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:12:46.629+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:12:46.640+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:12:46.640+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:12:46.652+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:12:46.652+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:12:46.661+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.545 seconds
[2023-10-26T19:13:16.748+0800] {processor.py:157} INFO - Started process (PID=4368) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:13:16.752+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:13:16.753+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:13:16.753+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:13:17.105+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:13:17.306+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:13:17.305+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:13:17.329+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:13:17.328+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:13:17.342+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.598 seconds
[2023-10-26T19:13:48.253+0800] {processor.py:157} INFO - Started process (PID=4392) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:13:48.257+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:13:48.258+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:13:48.258+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:13:48.763+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:13:48.774+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:13:48.773+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:13:48.784+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:13:48.784+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:13:48.793+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.543 seconds
[2023-10-26T19:14:18.959+0800] {processor.py:157} INFO - Started process (PID=4416) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:14:18.965+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:14:18.966+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:14:18.965+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:14:19.473+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:14:19.484+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:14:19.483+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:14:19.494+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:14:19.494+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:14:19.505+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.550 seconds
[2023-10-26T19:14:50.423+0800] {processor.py:157} INFO - Started process (PID=4440) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:14:50.429+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:14:50.430+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:14:50.430+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:14:50.953+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:14:50.967+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:14:50.967+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:14:50.979+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:14:50.979+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:14:50.988+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.571 seconds
[2023-10-26T19:15:21.104+0800] {processor.py:157} INFO - Started process (PID=4464) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:15:21.114+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:15:21.115+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:15:21.114+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:15:21.705+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:15:21.717+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:15:21.717+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:15:21.728+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:15:21.727+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:15:21.738+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.640 seconds
[2023-10-26T19:15:52.656+0800] {processor.py:157} INFO - Started process (PID=4495) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:15:52.665+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:15:52.666+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:15:52.666+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:15:53.192+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:15:53.203+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:15:53.202+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:15:53.213+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:15:53.213+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:15:53.223+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.574 seconds
[2023-10-26T19:16:23.346+0800] {processor.py:157} INFO - Started process (PID=4519) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:16:23.357+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:16:23.358+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:16:23.358+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:16:23.866+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:16:23.877+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:16:23.876+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:16:23.887+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:16:23.887+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:16:23.897+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.556 seconds
[2023-10-26T19:16:54.030+0800] {processor.py:157} INFO - Started process (PID=4543) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:16:54.038+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:16:54.039+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:16:54.038+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:16:54.578+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:16:54.589+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:16:54.588+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:16:54.602+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:16:54.602+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:16:54.651+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.630 seconds
[2023-10-26T19:17:25.579+0800] {processor.py:157} INFO - Started process (PID=4567) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:17:25.587+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:17:25.589+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:17:25.588+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:17:26.130+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:17:26.142+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:17:26.142+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:17:26.152+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:17:26.152+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:17:26.162+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.588 seconds
[2023-10-26T19:17:56.997+0800] {processor.py:157} INFO - Started process (PID=4591) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:17:57.009+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:17:57.011+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:17:57.010+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:17:57.559+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:17:57.573+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:17:57.573+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:17:57.588+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:17:57.588+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:17:57.606+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.632 seconds
[2023-10-26T19:18:28.485+0800] {processor.py:157} INFO - Started process (PID=4615) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:18:28.511+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:18:28.513+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:18:28.512+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:18:29.019+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:18:29.029+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:18:29.029+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:18:29.040+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:18:29.040+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:18:29.051+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.574 seconds
[2023-10-26T19:19:00.016+0800] {processor.py:157} INFO - Started process (PID=4639) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:19:00.024+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:19:00.027+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:19:00.026+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:19:00.525+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:19:00.537+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:19:00.537+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:19:00.548+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:19:00.548+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:19:00.557+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.553 seconds
[2023-10-26T19:19:31.254+0800] {processor.py:157} INFO - Started process (PID=4663) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:19:31.262+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:19:31.263+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:19:31.263+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:19:31.785+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:19:31.804+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:19:31.803+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:19:31.826+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:19:31.826+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:19:31.840+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.598 seconds
[2023-10-26T19:20:02.849+0800] {processor.py:157} INFO - Started process (PID=4687) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:20:02.858+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:20:02.862+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:20:02.860+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:20:03.374+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:20:03.385+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:20:03.385+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:20:03.397+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:20:03.397+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:20:03.413+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.583 seconds
[2023-10-26T19:20:33.506+0800] {processor.py:157} INFO - Started process (PID=4711) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:20:33.509+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:20:33.510+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:20:33.510+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:20:34.051+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:20:34.064+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:20:34.063+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:20:34.076+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:20:34.076+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:20:34.087+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.589 seconds
[2023-10-26T19:21:04.214+0800] {processor.py:157} INFO - Started process (PID=4734) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:21:04.217+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:21:04.219+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:21:04.218+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:21:04.770+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:21:04.781+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:21:04.781+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:21:04.791+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:21:04.791+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:21:04.800+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.594 seconds
[2023-10-26T19:21:34.941+0800] {processor.py:157} INFO - Started process (PID=4758) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:21:34.944+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:21:34.946+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:21:34.945+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:21:35.842+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:21:35.854+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:21:35.854+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:21:35.866+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:21:35.866+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:21:35.881+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.947 seconds
[2023-10-26T19:22:06.536+0800] {processor.py:157} INFO - Started process (PID=4782) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:22:06.550+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:22:06.552+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:22:06.552+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:22:07.104+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:22:07.116+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:22:07.115+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:22:07.126+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:22:07.126+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:22:07.137+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.623 seconds
[2023-10-26T19:22:37.294+0800] {processor.py:157} INFO - Started process (PID=4806) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:22:37.298+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:22:37.299+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:22:37.299+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:22:37.854+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:22:37.864+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:22:37.864+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:22:37.875+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:22:37.875+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:22:37.884+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.598 seconds
[2023-10-26T19:23:08.893+0800] {processor.py:157} INFO - Started process (PID=4830) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:23:08.896+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:23:08.898+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:23:08.897+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:23:09.457+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:23:09.468+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:23:09.468+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:23:09.480+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:23:09.480+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:23:09.491+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.608 seconds
[2023-10-26T19:23:40.383+0800] {processor.py:157} INFO - Started process (PID=4854) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:23:40.389+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:23:40.391+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:23:40.390+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:23:40.934+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:23:40.946+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:23:40.945+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:23:40.958+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:23:40.958+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:23:40.967+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.593 seconds
[2023-10-26T19:24:11.841+0800] {processor.py:157} INFO - Started process (PID=4878) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:24:11.848+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:24:11.849+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:24:11.849+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:24:12.385+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:24:12.396+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:24:12.396+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:24:12.417+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:24:12.417+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:24:12.433+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.629 seconds
[2023-10-26T19:24:43.365+0800] {processor.py:157} INFO - Started process (PID=4903) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:24:43.372+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:24:43.373+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:24:43.372+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:24:43.919+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:24:43.930+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:24:43.929+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:24:43.940+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:24:43.940+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:24:43.948+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.589 seconds
[2023-10-26T19:25:14.758+0800] {processor.py:157} INFO - Started process (PID=4927) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:25:14.762+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:25:14.763+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:25:14.762+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:25:15.310+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:25:15.325+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:25:15.324+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:25:15.335+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:25:15.335+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:25:15.345+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.593 seconds
[2023-10-26T19:25:46.160+0800] {processor.py:157} INFO - Started process (PID=4951) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:25:46.166+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:25:46.167+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:25:46.167+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:25:46.722+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:25:46.733+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:25:46.733+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:25:46.744+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:25:46.744+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:25:46.754+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.604 seconds
[2023-10-26T19:26:17.662+0800] {processor.py:157} INFO - Started process (PID=4974) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:26:17.668+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:26:17.670+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:26:17.669+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:26:18.222+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:26:18.234+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:26:18.234+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:26:18.245+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:26:18.245+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:26:18.255+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.598 seconds
[2023-10-26T19:26:49.302+0800] {processor.py:157} INFO - Started process (PID=4998) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:26:49.307+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:26:49.308+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:26:49.307+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:26:49.825+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:26:49.836+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:26:49.835+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:26:49.846+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:26:49.846+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:26:49.856+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.565 seconds
[2023-10-26T19:27:20.907+0800] {processor.py:157} INFO - Started process (PID=5022) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:27:20.912+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:27:20.914+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:27:20.913+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:27:21.456+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:27:21.467+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:27:21.466+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:27:21.477+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:27:21.477+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:27:21.486+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.585 seconds
[2023-10-26T19:27:52.093+0800] {processor.py:157} INFO - Started process (PID=5046) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:27:52.101+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:27:52.102+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:27:52.102+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:27:52.664+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:27:52.675+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:27:52.674+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:27:52.687+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:27:52.687+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:27:52.696+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.609 seconds
[2023-10-26T19:28:23.777+0800] {processor.py:157} INFO - Started process (PID=5070) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:28:23.791+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:28:23.792+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:28:23.792+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:28:24.334+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:28:24.345+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:28:24.344+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:28:24.355+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:28:24.355+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:28:24.365+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.605 seconds
[2023-10-26T19:28:54.852+0800] {processor.py:157} INFO - Started process (PID=5094) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:28:54.867+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:28:54.868+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:28:54.868+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:28:55.469+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:28:55.480+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:28:55.480+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:28:55.491+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:28:55.491+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:28:55.503+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.672 seconds
[2023-10-26T19:29:26.060+0800] {processor.py:157} INFO - Started process (PID=5124) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:29:26.069+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:29:26.076+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:29:26.076+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:29:26.618+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:29:26.631+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:29:26.631+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:29:26.642+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:29:26.642+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:29:26.651+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.598 seconds
[2023-10-26T19:29:56.829+0800] {processor.py:157} INFO - Started process (PID=5148) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:29:56.836+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:29:56.843+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:29:56.842+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:29:57.355+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:29:57.366+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:29:57.365+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:29:57.377+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:29:57.377+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:29:57.386+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.562 seconds
[2023-10-26T19:30:27.560+0800] {processor.py:157} INFO - Started process (PID=5172) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:30:27.576+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:30:27.583+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:30:27.582+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:30:28.093+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:30:28.104+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:30:28.103+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:30:28.114+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:30:28.114+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:30:28.123+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.572 seconds
[2023-10-26T19:30:58.260+0800] {processor.py:157} INFO - Started process (PID=5197) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:30:58.276+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:30:58.277+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:30:58.277+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:30:58.821+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:30:58.832+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:30:58.832+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:30:58.842+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:30:58.842+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:30:58.851+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.597 seconds
[2023-10-26T19:31:29.024+0800] {processor.py:157} INFO - Started process (PID=5221) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:31:29.034+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:31:29.041+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:31:29.040+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:31:29.590+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:31:29.607+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:31:29.606+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:31:29.617+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:31:29.617+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:31:29.625+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.608 seconds
[2023-10-26T19:31:59.921+0800] {processor.py:157} INFO - Started process (PID=5244) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:31:59.938+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:31:59.940+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:31:59.939+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:32:00.491+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:32:00.503+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:32:00.503+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:32:00.514+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:32:00.514+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:32:00.523+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.625 seconds
[2023-10-26T19:32:30.765+0800] {processor.py:157} INFO - Started process (PID=5268) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:32:30.774+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:32:30.782+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:32:30.781+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:32:31.322+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:32:31.333+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:32:31.333+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:32:31.344+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:32:31.344+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:32:31.353+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.596 seconds
[2023-10-26T19:33:01.581+0800] {processor.py:157} INFO - Started process (PID=5292) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:33:01.594+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:33:01.596+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:33:01.595+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:33:02.178+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:33:02.191+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:33:02.190+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:33:02.203+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:33:02.203+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:33:02.215+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.657 seconds
[2023-10-26T19:33:32.853+0800] {processor.py:157} INFO - Started process (PID=5315) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:33:32.868+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:33:32.869+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:33:32.868+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:33:33.487+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:33:33.502+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:33:33.501+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:33:33.523+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:33:33.523+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:33:33.535+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.701 seconds
[2023-10-26T19:34:04.140+0800] {processor.py:157} INFO - Started process (PID=5339) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:34:04.162+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:34:04.164+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:34:04.163+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:34:04.751+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:34:04.763+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:34:04.762+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:34:04.777+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:34:04.777+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:34:04.786+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.663 seconds
[2023-10-26T19:34:35.487+0800] {processor.py:157} INFO - Started process (PID=5363) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:34:35.491+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:34:35.493+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:34:35.492+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:34:36.035+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:34:36.047+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:34:36.046+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:34:36.061+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:34:36.061+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:34:36.077+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.599 seconds
[2023-10-26T19:35:06.641+0800] {processor.py:157} INFO - Started process (PID=5387) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:35:06.647+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:35:06.652+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:35:06.650+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:35:07.278+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:35:07.300+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:35:07.299+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:35:07.317+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:35:07.317+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:35:07.330+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.696 seconds
[2023-10-26T19:35:37.899+0800] {processor.py:157} INFO - Started process (PID=5411) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:35:37.906+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:35:37.907+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:35:37.907+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:35:38.479+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:35:38.491+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:35:38.491+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:35:38.505+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:35:38.505+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:35:38.518+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.639 seconds
[2023-10-26T19:36:09.094+0800] {processor.py:157} INFO - Started process (PID=5439) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:36:09.101+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:36:09.103+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:36:09.102+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:36:09.740+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:36:09.755+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:36:09.754+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:36:09.768+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:36:09.768+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:36:09.786+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.710 seconds
[2023-10-26T19:36:39.939+0800] {processor.py:157} INFO - Started process (PID=5463) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:36:39.944+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:36:39.945+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:36:39.945+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:36:40.578+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:36:40.591+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:36:40.591+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:36:40.610+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:36:40.610+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:36:40.623+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.691 seconds
[2023-10-26T19:37:10.802+0800] {processor.py:157} INFO - Started process (PID=5487) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:37:10.805+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:37:10.806+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:37:10.806+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:37:11.446+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:37:11.461+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:37:11.461+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:37:11.475+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:37:11.474+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:37:11.486+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.687 seconds
[2023-10-26T19:37:41.747+0800] {processor.py:157} INFO - Started process (PID=5511) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:37:41.751+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:37:41.753+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:37:41.753+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:37:42.773+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:37:42.792+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:37:42.790+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:37:42.813+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:37:42.813+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:37:42.825+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.084 seconds
[2023-10-26T19:38:13.522+0800] {processor.py:157} INFO - Started process (PID=5543) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:38:13.527+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:38:13.528+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:38:13.527+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:38:13.987+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:38:13.999+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:38:13.999+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:38:14.011+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:38:14.011+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:38:14.020+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.504 seconds
[2023-10-26T19:38:44.470+0800] {processor.py:157} INFO - Started process (PID=5566) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:38:44.480+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:38:44.488+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:38:44.485+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:38:45.408+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:38:45.423+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:38:45.423+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:38:45.438+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:38:45.438+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:38:45.450+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.987 seconds
[2023-10-26T19:39:16.412+0800] {processor.py:157} INFO - Started process (PID=5590) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:39:16.416+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:39:16.418+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:39:16.418+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:39:17.263+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:39:17.281+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:39:17.280+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:39:17.299+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:39:17.299+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:39:17.316+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.919 seconds
[2023-10-26T19:39:48.227+0800] {processor.py:157} INFO - Started process (PID=5614) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:39:48.235+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:39:48.238+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:39:48.237+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:39:48.835+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:39:48.849+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:39:48.848+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:39:48.862+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:39:48.862+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:39:48.880+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.658 seconds
[2023-10-26T19:40:19.530+0800] {processor.py:157} INFO - Started process (PID=5638) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:40:19.537+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:40:19.538+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:40:19.537+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:40:20.116+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:40:20.136+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:40:20.136+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:40:20.149+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:40:20.149+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:40:20.158+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.636 seconds
[2023-10-26T19:40:50.783+0800] {processor.py:157} INFO - Started process (PID=5662) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:40:50.791+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:40:50.796+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:40:50.793+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:40:51.306+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:40:51.318+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:40:51.318+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:40:51.335+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:40:51.335+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:40:51.361+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.583 seconds
[2023-10-26T19:41:21.701+0800] {processor.py:157} INFO - Started process (PID=5685) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:41:21.709+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:41:21.711+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:41:21.710+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:41:22.244+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:41:22.257+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:41:22.257+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:41:22.270+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:41:22.270+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:41:22.279+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.588 seconds
[2023-10-26T19:41:52.483+0800] {processor.py:157} INFO - Started process (PID=5710) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:41:52.491+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:41:52.492+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:41:52.491+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:41:52.996+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:41:53.008+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:41:53.008+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:41:53.020+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:41:53.020+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:41:53.029+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.555 seconds
[2023-10-26T19:42:23.123+0800] {processor.py:157} INFO - Started process (PID=5734) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:42:23.128+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:42:23.130+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:42:23.129+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:42:23.587+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:42:23.599+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:42:23.599+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:42:23.612+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:42:23.612+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:42:23.623+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.508 seconds
[2023-10-26T19:42:53.920+0800] {processor.py:157} INFO - Started process (PID=5758) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:42:53.929+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:42:53.931+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:42:53.930+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:42:54.480+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:42:54.491+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:42:54.491+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:42:54.503+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:42:54.503+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:42:54.520+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.607 seconds
[2023-10-26T19:43:25.181+0800] {processor.py:157} INFO - Started process (PID=5781) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:43:25.187+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:43:25.189+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:43:25.188+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:43:25.715+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:43:25.726+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:43:25.725+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:43:25.751+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:43:25.751+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:43:25.761+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.602 seconds
[2023-10-26T19:43:56.416+0800] {processor.py:157} INFO - Started process (PID=5805) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:43:56.423+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:43:56.425+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:43:56.424+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:43:56.998+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:43:57.010+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:43:57.009+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:43:57.024+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:43:57.024+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:43:57.034+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.628 seconds
[2023-10-26T19:44:27.728+0800] {processor.py:157} INFO - Started process (PID=5829) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:44:27.734+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:44:27.736+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:44:27.735+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:44:28.307+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:44:28.319+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:44:28.319+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:44:28.335+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:44:28.335+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:44:28.346+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.626 seconds
[2023-10-26T19:44:59.000+0800] {processor.py:157} INFO - Started process (PID=5854) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:44:59.006+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:44:59.007+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:44:59.007+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:44:59.638+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:44:59.658+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:44:59.657+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:44:59.677+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:44:59.677+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:44:59.690+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.697 seconds
[2023-10-26T19:45:30.390+0800] {processor.py:157} INFO - Started process (PID=5887) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:45:30.395+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:45:30.396+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:45:30.396+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:45:31.226+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:45:31.246+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:45:31.244+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:45:31.280+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:45:31.280+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:45:31.295+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.910 seconds
[2023-10-26T19:46:01.994+0800] {processor.py:157} INFO - Started process (PID=5911) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:46:02.004+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:46:02.005+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:46:02.005+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:46:02.626+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:46:02.638+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:46:02.638+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:46:02.651+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:46:02.651+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:46:02.661+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.688 seconds
[2023-10-26T19:46:33.362+0800] {processor.py:157} INFO - Started process (PID=5935) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:46:33.372+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:46:33.374+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:46:33.373+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:46:34.007+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:46:34.038+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:46:34.037+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:46:34.072+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:46:34.071+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:46:34.092+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.736 seconds
[2023-10-26T19:47:04.228+0800] {processor.py:157} INFO - Started process (PID=5959) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:47:04.237+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:47:04.239+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:47:04.238+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:47:04.865+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:47:04.875+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:47:04.875+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:47:04.887+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:47:04.887+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:47:04.897+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.676 seconds
[2023-10-26T19:47:35.500+0800] {processor.py:157} INFO - Started process (PID=5984) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:47:35.507+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:47:35.510+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:47:35.509+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:47:36.083+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:47:36.098+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:47:36.097+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:47:36.110+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:47:36.110+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:47:36.121+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.640 seconds
[2023-10-26T19:48:06.766+0800] {processor.py:157} INFO - Started process (PID=6008) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:48:06.772+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:48:06.773+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:48:06.773+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:48:07.372+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:48:07.385+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:48:07.384+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:48:07.396+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:48:07.396+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:48:07.407+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.651 seconds
[2023-10-26T19:48:38.041+0800] {processor.py:157} INFO - Started process (PID=6032) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:48:38.048+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:48:38.049+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:48:38.048+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:48:38.644+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:48:38.657+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:48:38.657+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:48:38.669+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:48:38.669+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:48:38.680+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.645 seconds
[2023-10-26T19:49:09.117+0800] {processor.py:157} INFO - Started process (PID=6056) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:49:09.122+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:49:09.124+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:49:09.123+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:49:09.751+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:49:09.765+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:49:09.765+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:49:09.787+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:49:09.787+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:49:09.798+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.697 seconds
[2023-10-26T19:49:40.300+0800] {processor.py:157} INFO - Started process (PID=6081) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:49:40.309+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:49:40.318+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:49:40.314+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:49:40.851+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:49:40.864+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:49:40.864+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:49:40.877+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:49:40.877+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:49:40.887+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.596 seconds
[2023-10-26T19:50:11.070+0800] {processor.py:157} INFO - Started process (PID=6106) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:50:11.076+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:50:11.077+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:50:11.076+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:50:11.608+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:50:11.619+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:50:11.618+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:50:11.629+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:50:11.629+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:50:11.640+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.577 seconds
[2023-10-26T19:50:42.231+0800] {processor.py:157} INFO - Started process (PID=6130) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:50:42.238+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:50:42.239+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:50:42.239+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:50:42.781+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:50:42.793+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:50:42.792+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:50:42.805+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:50:42.805+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:50:42.815+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.592 seconds
[2023-10-26T19:51:12.963+0800] {processor.py:157} INFO - Started process (PID=6154) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:51:12.968+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:51:12.969+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:51:12.969+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:51:13.536+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:51:13.546+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:51:13.546+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:51:13.560+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:51:13.559+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:51:13.569+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.615 seconds
[2023-10-26T19:51:44.254+0800] {processor.py:157} INFO - Started process (PID=6178) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:51:44.258+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:51:44.260+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:51:44.259+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:51:44.810+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:51:44.821+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:51:44.821+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:51:44.835+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:51:44.834+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:51:44.844+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.599 seconds
[2023-10-26T19:52:15.586+0800] {processor.py:157} INFO - Started process (PID=6202) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:52:15.591+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:52:15.593+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:52:15.592+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:52:16.136+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:52:16.147+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:52:16.146+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:52:16.157+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:52:16.157+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:52:16.168+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.604 seconds
[2023-10-26T19:52:46.737+0800] {processor.py:157} INFO - Started process (PID=6226) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:52:46.744+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:52:46.746+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:52:46.745+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:52:47.300+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:52:47.310+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:52:47.310+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:52:47.321+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:52:47.321+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:52:47.331+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.600 seconds
[2023-10-26T19:53:17.581+0800] {processor.py:157} INFO - Started process (PID=6251) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:53:17.588+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:53:17.589+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:53:17.589+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:53:18.153+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:53:18.164+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:53:18.163+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:53:18.174+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:53:18.174+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:53:18.184+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.609 seconds
[2023-10-26T19:53:48.795+0800] {processor.py:157} INFO - Started process (PID=6274) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:53:48.805+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:53:48.807+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:53:48.806+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:53:49.366+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:53:49.376+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:53:49.376+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:53:49.387+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:53:49.387+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:53:49.397+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.625 seconds
[2023-10-26T19:54:20.067+0800] {processor.py:157} INFO - Started process (PID=6298) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:54:20.079+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:54:20.089+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:54:20.083+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:54:20.627+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:54:20.638+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:54:20.638+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:54:20.650+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:54:20.650+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:54:20.661+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.604 seconds
[2023-10-26T19:54:51.236+0800] {processor.py:157} INFO - Started process (PID=6323) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:54:51.247+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:54:51.248+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:54:51.247+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:54:51.785+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:54:51.795+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:54:51.795+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:54:51.807+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:54:51.807+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:54:51.819+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.589 seconds
[2023-10-26T19:55:22.042+0800] {processor.py:157} INFO - Started process (PID=6347) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:55:22.046+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:55:22.048+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:55:22.047+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:55:22.586+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:55:22.599+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:55:22.598+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:55:22.609+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:55:22.609+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:55:22.619+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.598 seconds
[2023-10-26T19:55:53.301+0800] {processor.py:157} INFO - Started process (PID=6372) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:55:53.308+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:55:53.310+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:55:53.309+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:55:53.836+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:55:53.847+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:55:53.847+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:55:53.859+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:55:53.859+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:55:53.871+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.577 seconds
[2023-10-26T19:56:24.539+0800] {processor.py:157} INFO - Started process (PID=6396) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:56:24.546+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:56:24.547+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:56:24.546+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:56:25.102+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:56:25.115+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:56:25.115+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:56:25.129+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:56:25.128+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:56:25.139+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.608 seconds
[2023-10-26T19:56:55.816+0800] {processor.py:157} INFO - Started process (PID=6420) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:56:55.824+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:56:55.826+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:56:55.825+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:56:56.394+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:56:56.406+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:56:56.406+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:56:56.417+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:56:56.417+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:56:56.427+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.620 seconds
[2023-10-26T19:57:27.193+0800] {processor.py:157} INFO - Started process (PID=6444) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:57:27.198+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:57:27.200+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:57:27.199+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:57:27.746+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:57:27.758+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:57:27.758+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:57:27.769+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:57:27.769+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:57:27.780+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.593 seconds
[2023-10-26T19:57:58.429+0800] {processor.py:157} INFO - Started process (PID=6468) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:57:58.434+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:57:58.435+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:57:58.435+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:57:58.974+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:57:58.985+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:57:58.985+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:57:59.003+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:57:59.003+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:57:59.016+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.615 seconds
[2023-10-26T19:58:29.568+0800] {processor.py:157} INFO - Started process (PID=6492) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:58:29.575+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:58:29.591+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:58:29.583+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:58:30.151+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:58:30.162+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:58:30.162+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:58:30.173+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:58:30.173+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:58:30.186+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.626 seconds
[2023-10-26T19:59:00.824+0800] {processor.py:157} INFO - Started process (PID=6519) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:59:00.831+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:59:00.832+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:59:00.831+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:59:01.388+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:59:01.399+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:59:01.399+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:59:01.409+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:59:01.409+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:59:01.419+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.608 seconds
[2023-10-26T19:59:31.540+0800] {processor.py:157} INFO - Started process (PID=6545) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:59:31.543+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T19:59:31.543+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:59:31.543+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:59:32.053+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T19:59:32.064+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:59:32.063+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T19:59:32.074+0800] {logging_mixin.py:151} INFO - [2023-10-26T19:59:32.074+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T19:59:32.092+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.555 seconds
[2023-10-26T20:00:02.169+0800] {processor.py:157} INFO - Started process (PID=6569) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:00:02.181+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:00:02.181+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:00:02.181+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:00:02.721+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:00:02.732+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:00:02.732+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:00:02.742+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:00:02.742+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:00:02.752+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.584 seconds
[2023-10-26T20:00:32.792+0800] {processor.py:157} INFO - Started process (PID=6592) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:00:32.796+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:00:32.797+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:00:32.796+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:00:33.317+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:00:33.328+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:00:33.328+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:00:33.338+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:00:33.338+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:00:33.348+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.561 seconds
[2023-10-26T20:01:03.430+0800] {processor.py:157} INFO - Started process (PID=6616) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:01:03.431+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:01:03.432+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:01:03.432+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:01:04.008+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:01:04.019+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:01:04.019+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:01:04.031+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:01:04.031+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:01:04.051+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.623 seconds
[2023-10-26T20:01:34.833+0800] {processor.py:157} INFO - Started process (PID=6640) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:01:34.839+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:01:34.840+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:01:34.840+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:01:35.381+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:01:35.392+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:01:35.391+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:01:35.405+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:01:35.405+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:01:35.416+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.587 seconds
[2023-10-26T20:02:05.561+0800] {processor.py:157} INFO - Started process (PID=6672) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:02:05.570+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:02:05.571+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:02:05.571+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:02:06.122+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:02:06.133+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:02:06.133+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:02:06.145+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:02:06.145+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:02:06.154+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.599 seconds
[2023-10-26T20:02:36.243+0800] {processor.py:157} INFO - Started process (PID=6695) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:02:36.255+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:02:36.256+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:02:36.255+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:02:36.792+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:02:36.804+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:02:36.803+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:02:36.815+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:02:36.815+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:02:36.826+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.588 seconds
[2023-10-26T20:03:06.902+0800] {processor.py:157} INFO - Started process (PID=6719) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:03:06.911+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:03:06.912+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:03:06.911+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:03:07.432+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:03:07.444+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:03:07.443+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:03:07.454+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:03:07.454+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:03:07.463+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.568 seconds
[2023-10-26T20:03:38.366+0800] {processor.py:157} INFO - Started process (PID=6743) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:03:38.379+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:03:38.380+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:03:38.380+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:03:38.906+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:03:38.917+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:03:38.917+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:03:38.928+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:03:38.928+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:03:38.938+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.577 seconds
[2023-10-26T20:04:09.106+0800] {processor.py:157} INFO - Started process (PID=6767) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:04:09.109+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:04:09.111+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:04:09.110+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:04:09.669+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:04:09.681+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:04:09.681+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:04:09.693+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:04:09.693+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:04:09.703+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.602 seconds
[2023-10-26T20:04:39.815+0800] {processor.py:157} INFO - Started process (PID=6791) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:04:39.820+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:04:39.821+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:04:39.820+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:04:40.359+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:04:40.370+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:04:40.370+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:04:40.381+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:04:40.381+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:04:40.390+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.579 seconds
[2023-10-26T20:05:11.357+0800] {processor.py:157} INFO - Started process (PID=6815) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:05:11.361+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:05:11.362+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:05:11.361+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:05:11.908+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:05:11.918+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:05:11.918+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:05:11.929+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:05:11.929+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:05:11.940+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.588 seconds
[2023-10-26T20:05:42.853+0800] {processor.py:157} INFO - Started process (PID=6839) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:05:42.861+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:05:42.862+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:05:42.862+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:05:43.398+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:05:43.409+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:05:43.409+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:05:43.420+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:05:43.420+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:05:43.435+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.588 seconds
[2023-10-26T20:06:13.551+0800] {processor.py:157} INFO - Started process (PID=6863) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:06:13.560+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:06:13.561+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:06:13.560+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:06:14.070+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:06:14.080+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:06:14.080+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:06:14.091+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:06:14.091+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:06:14.101+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.555 seconds
[2023-10-26T20:06:44.148+0800] {processor.py:157} INFO - Started process (PID=6887) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:06:44.156+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:06:44.157+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:06:44.157+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:06:44.691+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:06:44.702+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:06:44.702+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:06:44.714+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:06:44.714+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:06:44.723+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.578 seconds
[2023-10-26T20:07:14.787+0800] {processor.py:157} INFO - Started process (PID=6911) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:07:14.797+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:07:14.798+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:07:14.798+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:07:15.350+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:07:15.362+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:07:15.361+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:07:15.372+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:07:15.372+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:07:15.382+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.600 seconds
[2023-10-26T20:07:46.295+0800] {processor.py:157} INFO - Started process (PID=6935) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:07:46.318+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:07:46.323+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:07:46.320+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:07:46.842+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:07:46.855+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:07:46.855+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:07:46.868+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:07:46.868+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:07:46.879+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.594 seconds
[2023-10-26T20:08:16.961+0800] {processor.py:157} INFO - Started process (PID=6959) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:08:16.970+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:08:16.971+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:08:16.971+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:08:17.518+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:08:17.529+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:08:17.529+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:08:17.544+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:08:17.544+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:08:17.557+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.603 seconds
[2023-10-26T20:08:48.538+0800] {processor.py:157} INFO - Started process (PID=6983) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:08:48.546+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:08:48.547+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:08:48.546+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:08:49.389+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:08:49.414+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:08:49.413+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:08:49.432+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:08:49.432+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:08:49.443+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.913 seconds
[2023-10-26T20:09:20.052+0800] {processor.py:157} INFO - Started process (PID=7007) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:09:20.063+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:09:20.064+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:09:20.064+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:09:20.589+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:09:20.599+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:09:20.599+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:09:20.609+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:09:20.609+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:09:20.624+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.579 seconds
[2023-10-26T20:09:50.713+0800] {processor.py:157} INFO - Started process (PID=7031) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:09:50.718+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:09:50.719+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:09:50.719+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:09:51.260+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:09:51.271+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:09:51.271+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:09:51.282+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:09:51.282+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:09:51.291+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.585 seconds
[2023-10-26T20:10:22.284+0800] {processor.py:157} INFO - Started process (PID=7056) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:10:22.290+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:10:22.292+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:10:22.291+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:10:22.835+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:10:22.848+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:10:22.847+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:10:22.858+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:10:22.858+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:10:22.867+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.590 seconds
[2023-10-26T20:10:53.885+0800] {processor.py:157} INFO - Started process (PID=7080) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:10:53.900+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:10:53.901+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:10:53.901+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:10:54.454+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:10:54.472+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:10:54.472+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:10:54.483+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:10:54.483+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:10:54.492+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.622 seconds
[2023-10-26T20:11:25.404+0800] {processor.py:157} INFO - Started process (PID=7104) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:11:25.415+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:11:25.416+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:11:25.415+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:11:25.940+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:11:25.955+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:11:25.955+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:11:25.965+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:11:25.965+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:11:25.976+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.584 seconds
[2023-10-26T20:11:56.146+0800] {processor.py:157} INFO - Started process (PID=7128) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:11:56.156+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:11:56.157+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:11:56.157+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:11:56.712+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:11:56.724+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:11:56.724+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:11:56.735+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:11:56.735+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:11:56.744+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.605 seconds
[2023-10-26T20:12:26.865+0800] {processor.py:157} INFO - Started process (PID=7152) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:12:26.896+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:12:26.897+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:12:26.897+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:12:27.446+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:12:27.463+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:12:27.463+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:12:27.474+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:12:27.474+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:12:27.486+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.645 seconds
[2023-10-26T20:12:58.342+0800] {processor.py:157} INFO - Started process (PID=7176) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:12:58.346+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:12:58.347+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:12:58.346+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:12:58.880+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:12:58.892+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:12:58.892+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:12:58.903+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:12:58.903+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:12:58.927+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.603 seconds
[2023-10-26T20:13:29.920+0800] {processor.py:157} INFO - Started process (PID=7201) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:13:29.923+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:13:29.924+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:13:29.924+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:13:30.443+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:13:30.454+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:13:30.454+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:13:30.464+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:13:30.464+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:13:30.476+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.562 seconds
[2023-10-26T20:14:01.536+0800] {processor.py:157} INFO - Started process (PID=7225) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:14:01.547+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:14:01.549+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:14:01.548+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:14:02.109+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:14:02.120+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:14:02.120+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:14:02.131+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:14:02.131+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:14:02.141+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.616 seconds
[2023-10-26T20:14:33.242+0800] {processor.py:157} INFO - Started process (PID=7250) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:14:33.245+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:14:33.248+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:14:33.248+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:14:33.787+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:14:33.798+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:14:33.797+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:14:33.809+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:14:33.809+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:14:33.823+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.588 seconds
[2023-10-26T20:15:04.093+0800] {processor.py:157} INFO - Started process (PID=7274) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:15:04.101+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:15:04.102+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:15:04.102+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:15:04.680+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:15:04.690+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:15:04.690+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:15:04.701+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:15:04.701+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:15:04.711+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.635 seconds
[2023-10-26T20:15:34.926+0800] {processor.py:157} INFO - Started process (PID=7298) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:15:34.937+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:15:34.946+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:15:34.945+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:15:35.490+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:15:35.503+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:15:35.502+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:15:35.514+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:15:35.513+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:15:35.523+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.603 seconds
[2023-10-26T20:16:05.791+0800] {processor.py:157} INFO - Started process (PID=7322) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:16:05.811+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:16:05.813+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:16:05.812+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:16:06.359+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:16:06.369+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:16:06.369+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:16:06.380+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:16:06.380+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:16:06.390+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.606 seconds
[2023-10-26T20:16:36.793+0800] {processor.py:157} INFO - Started process (PID=7345) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:16:36.806+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:16:36.814+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:16:36.814+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:16:37.324+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:16:37.342+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:16:37.342+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:16:37.354+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:16:37.354+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:16:37.364+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.579 seconds
[2023-10-26T20:17:07.814+0800] {processor.py:157} INFO - Started process (PID=7369) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:17:07.826+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:17:07.834+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:17:07.834+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:17:08.380+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:17:08.391+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:17:08.391+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:17:08.405+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:17:08.405+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:17:08.419+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.612 seconds
[2023-10-26T20:17:38.936+0800] {processor.py:157} INFO - Started process (PID=7394) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:17:38.947+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:17:38.957+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:17:38.957+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:17:39.493+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:17:39.507+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:17:39.507+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:17:39.522+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:17:39.522+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:17:39.531+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.602 seconds
[2023-10-26T20:18:09.743+0800] {processor.py:157} INFO - Started process (PID=7418) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:18:09.758+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:18:09.767+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:18:09.766+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:18:10.362+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:18:10.383+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:18:10.383+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:18:10.396+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:18:10.396+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:18:10.407+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.676 seconds
[2023-10-26T20:18:40.791+0800] {processor.py:157} INFO - Started process (PID=7448) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:18:40.801+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:18:40.806+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:18:40.805+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:18:41.367+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:18:41.379+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:18:41.379+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:18:41.390+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:18:41.390+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:18:41.399+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.615 seconds
[2023-10-26T20:19:11.605+0800] {processor.py:157} INFO - Started process (PID=7472) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:19:11.616+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:19:11.624+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:19:11.623+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:19:12.180+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:19:12.191+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:19:12.190+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:19:12.207+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:19:12.207+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:19:12.216+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.615 seconds
[2023-10-26T20:19:42.408+0800] {processor.py:157} INFO - Started process (PID=7496) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:19:42.413+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:19:42.419+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:19:42.417+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:19:42.950+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:19:42.961+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:19:42.961+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:19:42.972+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:19:42.972+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:19:42.982+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.581 seconds
[2023-10-26T20:20:13.230+0800] {processor.py:157} INFO - Started process (PID=7520) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:20:13.240+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:20:13.243+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:20:13.242+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:20:13.779+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:20:13.796+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:20:13.796+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:20:13.808+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:20:13.807+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:20:13.817+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.595 seconds
[2023-10-26T20:20:44.055+0800] {processor.py:157} INFO - Started process (PID=7544) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:20:44.060+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:20:44.063+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:20:44.062+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:20:44.582+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:20:44.602+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:20:44.602+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:20:44.612+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:20:44.612+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:20:44.622+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.577 seconds
[2023-10-26T20:21:14.883+0800] {processor.py:157} INFO - Started process (PID=7568) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:21:14.889+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:21:14.890+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:21:14.890+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:21:15.446+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:21:15.456+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:21:15.456+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:21:15.473+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:21:15.473+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:21:15.487+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.611 seconds
[2023-10-26T20:21:45.773+0800] {processor.py:157} INFO - Started process (PID=7592) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:21:45.782+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:21:45.782+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:21:45.782+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:21:46.317+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:21:46.329+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:21:46.329+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:21:46.340+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:21:46.339+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:21:46.349+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.591 seconds
[2023-10-26T20:22:16.560+0800] {processor.py:157} INFO - Started process (PID=7616) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:22:16.567+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:22:16.569+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:22:16.569+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:22:17.197+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:22:17.208+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:22:17.207+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:22:17.218+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:22:17.218+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:22:17.230+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.676 seconds
[2023-10-26T20:22:47.376+0800] {processor.py:157} INFO - Started process (PID=7640) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:22:47.384+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:22:47.387+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:22:47.387+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:22:47.929+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:22:47.941+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:22:47.941+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:22:47.952+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:22:47.951+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:22:47.962+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.607 seconds
[2023-10-26T20:23:18.151+0800] {processor.py:157} INFO - Started process (PID=7664) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:23:18.158+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:23:18.160+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:23:18.160+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:23:18.702+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:23:18.716+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:23:18.716+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:23:18.729+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:23:18.729+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:23:18.739+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.595 seconds
[2023-10-26T20:23:48.890+0800] {processor.py:157} INFO - Started process (PID=7688) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:23:48.898+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:23:48.904+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:23:48.904+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:23:49.441+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:23:49.453+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:23:49.452+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:23:49.464+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:23:49.464+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:23:49.480+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.596 seconds
[2023-10-26T20:24:19.659+0800] {processor.py:157} INFO - Started process (PID=7712) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:24:19.668+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:24:19.675+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:24:19.675+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:24:20.217+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:24:20.229+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:24:20.228+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:24:20.241+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:24:20.241+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:24:20.251+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.621 seconds
[2023-10-26T20:24:50.592+0800] {processor.py:157} INFO - Started process (PID=7737) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:24:50.600+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:24:50.601+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:24:50.600+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:24:51.201+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:24:51.219+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:24:51.218+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:24:51.240+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:24:51.240+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:24:51.252+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.669 seconds
[2023-10-26T20:25:21.893+0800] {processor.py:157} INFO - Started process (PID=7761) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:25:21.902+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:25:21.903+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:25:21.902+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:25:22.442+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:25:22.452+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:25:22.452+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:25:22.462+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:25:22.462+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:25:22.472+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.587 seconds
[2023-10-26T20:25:53.083+0800] {processor.py:157} INFO - Started process (PID=7785) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:25:53.093+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:25:53.098+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:25:53.097+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:25:53.638+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:25:53.651+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:25:53.650+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:25:53.668+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:25:53.668+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:25:53.718+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.642 seconds
[2023-10-26T20:26:24.432+0800] {processor.py:157} INFO - Started process (PID=7809) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:26:24.443+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:26:24.445+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:26:24.444+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:26:25.071+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:26:25.082+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:26:25.082+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:26:25.094+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:26:25.094+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:26:25.107+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.682 seconds
[2023-10-26T20:26:55.698+0800] {processor.py:157} INFO - Started process (PID=7833) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:26:55.723+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:26:55.724+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:26:55.723+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:26:56.227+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:26:56.268+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:26:56.267+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:26:56.283+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:26:56.283+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:26:56.293+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.602 seconds
[2023-10-26T20:27:26.565+0800] {processor.py:157} INFO - Started process (PID=7857) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:27:26.576+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:27:26.584+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:27:26.584+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:27:27.113+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:27:27.125+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:27:27.124+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:27:27.136+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:27:27.136+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:27:27.148+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.588 seconds
[2023-10-26T20:27:57.447+0800] {processor.py:157} INFO - Started process (PID=7881) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:27:57.466+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:27:57.468+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:27:57.467+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:27:58.842+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:27:58.858+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:27:58.858+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:27:58.883+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:27:58.883+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:27:58.895+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.460 seconds
[2023-10-26T20:28:29.013+0800] {processor.py:157} INFO - Started process (PID=7905) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:28:29.034+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:28:29.036+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:28:29.035+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:28:29.906+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:28:29.948+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:28:29.947+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:28:30.000+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:28:29.999+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:28:30.024+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.019 seconds
[2023-10-26T20:29:00.746+0800] {processor.py:157} INFO - Started process (PID=7935) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:29:00.753+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:29:00.753+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:29:00.753+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:29:01.311+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:29:01.325+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:29:01.324+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:29:01.339+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:29:01.338+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:29:01.350+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.606 seconds
[2023-10-26T20:29:31.980+0800] {processor.py:157} INFO - Started process (PID=7959) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:29:31.988+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:29:31.989+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:29:31.988+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:29:32.732+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:29:32.784+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:29:32.784+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:29:32.803+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:29:32.803+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:29:32.817+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.839 seconds
[2023-10-26T20:30:02.910+0800] {processor.py:157} INFO - Started process (PID=7984) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:30:02.919+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:30:02.921+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:30:02.920+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:30:03.406+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:30:03.424+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:30:03.424+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:30:03.447+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:30:03.447+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:30:03.458+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.555 seconds
[2023-10-26T20:30:34.040+0800] {processor.py:157} INFO - Started process (PID=8014) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:30:34.051+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:30:34.052+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:30:34.051+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:30:34.655+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:30:34.666+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:30:34.666+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:30:34.678+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:30:34.678+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:30:34.688+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.654 seconds
[2023-10-26T20:31:05.476+0800] {processor.py:157} INFO - Started process (PID=8038) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:31:05.487+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:31:05.488+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:31:05.487+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:31:06.085+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:31:06.098+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:31:06.098+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:31:06.111+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:31:06.111+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:31:06.128+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.667 seconds
[2023-10-26T20:31:36.885+0800] {processor.py:157} INFO - Started process (PID=8062) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:31:36.890+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:31:36.891+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:31:36.890+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:31:37.528+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:31:37.555+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:31:37.555+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:31:37.580+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:31:37.580+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:31:37.644+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.771 seconds
[2023-10-26T20:32:08.069+0800] {processor.py:157} INFO - Started process (PID=8103) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:32:08.072+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:32:08.073+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:32:08.073+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:32:08.905+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:32:08.924+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:32:08.923+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:32:08.975+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:32:08.975+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:32:08.999+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.943 seconds
[2023-10-26T20:32:39.773+0800] {processor.py:157} INFO - Started process (PID=8138) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:32:39.776+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:32:39.778+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:32:39.777+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:32:40.432+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:32:40.446+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:32:40.446+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:32:40.466+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:32:40.466+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:32:40.476+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.717 seconds
[2023-10-26T20:33:11.514+0800] {processor.py:157} INFO - Started process (PID=8168) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:33:11.517+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:33:11.519+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:33:11.518+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:33:12.060+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:33:12.070+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:33:12.070+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:33:12.081+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:33:12.081+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:33:12.094+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.586 seconds
[2023-10-26T20:33:42.220+0800] {processor.py:157} INFO - Started process (PID=8197) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:33:42.229+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:33:42.230+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:33:42.229+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:33:42.858+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:33:42.875+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:33:42.875+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:33:42.896+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:33:42.896+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:33:42.910+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.701 seconds
[2023-10-26T20:34:13.580+0800] {processor.py:157} INFO - Started process (PID=8232) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:34:13.589+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:34:13.590+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:34:13.590+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:34:14.361+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:34:14.457+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:34:14.455+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:34:14.489+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:34:14.488+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:34:14.519+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.945 seconds
[2023-10-26T20:34:45.226+0800] {processor.py:157} INFO - Started process (PID=8273) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:34:45.233+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:34:45.234+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:34:45.233+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:34:45.919+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:34:45.933+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:34:45.933+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:34:45.952+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:34:45.952+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:34:45.966+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.745 seconds
[2023-10-26T20:35:16.859+0800] {processor.py:157} INFO - Started process (PID=8308) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:35:16.868+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:35:16.870+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:35:16.869+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:35:17.593+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:35:17.607+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:35:17.606+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:35:17.622+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:35:17.622+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:35:17.636+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.793 seconds
[2023-10-26T20:35:48.012+0800] {processor.py:157} INFO - Started process (PID=8338) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:35:48.026+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:35:48.028+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:35:48.027+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:35:48.680+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:35:48.704+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:35:48.704+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:35:48.723+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:35:48.723+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:35:48.739+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.732 seconds
[2023-10-26T20:36:19.366+0800] {processor.py:157} INFO - Started process (PID=8368) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:36:19.375+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:36:19.376+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:36:19.376+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:36:19.985+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:36:19.996+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:36:19.996+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:36:20.009+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:36:20.009+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:36:20.019+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.671 seconds
[2023-10-26T20:36:50.868+0800] {processor.py:157} INFO - Started process (PID=8398) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:36:50.879+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:36:50.880+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:36:50.879+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:36:51.490+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:36:51.503+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:36:51.503+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:36:51.526+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:36:51.526+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:36:51.537+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.675 seconds
[2023-10-26T20:37:21.695+0800] {processor.py:157} INFO - Started process (PID=8428) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:37:21.702+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:37:21.704+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:37:21.704+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:37:22.323+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:37:22.336+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:37:22.335+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:37:22.349+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:37:22.349+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:37:22.358+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.685 seconds
[2023-10-26T20:37:53.334+0800] {processor.py:157} INFO - Started process (PID=8458) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:37:53.350+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:37:53.352+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:37:53.351+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:37:53.906+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:37:53.945+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:37:53.944+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:37:53.961+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:37:53.961+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:37:54.006+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.682 seconds
[2023-10-26T20:38:24.938+0800] {processor.py:157} INFO - Started process (PID=8488) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:38:24.951+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:38:24.952+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:38:24.952+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:38:25.504+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:38:25.515+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:38:25.514+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:38:25.524+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:38:25.524+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:38:25.534+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.604 seconds
[2023-10-26T20:38:56.473+0800] {processor.py:157} INFO - Started process (PID=8518) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:38:56.484+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:38:56.485+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:38:56.484+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:38:57.126+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:38:57.139+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:38:57.139+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:38:57.150+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:38:57.150+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:38:57.160+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.692 seconds
[2023-10-26T20:39:27.314+0800] {processor.py:157} INFO - Started process (PID=8548) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:39:27.325+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:39:27.326+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:39:27.326+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:39:27.901+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:39:27.911+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:39:27.911+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:39:27.924+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:39:27.924+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:39:27.933+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.625 seconds
[2023-10-26T20:39:58.059+0800] {processor.py:157} INFO - Started process (PID=8578) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:39:58.071+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:39:58.072+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:39:58.072+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:39:58.638+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:39:58.650+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:39:58.650+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:39:58.662+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:39:58.662+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:39:58.680+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.629 seconds
[2023-10-26T20:40:28.913+0800] {processor.py:157} INFO - Started process (PID=8607) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:40:28.927+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:40:28.931+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:40:28.928+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:40:29.481+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:40:29.492+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:40:29.492+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:40:29.503+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:40:29.503+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:40:29.513+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.605 seconds
[2023-10-26T20:40:59.709+0800] {processor.py:157} INFO - Started process (PID=8637) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:40:59.721+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:40:59.722+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:40:59.722+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:41:00.297+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:41:00.308+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:41:00.308+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:41:00.320+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:41:00.320+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:41:00.330+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.626 seconds
[2023-10-26T20:41:31.256+0800] {processor.py:157} INFO - Started process (PID=8668) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:41:31.271+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:41:31.272+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:41:31.271+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:41:31.800+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:41:31.811+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:41:31.810+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:41:31.821+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:41:31.821+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:41:31.831+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.583 seconds
[2023-10-26T20:42:02.584+0800] {processor.py:157} INFO - Started process (PID=8699) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:42:02.596+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:42:02.597+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:42:02.596+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:42:03.106+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:42:03.118+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:42:03.118+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:42:03.131+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:42:03.131+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:42:03.141+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.563 seconds
[2023-10-26T20:42:33.996+0800] {processor.py:157} INFO - Started process (PID=8732) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:42:34.006+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:42:34.007+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:42:34.007+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:42:34.760+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:42:34.772+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:42:34.771+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:42:34.782+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:42:34.782+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:42:34.793+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.802 seconds
[2023-10-26T20:43:05.462+0800] {processor.py:157} INFO - Started process (PID=8762) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:43:05.472+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:43:05.473+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:43:05.473+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:43:05.994+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:43:06.004+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:43:06.004+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:43:06.016+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:43:06.016+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:43:06.025+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.566 seconds
[2023-10-26T20:43:36.689+0800] {processor.py:157} INFO - Started process (PID=8792) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:43:36.699+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:43:36.700+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:43:36.700+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:43:37.334+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:43:37.349+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:43:37.348+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:43:37.367+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:43:37.366+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:43:37.388+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.701 seconds
[2023-10-26T20:44:08.041+0800] {processor.py:157} INFO - Started process (PID=8822) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:44:08.054+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:44:08.054+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:44:08.054+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:44:08.661+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:44:08.673+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:44:08.673+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:44:08.684+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:44:08.684+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:44:08.692+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.654 seconds
[2023-10-26T20:44:39.221+0800] {processor.py:157} INFO - Started process (PID=8861) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:44:39.232+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:44:39.232+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:44:39.232+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:44:40.093+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:44:40.107+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:44:40.106+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:44:40.120+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:44:40.120+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:44:40.136+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.918 seconds
[2023-10-26T20:45:10.762+0800] {processor.py:157} INFO - Started process (PID=8891) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:45:10.774+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:45:10.774+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:45:10.774+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:45:11.307+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:45:11.319+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:45:11.319+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:45:11.338+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:45:11.338+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:45:11.347+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.589 seconds
[2023-10-26T20:45:42.019+0800] {processor.py:157} INFO - Started process (PID=8921) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:45:42.030+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:45:42.031+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:45:42.030+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:45:42.790+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:45:42.818+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:45:42.818+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:45:42.830+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:45:42.830+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:45:42.840+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.824 seconds
[2023-10-26T20:46:13.535+0800] {processor.py:157} INFO - Started process (PID=8951) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:46:13.553+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:46:13.554+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:46:13.554+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:46:14.120+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:46:14.130+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:46:14.130+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:46:14.144+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:46:14.144+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:46:14.155+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.641 seconds
[2023-10-26T20:46:44.786+0800] {processor.py:157} INFO - Started process (PID=8982) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:46:44.805+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:46:44.806+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:46:44.805+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:46:45.396+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:46:45.409+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:46:45.408+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:46:45.419+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:46:45.419+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:46:45.429+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.646 seconds
[2023-10-26T20:47:16.031+0800] {processor.py:157} INFO - Started process (PID=9012) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:47:16.045+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:47:16.046+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:47:16.046+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:47:16.647+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:47:16.660+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:47:16.660+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:47:16.672+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:47:16.672+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:47:16.680+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.662 seconds
[2023-10-26T20:47:47.449+0800] {processor.py:157} INFO - Started process (PID=9042) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:47:47.461+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:47:47.463+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:47:47.462+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:47:48.107+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:47:48.120+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:47:48.120+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:47:48.130+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:47:48.130+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:47:48.140+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.695 seconds
[2023-10-26T20:48:18.790+0800] {processor.py:157} INFO - Started process (PID=9072) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:48:18.804+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:48:18.805+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:48:18.804+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:48:19.459+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:48:19.469+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:48:19.469+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:48:19.478+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:48:19.478+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:48:19.487+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.704 seconds
[2023-10-26T20:48:50.152+0800] {processor.py:157} INFO - Started process (PID=9109) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:48:50.163+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:48:50.164+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:48:50.164+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:48:50.779+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:48:50.791+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:48:50.790+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:48:50.802+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:48:50.801+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:48:50.811+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.662 seconds
[2023-10-26T20:49:21.424+0800] {processor.py:157} INFO - Started process (PID=9139) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:49:21.438+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:49:21.439+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:49:21.438+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:49:22.094+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:49:22.105+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:49:22.105+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:49:22.116+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:49:22.116+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:49:22.125+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.708 seconds
[2023-10-26T20:49:52.589+0800] {processor.py:157} INFO - Started process (PID=9169) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:49:52.600+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:49:52.604+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:49:52.602+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:49:53.620+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:49:53.633+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:49:53.633+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:49:53.650+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:49:53.650+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:49:53.660+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.077 seconds
[2023-10-26T20:50:24.343+0800] {processor.py:157} INFO - Started process (PID=9199) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:50:24.354+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:50:24.355+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:50:24.355+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:50:24.969+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:50:24.982+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:50:24.981+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:50:24.993+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:50:24.993+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:50:25.003+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.663 seconds
[2023-10-26T20:50:55.726+0800] {processor.py:157} INFO - Started process (PID=9229) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:50:55.735+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:50:55.736+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:50:55.735+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:50:56.403+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:50:56.413+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:50:56.413+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:50:56.423+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:50:56.422+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:50:56.434+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.713 seconds
[2023-10-26T20:51:27.222+0800] {processor.py:157} INFO - Started process (PID=9259) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:51:27.233+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:51:27.234+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:51:27.233+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:51:27.869+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:51:27.880+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:51:27.879+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:51:27.890+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:51:27.890+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:51:27.900+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.681 seconds
[2023-10-26T20:52:37.722+0800] {processor.py:157} INFO - Started process (PID=174) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:52:37.730+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:52:37.731+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:52:37.731+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:52:39.134+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:52:39.208+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:52:39.208+0800] {security.py:708} INFO - Not syncing DAG-level permissions for DAG 'DAG:stock_data_crawler' as access control is unset.
[2023-10-26T20:52:39.209+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:52:39.209+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:52:39.222+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:52:39.222+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:52:39.234+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.515 seconds
[2023-10-26T20:53:09.716+0800] {processor.py:157} INFO - Started process (PID=203) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:53:09.721+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:53:09.722+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:53:09.722+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:53:10.578+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:53:10.607+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:53:10.606+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:53:10.624+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:53:10.624+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:53:10.647+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.935 seconds
[2023-10-26T20:53:41.298+0800] {processor.py:157} INFO - Started process (PID=233) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:53:41.304+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:53:41.304+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:53:41.304+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:53:42.309+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:53:42.332+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:53:42.331+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:53:42.356+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:53:42.356+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:53:42.386+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.091 seconds
[2023-10-26T20:54:12.827+0800] {processor.py:157} INFO - Started process (PID=263) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:54:12.832+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:54:12.833+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:54:12.832+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:54:13.372+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:54:13.383+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:54:13.383+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:54:13.393+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:54:13.393+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:54:13.401+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.577 seconds
[2023-10-26T20:54:44.021+0800] {processor.py:157} INFO - Started process (PID=293) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:54:44.028+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:54:44.030+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:54:44.029+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:54:44.507+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:54:44.517+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:54:44.517+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:54:44.527+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:54:44.527+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:54:44.536+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.522 seconds
[2023-10-26T20:55:15.187+0800] {processor.py:157} INFO - Started process (PID=323) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:55:15.192+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:55:15.193+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:55:15.193+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:55:15.733+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:55:15.749+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:55:15.749+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:55:15.759+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:55:15.759+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:55:15.768+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.584 seconds
[2023-10-26T20:55:46.388+0800] {processor.py:157} INFO - Started process (PID=353) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:55:46.397+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:55:46.398+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:55:46.398+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:55:46.913+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:55:46.924+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:55:46.924+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:55:46.946+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:55:46.946+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:55:46.955+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.571 seconds
[2023-10-26T20:56:17.657+0800] {processor.py:157} INFO - Started process (PID=383) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:56:17.667+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:56:17.668+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:56:17.668+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:56:18.150+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:56:18.161+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:56:18.161+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:56:18.171+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:56:18.171+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:56:18.180+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.530 seconds
[2023-10-26T20:56:48.787+0800] {processor.py:157} INFO - Started process (PID=413) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:56:48.789+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:56:48.790+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:56:48.790+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:56:49.263+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:56:49.274+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:56:49.274+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:56:49.283+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:56:49.283+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:56:49.292+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.508 seconds
[2023-10-26T20:57:19.829+0800] {processor.py:157} INFO - Started process (PID=443) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:57:19.846+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:57:19.847+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:57:19.847+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:57:20.336+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:57:20.347+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:57:20.347+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:57:20.356+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:57:20.356+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:57:20.365+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.539 seconds
[2023-10-26T20:57:50.947+0800] {processor.py:157} INFO - Started process (PID=473) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:57:50.951+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:57:50.952+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:57:50.952+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:57:51.423+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:57:51.434+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:57:51.433+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:57:51.444+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:57:51.443+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:57:51.452+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.508 seconds
[2023-10-26T20:58:22.069+0800] {processor.py:157} INFO - Started process (PID=504) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:58:22.075+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:58:22.076+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:58:22.076+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:58:22.557+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:58:22.568+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:58:22.568+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:58:22.578+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:58:22.578+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:58:22.587+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.522 seconds
[2023-10-26T20:58:53.207+0800] {processor.py:157} INFO - Started process (PID=533) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:58:53.214+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:58:53.215+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:58:53.214+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:58:53.744+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:58:53.760+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:58:53.760+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:58:53.773+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:58:53.773+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:58:53.784+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.580 seconds
[2023-10-26T20:59:24.444+0800] {processor.py:157} INFO - Started process (PID=563) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:59:24.456+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:59:24.457+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:59:24.457+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:59:24.922+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:59:24.933+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:59:24.932+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:59:24.942+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:59:24.942+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:59:24.956+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.522 seconds
[2023-10-26T20:59:55.521+0800] {processor.py:157} INFO - Started process (PID=593) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:59:55.527+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T20:59:55.528+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:59:55.528+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:59:56.020+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T20:59:56.035+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:59:56.034+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T20:59:56.047+0800] {logging_mixin.py:151} INFO - [2023-10-26T20:59:56.046+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T20:59:56.057+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.547 seconds
[2023-10-26T21:00:26.781+0800] {processor.py:157} INFO - Started process (PID=624) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:00:26.787+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:00:26.788+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:00:26.788+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:00:27.265+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:00:27.275+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:00:27.275+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:00:27.285+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:00:27.285+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:00:27.293+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.515 seconds
[2023-10-26T21:00:57.895+0800] {processor.py:157} INFO - Started process (PID=654) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:00:57.899+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:00:57.900+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:00:57.900+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:00:58.353+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:00:58.365+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:00:58.364+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:00:58.376+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:00:58.375+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:00:58.384+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.492 seconds
[2023-10-26T21:01:28.954+0800] {processor.py:157} INFO - Started process (PID=684) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:01:28.960+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:01:28.962+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:01:28.961+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:01:29.415+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:01:29.427+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:01:29.427+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:01:29.437+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:01:29.436+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:01:29.446+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.496 seconds
[2023-10-26T21:01:59.975+0800] {processor.py:157} INFO - Started process (PID=714) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:01:59.978+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:01:59.979+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:01:59.979+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:02:00.488+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:02:00.498+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:02:00.498+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:02:00.508+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:02:00.508+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:02:00.516+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.544 seconds
[2023-10-26T21:02:31.058+0800] {processor.py:157} INFO - Started process (PID=744) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:02:31.062+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:02:31.063+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:02:31.063+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:02:31.563+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:02:31.574+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:02:31.573+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:02:31.585+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:02:31.584+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:02:31.593+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.538 seconds
[2023-10-26T21:03:02.280+0800] {processor.py:157} INFO - Started process (PID=774) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:03:02.284+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:03:02.285+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:03:02.284+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:03:02.755+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:03:02.766+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:03:02.766+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:03:02.776+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:03:02.776+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:03:02.797+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.521 seconds
[2023-10-26T21:03:33.516+0800] {processor.py:157} INFO - Started process (PID=810) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:03:33.520+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:03:33.522+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:03:33.521+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:03:34.008+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:03:34.019+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:03:34.018+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:03:34.029+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:03:34.028+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:03:34.038+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.526 seconds
[2023-10-26T21:04:04.697+0800] {processor.py:157} INFO - Started process (PID=841) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:04:04.702+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:04:04.703+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:04:04.703+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:04:05.275+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:04:05.286+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:04:05.286+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:04:05.297+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:04:05.297+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:04:05.306+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.616 seconds
[2023-10-26T21:04:35.908+0800] {processor.py:157} INFO - Started process (PID=871) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:04:35.915+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:04:35.916+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:04:35.915+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:04:36.550+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:04:36.570+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:04:36.569+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:04:36.582+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:04:36.582+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:04:36.597+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.692 seconds
[2023-10-26T21:05:07.215+0800] {processor.py:157} INFO - Started process (PID=901) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:05:07.220+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:05:07.221+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:05:07.221+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:05:07.712+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:05:07.723+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:05:07.723+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:05:07.733+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:05:07.733+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:05:07.741+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.529 seconds
[2023-10-26T21:05:38.408+0800] {processor.py:157} INFO - Started process (PID=931) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:05:38.432+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:05:38.433+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:05:38.433+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:05:38.913+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:05:38.924+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:05:38.924+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:05:38.935+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:05:38.935+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:05:38.944+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.539 seconds
[2023-10-26T21:06:09.625+0800] {processor.py:157} INFO - Started process (PID=962) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:06:09.634+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:06:09.635+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:06:09.635+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:06:10.126+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:06:10.137+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:06:10.137+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:06:10.146+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:06:10.146+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:06:10.155+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.533 seconds
[2023-10-26T21:06:40.868+0800] {processor.py:157} INFO - Started process (PID=992) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:06:40.875+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:06:40.876+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:06:40.876+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:06:41.355+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:06:41.367+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:06:41.367+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:06:41.377+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:06:41.377+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:06:41.386+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.531 seconds
[2023-10-26T21:07:12.046+0800] {processor.py:157} INFO - Started process (PID=1023) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:07:12.057+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:07:12.058+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:07:12.058+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:07:12.533+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:07:12.545+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:07:12.545+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:07:12.562+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:07:12.562+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:07:12.570+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.528 seconds
[2023-10-26T21:07:43.277+0800] {processor.py:157} INFO - Started process (PID=1053) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:07:43.289+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:07:43.290+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:07:43.289+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:07:43.790+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:07:43.801+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:07:43.801+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:07:43.810+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:07:43.810+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:07:43.819+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.545 seconds
[2023-10-26T21:08:14.522+0800] {processor.py:157} INFO - Started process (PID=1083) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:08:14.533+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:08:14.535+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:08:14.534+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:08:15.022+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:08:15.032+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:08:15.032+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:08:15.042+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:08:15.042+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:08:15.051+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.534 seconds
[2023-10-26T21:08:45.867+0800] {processor.py:157} INFO - Started process (PID=1113) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:08:45.875+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:08:45.876+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:08:45.876+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:08:46.403+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:08:46.414+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:08:46.414+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:08:46.426+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:08:46.426+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:08:46.434+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.571 seconds
[2023-10-26T21:09:17.099+0800] {processor.py:157} INFO - Started process (PID=1142) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:09:17.102+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:09:17.103+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:09:17.103+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:09:17.628+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:09:17.638+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:09:17.638+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:09:17.650+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:09:17.650+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:09:17.660+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.564 seconds
[2023-10-26T21:09:48.344+0800] {processor.py:157} INFO - Started process (PID=1171) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:09:48.348+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:09:48.349+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:09:48.349+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:09:48.887+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:09:48.900+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:09:48.899+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:09:48.909+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:09:48.909+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:09:48.917+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.577 seconds
[2023-10-26T21:10:19.674+0800] {processor.py:157} INFO - Started process (PID=1201) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:10:19.681+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:10:19.682+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:10:19.681+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:10:20.183+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:10:20.194+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:10:20.194+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:10:20.205+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:10:20.205+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:10:20.214+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.544 seconds
[2023-10-26T21:10:50.907+0800] {processor.py:157} INFO - Started process (PID=1231) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:10:50.916+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:10:50.918+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:10:50.917+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:10:51.408+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:10:51.421+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:10:51.421+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:10:51.432+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:10:51.432+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:10:51.449+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.546 seconds
[2023-10-26T21:11:21.867+0800] {processor.py:157} INFO - Started process (PID=1261) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:11:21.875+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:11:21.876+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:11:21.875+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:11:22.355+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:11:22.365+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:11:22.365+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:11:22.375+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:11:22.375+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:11:22.383+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.523 seconds
[2023-10-26T21:11:52.971+0800] {processor.py:157} INFO - Started process (PID=1292) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:11:52.977+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:11:52.978+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:11:52.978+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:11:53.468+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:11:53.479+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:11:53.479+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:11:53.490+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:11:53.490+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:11:53.499+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.533 seconds
[2023-10-26T21:12:24.261+0800] {processor.py:157} INFO - Started process (PID=1322) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:12:24.271+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:12:24.272+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:12:24.272+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:12:24.779+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:12:24.792+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:12:24.791+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:12:24.802+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:12:24.802+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:12:24.811+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.554 seconds
[2023-10-26T21:12:55.646+0800] {processor.py:157} INFO - Started process (PID=1357) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:12:55.652+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:12:55.653+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:12:55.653+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:12:56.065+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:12:56.081+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:12:56.080+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:12:56.090+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:12:56.090+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:12:56.099+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.456 seconds
[2023-10-26T21:13:26.752+0800] {processor.py:157} INFO - Started process (PID=1388) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:13:26.759+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:13:26.760+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:13:26.760+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:13:27.171+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:13:27.182+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:13:27.182+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:13:27.199+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:13:27.199+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:13:27.209+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.460 seconds
[2023-10-26T21:13:57.887+0800] {processor.py:157} INFO - Started process (PID=1418) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:13:57.895+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:13:57.895+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:13:57.895+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:13:58.319+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:13:58.332+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:13:58.331+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:13:58.342+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:13:58.342+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:13:58.350+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.465 seconds
[2023-10-26T21:14:28.949+0800] {processor.py:157} INFO - Started process (PID=1448) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:14:28.957+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:14:28.957+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:14:28.957+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:14:29.380+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:14:29.396+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:14:29.396+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:14:29.405+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:14:29.405+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:14:29.415+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.469 seconds
[2023-10-26T21:15:00.123+0800] {processor.py:157} INFO - Started process (PID=1478) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:15:00.130+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:15:00.131+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:15:00.131+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:15:00.533+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:15:00.544+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:15:00.543+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:15:00.557+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:15:00.557+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:15:00.565+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.445 seconds
[2023-10-26T21:15:31.130+0800] {processor.py:157} INFO - Started process (PID=1508) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:15:31.138+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:15:31.139+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:15:31.139+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:15:31.551+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:15:31.563+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:15:31.563+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:15:31.573+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:15:31.573+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:15:31.581+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.453 seconds
[2023-10-26T21:16:02.195+0800] {processor.py:157} INFO - Started process (PID=1538) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:16:02.203+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:16:02.204+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:16:02.203+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:16:02.640+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:16:02.652+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:16:02.652+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:16:02.664+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:16:02.664+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:16:02.673+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.484 seconds
[2023-10-26T21:16:33.263+0800] {processor.py:157} INFO - Started process (PID=1568) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:16:33.270+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:16:33.271+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:16:33.271+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:16:33.708+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:16:33.721+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:16:33.720+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:16:33.732+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:16:33.732+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:16:33.743+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.483 seconds
[2023-10-26T21:17:04.421+0800] {processor.py:157} INFO - Started process (PID=1598) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:17:04.428+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:17:04.429+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:17:04.428+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:17:04.836+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:17:04.847+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:17:04.847+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:17:04.857+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:17:04.857+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:17:04.869+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.450 seconds
[2023-10-26T21:17:35.529+0800] {processor.py:157} INFO - Started process (PID=1628) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:17:35.536+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:17:35.537+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:17:35.537+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:17:35.962+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:17:35.974+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:17:35.973+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:17:35.984+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:17:35.984+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:17:35.999+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.472 seconds
[2023-10-26T21:18:06.523+0800] {processor.py:157} INFO - Started process (PID=1658) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:18:06.530+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:18:06.531+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:18:06.530+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:18:07.032+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:18:07.047+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:18:07.046+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:18:07.059+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:18:07.059+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:18:07.069+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.548 seconds
[2023-10-26T21:18:37.601+0800] {processor.py:157} INFO - Started process (PID=1695) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:18:37.608+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:18:37.609+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:18:37.609+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:18:38.081+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:18:38.094+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:18:38.094+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:18:38.105+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:18:38.105+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:18:38.115+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.518 seconds
[2023-10-26T21:19:08.679+0800] {processor.py:157} INFO - Started process (PID=1725) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:19:08.689+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:19:08.690+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:19:08.689+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:19:09.190+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:19:09.203+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:19:09.203+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:19:09.216+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:19:09.216+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:19:09.231+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.555 seconds
[2023-10-26T21:19:39.813+0800] {processor.py:157} INFO - Started process (PID=1755) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:19:39.822+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:19:39.822+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:19:39.822+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:19:40.330+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:19:40.344+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:19:40.344+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:19:40.356+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:19:40.356+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:19:40.366+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.558 seconds
[2023-10-26T21:20:10.952+0800] {processor.py:157} INFO - Started process (PID=1785) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:20:10.961+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:20:10.961+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:20:10.961+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:20:11.438+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:20:11.451+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:20:11.450+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:20:11.461+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:20:11.461+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:20:11.470+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.522 seconds
[2023-10-26T21:20:42.034+0800] {processor.py:157} INFO - Started process (PID=1815) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:20:42.044+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:20:42.046+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:20:42.046+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:20:42.538+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:20:42.552+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:20:42.551+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:20:42.562+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:20:42.562+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:20:42.571+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.540 seconds
[2023-10-26T21:21:13.256+0800] {processor.py:157} INFO - Started process (PID=1845) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:21:13.269+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:21:13.269+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:21:13.269+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:21:13.802+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:21:13.814+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:21:13.813+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:21:13.824+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:21:13.824+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:21:13.832+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.580 seconds
[2023-10-26T21:21:44.545+0800] {processor.py:157} INFO - Started process (PID=1875) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:21:44.554+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:21:44.555+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:21:44.555+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:21:45.017+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:21:45.029+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:21:45.029+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:21:45.039+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:21:45.039+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:21:45.049+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.507 seconds
[2023-10-26T21:22:15.710+0800] {processor.py:157} INFO - Started process (PID=1904) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:22:15.720+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:22:15.721+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:22:15.720+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:22:16.212+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:22:16.224+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:22:16.224+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:22:16.234+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:22:16.234+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:22:16.243+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.536 seconds
[2023-10-26T21:22:46.955+0800] {processor.py:157} INFO - Started process (PID=1935) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:22:46.964+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:22:46.964+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:22:46.964+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:22:47.477+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:22:47.488+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:22:47.488+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:22:47.499+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:22:47.499+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:22:47.508+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.560 seconds
[2023-10-26T21:23:18.108+0800] {processor.py:157} INFO - Started process (PID=1965) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:23:18.118+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:23:18.119+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:23:18.119+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:23:18.639+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:23:18.657+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:23:18.656+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:23:18.667+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:23:18.667+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:23:18.676+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.572 seconds
[2023-10-26T21:23:49.310+0800] {processor.py:157} INFO - Started process (PID=1995) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:23:49.318+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:23:49.319+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:23:49.319+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:23:49.816+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:23:49.826+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:23:49.826+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:23:49.836+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:23:49.836+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:23:49.844+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.539 seconds
[2023-10-26T21:24:20.470+0800] {processor.py:157} INFO - Started process (PID=2025) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:24:20.479+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:24:20.480+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:24:20.480+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:24:21.011+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:24:21.023+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:24:21.023+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:24:21.033+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:24:21.033+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:24:21.042+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.579 seconds
[2023-10-26T21:24:51.733+0800] {processor.py:157} INFO - Started process (PID=2055) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:24:51.743+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:24:51.743+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:24:51.743+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:24:52.204+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:24:52.219+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:24:52.219+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:24:52.230+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:24:52.230+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:24:52.239+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.510 seconds
[2023-10-26T21:25:22.803+0800] {processor.py:157} INFO - Started process (PID=2086) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:25:22.825+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:25:22.826+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:25:22.826+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:25:23.456+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:25:23.473+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:25:23.473+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:25:23.485+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:25:23.485+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:25:23.493+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.693 seconds
[2023-10-26T21:25:54.052+0800] {processor.py:157} INFO - Started process (PID=2116) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:25:54.068+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:25:54.069+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:25:54.068+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:25:54.554+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:25:54.566+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:25:54.566+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:25:54.577+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:25:54.576+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:25:54.585+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.535 seconds
[2023-10-26T21:26:25.251+0800] {processor.py:157} INFO - Started process (PID=2147) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:26:25.261+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:26:25.262+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:26:25.262+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:26:25.723+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:26:25.735+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:26:25.735+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:26:25.745+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:26:25.744+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:26:25.755+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.506 seconds
[2023-10-26T21:26:56.388+0800] {processor.py:157} INFO - Started process (PID=2176) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:26:56.392+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:26:56.393+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:26:56.393+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:26:56.894+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:26:56.904+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:26:56.904+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:26:56.914+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:26:56.914+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:26:56.926+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.549 seconds
[2023-10-26T21:27:27.598+0800] {processor.py:157} INFO - Started process (PID=2206) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:27:27.606+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:27:27.607+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:27:27.607+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:27:28.114+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:27:28.125+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:27:28.124+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:27:28.135+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:27:28.135+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:27:28.144+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.551 seconds
[2023-10-26T21:27:58.816+0800] {processor.py:157} INFO - Started process (PID=2237) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:27:58.821+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:27:58.821+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:27:58.821+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:27:59.319+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:27:59.343+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:27:59.343+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:27:59.354+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:27:59.354+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:27:59.364+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.551 seconds
[2023-10-26T21:28:30.133+0800] {processor.py:157} INFO - Started process (PID=2267) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:28:30.143+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:28:30.144+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:28:30.144+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:28:30.671+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:28:30.682+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:28:30.682+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:28:30.694+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:28:30.693+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:28:30.702+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.584 seconds
[2023-10-26T21:29:01.419+0800] {processor.py:157} INFO - Started process (PID=2297) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:29:01.427+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:29:01.430+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:29:01.429+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:29:01.936+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:29:01.947+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:29:01.946+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:29:01.957+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:29:01.957+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:29:01.965+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.559 seconds
[2023-10-26T21:29:32.714+0800] {processor.py:157} INFO - Started process (PID=2327) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:29:32.720+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:29:32.721+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:29:32.721+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:29:33.207+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:29:33.219+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:29:33.218+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:29:33.229+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:29:33.229+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:29:33.241+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.530 seconds
[2023-10-26T21:30:03.967+0800] {processor.py:157} INFO - Started process (PID=2357) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:30:03.973+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:30:03.975+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:30:03.974+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:30:04.479+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:30:04.490+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:30:04.490+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:30:04.500+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:30:04.500+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:30:04.508+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.552 seconds
[2023-10-26T21:30:35.170+0800] {processor.py:157} INFO - Started process (PID=2387) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:30:35.177+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:30:35.178+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:30:35.178+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:30:35.690+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:30:35.702+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:30:35.701+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:30:35.712+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:30:35.712+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:30:35.722+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.556 seconds
[2023-10-26T21:31:06.444+0800] {processor.py:157} INFO - Started process (PID=2417) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:31:06.456+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:31:06.459+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:31:06.458+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:31:06.946+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:31:06.958+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:31:06.957+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:31:06.967+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:31:06.967+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:31:06.977+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.541 seconds
[2023-10-26T21:31:37.744+0800] {processor.py:157} INFO - Started process (PID=2445) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:31:37.754+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:31:37.756+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:31:37.755+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:31:38.273+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:31:38.284+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:31:38.284+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:31:38.294+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:31:38.294+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:31:38.302+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.564 seconds
[2023-10-26T21:32:08.906+0800] {processor.py:157} INFO - Started process (PID=2477) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:32:08.912+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:32:08.913+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:32:08.913+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:32:09.424+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:32:09.435+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:32:09.435+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:32:09.446+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:32:09.446+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:32:09.455+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.552 seconds
[2023-10-26T21:32:40.078+0800] {processor.py:157} INFO - Started process (PID=2507) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:32:40.084+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:32:40.085+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:32:40.084+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:32:40.565+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:32:40.584+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:32:40.584+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:32:40.594+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:32:40.594+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:32:40.604+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.530 seconds
[2023-10-26T21:33:11.476+0800] {processor.py:157} INFO - Started process (PID=2543) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:33:11.481+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:33:11.482+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:33:11.482+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:33:11.989+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:33:12.000+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:33:12.000+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:33:12.011+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:33:12.010+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:33:12.019+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.546 seconds
[2023-10-26T21:33:42.722+0800] {processor.py:157} INFO - Started process (PID=2573) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:33:42.728+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:33:42.729+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:33:42.729+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:33:43.222+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:33:43.235+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:33:43.234+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:33:43.252+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:33:43.252+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:33:43.261+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.544 seconds
[2023-10-26T21:34:13.967+0800] {processor.py:157} INFO - Started process (PID=2604) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:34:13.972+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:34:13.973+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:34:13.973+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:34:14.481+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:34:14.493+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:34:14.492+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:34:14.503+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:34:14.503+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:34:14.512+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.547 seconds
[2023-10-26T21:34:45.202+0800] {processor.py:157} INFO - Started process (PID=2634) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:34:45.210+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:34:45.211+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:34:45.211+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:34:45.958+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:34:45.972+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:34:45.971+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:34:45.986+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:34:45.986+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:34:45.997+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.797 seconds
[2023-10-26T21:35:16.550+0800] {processor.py:157} INFO - Started process (PID=2664) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:35:16.557+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:35:16.558+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:35:16.557+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:35:17.099+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:35:17.111+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:35:17.110+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:35:17.121+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:35:17.121+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:35:17.129+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.581 seconds
[2023-10-26T21:35:47.866+0800] {processor.py:157} INFO - Started process (PID=2695) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:35:47.872+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:35:47.873+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:35:47.873+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:35:48.420+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:35:48.432+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:35:48.432+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:35:48.442+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:35:48.442+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:35:48.453+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.590 seconds
[2023-10-26T21:36:19.168+0800] {processor.py:157} INFO - Started process (PID=2724) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:36:19.181+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:36:19.182+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:36:19.182+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:36:19.794+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:36:19.808+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:36:19.808+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:36:19.819+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:36:19.819+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:36:19.830+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.672 seconds
[2023-10-26T21:36:50.599+0800] {processor.py:157} INFO - Started process (PID=2759) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:36:50.604+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:36:50.605+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:36:50.605+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:36:51.039+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:36:51.050+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:36:51.050+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:36:51.061+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:36:51.061+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:36:51.072+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.476 seconds
[2023-10-26T21:37:21.672+0800] {processor.py:157} INFO - Started process (PID=2789) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:37:21.677+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:37:21.678+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:37:21.678+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:37:22.116+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:37:22.129+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:37:22.128+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:37:22.140+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:37:22.140+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:37:22.154+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.486 seconds
[2023-10-26T21:37:52.996+0800] {processor.py:157} INFO - Started process (PID=2819) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:37:53.004+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:37:53.008+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:37:53.008+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:37:53.396+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:37:53.410+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:37:53.409+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:37:53.428+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:37:53.428+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:37:53.442+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.450 seconds
[2023-10-26T21:38:23.997+0800] {processor.py:157} INFO - Started process (PID=2849) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:38:24.004+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:38:24.005+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:38:24.004+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:38:24.421+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:38:24.432+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:38:24.431+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:38:24.442+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:38:24.442+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:38:24.451+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.457 seconds
[2023-10-26T21:38:55.088+0800] {processor.py:157} INFO - Started process (PID=2879) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:38:55.095+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:38:55.096+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:38:55.095+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:38:55.497+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:38:55.510+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:38:55.510+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:38:55.521+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:38:55.521+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:38:55.529+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.445 seconds
[2023-10-26T21:39:26.283+0800] {processor.py:157} INFO - Started process (PID=2910) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:39:26.293+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:39:26.294+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:39:26.294+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:39:26.658+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:39:26.674+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:39:26.673+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:39:26.685+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:39:26.685+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:39:26.696+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.417 seconds
[2023-10-26T21:39:57.243+0800] {processor.py:157} INFO - Started process (PID=2940) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:39:57.250+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:39:57.251+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:39:57.250+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:39:57.692+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:39:57.705+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:39:57.705+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:39:57.722+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:39:57.722+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:39:57.732+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.491 seconds
[2023-10-26T21:40:28.208+0800] {processor.py:157} INFO - Started process (PID=2970) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:40:28.211+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:40:28.211+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:40:28.211+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:40:28.625+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:40:28.636+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:40:28.636+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:40:28.648+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:40:28.648+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:40:28.659+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.454 seconds
[2023-10-26T21:40:59.536+0800] {processor.py:157} INFO - Started process (PID=3001) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:40:59.539+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:40:59.539+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:40:59.539+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:40:59.875+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:40:59.886+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:40:59.885+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:40:59.896+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:40:59.895+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:40:59.905+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.371 seconds
[2023-10-26T21:41:30.706+0800] {processor.py:157} INFO - Started process (PID=3032) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:41:30.713+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:41:30.714+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:41:30.713+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:41:31.055+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:41:31.066+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:41:31.066+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:41:31.076+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:41:31.076+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:41:31.085+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.382 seconds
[2023-10-26T21:42:01.850+0800] {processor.py:157} INFO - Started process (PID=3062) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:42:01.858+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:42:01.859+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:42:01.859+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:42:02.140+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:42:02.151+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:42:02.151+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:42:02.162+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:42:02.162+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:42:02.171+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.325 seconds
[2023-10-26T21:42:32.607+0800] {processor.py:157} INFO - Started process (PID=3092) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:42:32.611+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:42:32.612+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:42:32.611+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:42:32.885+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:42:32.897+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:42:32.896+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:42:32.908+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:42:32.908+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:42:32.917+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.313 seconds
[2023-10-26T21:43:03.510+0800] {processor.py:157} INFO - Started process (PID=3123) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:43:03.516+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:43:03.517+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:43:03.516+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:43:03.843+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:43:03.856+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:43:03.856+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:43:03.868+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:43:03.868+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:43:03.879+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.372 seconds
[2023-10-26T21:43:34.389+0800] {processor.py:157} INFO - Started process (PID=3152) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:43:34.396+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:43:34.397+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:43:34.397+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:43:34.669+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:43:34.681+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:43:34.680+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:43:34.692+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:43:34.692+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:43:34.701+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.317 seconds
[2023-10-26T21:44:05.219+0800] {processor.py:157} INFO - Started process (PID=3183) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:44:05.225+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:44:05.226+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:44:05.226+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:44:05.508+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:44:05.523+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:44:05.523+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:44:05.535+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:44:05.535+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:44:05.545+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.330 seconds
[2023-10-26T21:45:11.016+0800] {processor.py:157} INFO - Started process (PID=172) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:45:11.041+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:45:11.043+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:45:11.042+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:45:11.687+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:45:11.810+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:45:11.810+0800] {security.py:708} INFO - Not syncing DAG-level permissions for DAG 'DAG:stock_data_crawler' as access control is unset.
[2023-10-26T21:45:11.812+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:45:11.811+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:45:11.826+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:45:11.826+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:45:11.845+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.833 seconds
[2023-10-26T21:45:42.381+0800] {processor.py:157} INFO - Started process (PID=201) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:45:42.390+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:45:42.390+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:45:42.390+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:45:43.240+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:45:43.269+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:45:43.268+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:45:43.290+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:45:43.289+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:45:43.300+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.923 seconds
[2023-10-26T21:46:13.778+0800] {processor.py:157} INFO - Started process (PID=231) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:46:13.785+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:46:13.786+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:46:13.785+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:46:14.251+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:46:14.261+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:46:14.261+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:46:14.271+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:46:14.271+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:46:14.280+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.505 seconds
[2023-10-26T21:46:44.807+0800] {processor.py:157} INFO - Started process (PID=261) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:46:44.817+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:46:44.818+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:46:44.818+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:46:45.279+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:46:45.289+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:46:45.289+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:46:45.303+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:46:45.303+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:46:45.313+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.511 seconds
[2023-10-26T21:47:15.965+0800] {processor.py:157} INFO - Started process (PID=291) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:47:15.976+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:47:15.977+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:47:15.977+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:47:16.628+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:47:16.674+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:47:16.673+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:47:16.694+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:47:16.694+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:47:16.706+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.744 seconds
[2023-10-26T21:47:47.129+0800] {processor.py:157} INFO - Started process (PID=321) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:47:47.139+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:47:47.139+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:47:47.139+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:47:47.610+0800] {processor.py:839} INFO - DAG(s) dict_keys(['stock_data_crawler']) retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:47:47.621+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:47:47.620+0800] {dag.py:2915} INFO - Sync 1 DAGs
[2023-10-26T21:47:47.631+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:47:47.631+0800] {dag.py:3696} INFO - Setting next_dagrun for stock_data_crawler to 2023-10-26T10:00:00+00:00, run_after=2023-10-27T10:00:00+00:00
[2023-10-26T21:47:47.641+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.515 seconds
[2023-10-26T21:48:18.200+0800] {processor.py:157} INFO - Started process (PID=351) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:48:18.214+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:48:18.215+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:48:18.215+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:48:18.686+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:48:18.684+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from functions.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'functions'
[2023-10-26T21:48:18.686+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:48:18.705+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.518 seconds
[2023-10-26T21:48:49.735+0800] {processor.py:157} INFO - Started process (PID=382) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:48:49.748+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:48:49.754+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:48:49.753+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:48:50.169+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:48:50.165+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from functions.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'functions'
[2023-10-26T21:48:50.170+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:48:50.213+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.494 seconds
[2023-10-26T21:48:55.411+0800] {processor.py:157} INFO - Started process (PID=394) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:48:55.415+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:48:55.416+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:48:55.416+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:48:55.995+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:48:55.990+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'src'
[2023-10-26T21:48:55.996+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:48:56.044+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.638 seconds
[2023-10-26T21:49:26.481+0800] {processor.py:157} INFO - Started process (PID=423) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:49:26.493+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:49:26.494+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:49:26.494+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:49:26.880+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:49:26.879+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'src'
[2023-10-26T21:49:26.881+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:49:26.895+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.423 seconds
[2023-10-26T21:49:57.435+0800] {processor.py:157} INFO - Started process (PID=451) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:49:57.449+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:49:57.451+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:49:57.450+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:49:57.820+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:49:57.818+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'src'
[2023-10-26T21:49:57.821+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:49:57.834+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.407 seconds
[2023-10-26T21:50:28.363+0800] {processor.py:157} INFO - Started process (PID=494) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:50:28.374+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:50:28.375+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:50:28.374+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:50:28.743+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:50:28.742+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'src'
[2023-10-26T21:50:28.743+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:50:28.756+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.411 seconds
[2023-10-26T21:50:59.013+0800] {processor.py:157} INFO - Started process (PID=523) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:50:59.026+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:50:59.028+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:50:59.027+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:50:59.426+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:50:59.425+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'src'
[2023-10-26T21:50:59.426+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:50:59.440+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.446 seconds
[2023-10-26T21:51:30.061+0800] {processor.py:157} INFO - Started process (PID=552) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:51:30.075+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:51:30.077+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:51:30.076+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:51:30.454+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:51:30.453+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'src'
[2023-10-26T21:51:30.455+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:51:30.466+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.412 seconds
[2023-10-26T21:52:00.926+0800] {processor.py:157} INFO - Started process (PID=581) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:52:00.939+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:52:00.941+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:52:00.940+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:52:01.305+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:52:01.304+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'src'
[2023-10-26T21:52:01.305+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:52:01.317+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.399 seconds
[2023-10-26T21:52:31.865+0800] {processor.py:157} INFO - Started process (PID=610) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:52:31.889+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:52:31.891+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:52:31.890+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:52:32.597+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:52:32.594+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'src'
[2023-10-26T21:52:32.598+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:52:32.618+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.763 seconds
[2023-10-26T21:52:58.082+0800] {processor.py:157} INFO - Started process (PID=632) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:52:58.088+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:52:58.101+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:52:58.101+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:52:59.050+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:52:59.046+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'src'
[2023-10-26T21:52:59.050+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:52:59.088+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.014 seconds
[2023-10-26T21:53:23.628+0800] {processor.py:157} INFO - Started process (PID=675) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:53:23.639+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:53:23.640+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:53:23.639+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:53:24.079+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:53:24.078+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow.src'
[2023-10-26T21:53:24.080+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:53:24.095+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.473 seconds
[2023-10-26T21:53:54.756+0800] {processor.py:157} INFO - Started process (PID=710) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:53:54.768+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:53:54.769+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:53:54.768+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:53:55.302+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:53:55.300+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow.src'
[2023-10-26T21:53:55.302+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:53:55.317+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.569 seconds
[2023-10-26T21:54:25.421+0800] {processor.py:157} INFO - Started process (PID=739) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:54:25.429+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:54:25.430+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:54:25.430+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:54:25.799+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:54:25.798+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow.src'
[2023-10-26T21:54:25.800+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:54:25.815+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.400 seconds
[2023-10-26T21:54:56.759+0800] {processor.py:157} INFO - Started process (PID=768) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:54:56.764+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:54:56.765+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:54:56.764+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:54:57.222+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:54:57.221+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow.src'
[2023-10-26T21:54:57.223+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:54:57.234+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.485 seconds
[2023-10-26T21:55:28.216+0800] {processor.py:157} INFO - Started process (PID=802) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:55:28.221+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:55:28.222+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:55:28.222+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:55:28.618+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:55:28.612+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow.src'
[2023-10-26T21:55:28.619+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:55:28.646+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.435 seconds
[2023-10-26T21:55:59.171+0800] {processor.py:157} INFO - Started process (PID=831) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:55:59.175+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:55:59.176+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:55:59.175+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:55:59.711+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:55:59.702+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow.src'
[2023-10-26T21:55:59.713+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:55:59.779+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.611 seconds
[2023-10-26T21:56:30.826+0800] {processor.py:157} INFO - Started process (PID=860) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:56:30.833+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:56:30.834+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:56:30.834+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:56:31.413+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:56:31.412+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow.src'
[2023-10-26T21:56:31.414+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:56:31.436+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.622 seconds
[2023-10-26T21:56:38.961+0800] {processor.py:157} INFO - Started process (PID=880) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:56:38.966+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:56:38.967+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:56:38.967+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:56:39.418+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:56:39.417+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T21:56:39.418+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:56:39.440+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.483 seconds
[2023-10-26T21:57:10.022+0800] {processor.py:157} INFO - Started process (PID=916) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:57:10.028+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:57:10.030+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:57:10.029+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:57:10.533+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:57:10.531+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T21:57:10.533+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:57:10.549+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.533 seconds
[2023-10-26T21:57:40.610+0800] {processor.py:157} INFO - Started process (PID=946) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:57:40.615+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:57:40.616+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:57:40.616+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:57:41.041+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:57:41.039+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T21:57:41.041+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:57:41.059+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.453 seconds
[2023-10-26T21:58:11.681+0800] {processor.py:157} INFO - Started process (PID=978) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:58:11.687+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:58:11.688+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:58:11.688+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:58:12.125+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:58:12.124+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T21:58:12.126+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:58:12.140+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.465 seconds
[2023-10-26T21:58:42.223+0800] {processor.py:157} INFO - Started process (PID=1012) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:58:42.228+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:58:42.228+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:58:42.228+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:58:42.444+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:58:42.443+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T21:58:42.444+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:58:42.456+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.238 seconds
[2023-10-26T21:59:12.957+0800] {processor.py:157} INFO - Started process (PID=1041) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:59:12.963+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:59:12.964+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:59:12.964+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:59:13.270+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:59:13.266+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T21:59:13.271+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:59:13.301+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.348 seconds
[2023-10-26T21:59:43.594+0800] {processor.py:157} INFO - Started process (PID=1070) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:59:43.602+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T21:59:43.604+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:59:43.603+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:59:43.848+0800] {logging_mixin.py:151} INFO - [2023-10-26T21:59:43.847+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T21:59:43.848+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T21:59:43.857+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.271 seconds
[2023-10-26T22:00:14.020+0800] {processor.py:157} INFO - Started process (PID=1100) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:00:14.026+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:00:14.027+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:00:14.027+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:00:14.680+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:00:14.678+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:00:14.681+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:00:14.707+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.698 seconds
[2023-10-26T22:00:44.869+0800] {processor.py:157} INFO - Started process (PID=1129) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:00:44.878+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:00:44.879+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:00:44.879+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:00:45.357+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:00:45.353+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:00:45.359+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:00:45.399+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.541 seconds
[2023-10-26T22:01:16.228+0800] {processor.py:157} INFO - Started process (PID=1158) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:01:16.241+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:01:16.245+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:01:16.243+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:01:17.051+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:01:17.045+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:01:17.053+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:01:17.104+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.882 seconds
[2023-10-26T22:01:47.423+0800] {processor.py:157} INFO - Started process (PID=1187) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:01:47.426+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:01:47.427+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:01:47.426+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:01:47.646+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:01:47.645+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:01:47.646+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:01:47.657+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.243 seconds
[2023-10-26T22:02:18.368+0800] {processor.py:157} INFO - Started process (PID=1209) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:02:18.371+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:02:18.373+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:02:18.372+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:02:18.864+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:02:18.862+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:02:18.864+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:02:18.879+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.515 seconds
[2023-10-26T22:02:49.462+0800] {processor.py:157} INFO - Started process (PID=1238) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:02:49.468+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:02:49.471+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:02:49.471+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:02:49.859+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:02:49.857+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:02:49.859+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:02:49.870+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.435 seconds
[2023-10-26T22:03:20.414+0800] {processor.py:157} INFO - Started process (PID=1267) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:03:20.423+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:03:20.435+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:03:20.434+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:03:20.808+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:03:20.806+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:03:20.808+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:03:20.824+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.427 seconds
[2023-10-26T22:03:50.983+0800] {processor.py:157} INFO - Started process (PID=1296) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:03:50.993+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:03:51.005+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:03:51.005+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:03:51.403+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:03:51.401+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:03:51.403+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:03:51.419+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.443 seconds
[2023-10-26T22:04:21.773+0800] {processor.py:157} INFO - Started process (PID=1325) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:04:21.783+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:04:21.794+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:04:21.793+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:04:22.243+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:04:22.241+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:04:22.243+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:04:22.267+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.501 seconds
[2023-10-26T22:04:52.823+0800] {processor.py:157} INFO - Started process (PID=1354) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:04:52.838+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:04:52.842+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:04:52.842+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:04:53.226+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:04:53.225+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:04:53.226+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:04:53.241+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.439 seconds
[2023-10-26T22:05:23.505+0800] {processor.py:157} INFO - Started process (PID=1383) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:05:23.510+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:05:23.511+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:05:23.511+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:05:23.932+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:05:23.931+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:05:23.933+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:05:23.949+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.451 seconds
[2023-10-26T22:05:55.009+0800] {processor.py:157} INFO - Started process (PID=1412) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:05:55.030+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:05:55.033+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:05:55.032+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:05:55.418+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:05:55.417+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:05:55.419+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:05:55.432+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.436 seconds
[2023-10-26T22:06:26.141+0800] {processor.py:157} INFO - Started process (PID=1440) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:06:26.145+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:06:26.147+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:06:26.146+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:06:26.550+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:06:26.545+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:06:26.550+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:06:26.567+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.432 seconds
[2023-10-26T22:06:57.280+0800] {processor.py:157} INFO - Started process (PID=1469) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:06:57.291+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:06:57.293+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:06:57.292+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:06:57.688+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:06:57.686+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:06:57.689+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:06:57.727+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.456 seconds
[2023-10-26T22:07:27.932+0800] {processor.py:157} INFO - Started process (PID=1498) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:07:27.938+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:07:27.940+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:07:27.939+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:07:28.330+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:07:28.329+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:07:28.330+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:07:28.341+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.418 seconds
[2023-10-26T22:07:58.616+0800] {processor.py:157} INFO - Started process (PID=1527) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:07:58.623+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:07:58.640+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:07:58.639+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:07:59.033+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:07:59.032+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:07:59.033+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:07:59.047+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.445 seconds
[2023-10-26T22:08:29.406+0800] {processor.py:157} INFO - Started process (PID=1556) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:08:29.411+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:08:29.413+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:08:29.412+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:08:29.867+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:08:29.866+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:08:29.867+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:08:29.886+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.487 seconds
[2023-10-26T22:09:00.369+0800] {processor.py:157} INFO - Started process (PID=1585) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:09:00.412+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:09:00.413+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:09:00.413+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:09:00.818+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:09:00.817+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:09:00.819+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:09:00.832+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.471 seconds
[2023-10-26T22:09:31.447+0800] {processor.py:157} INFO - Started process (PID=1614) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:09:31.451+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:09:31.455+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:09:31.455+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:09:31.771+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:09:31.770+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:09:31.772+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:09:31.783+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.342 seconds
[2023-10-26T22:10:01.916+0800] {processor.py:157} INFO - Started process (PID=1643) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:10:01.929+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:10:01.930+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:10:01.929+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:10:02.216+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:10:02.215+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:10:02.216+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:10:02.227+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.318 seconds
[2023-10-26T22:10:32.500+0800] {processor.py:157} INFO - Started process (PID=1673) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:10:32.506+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:10:32.509+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:10:32.509+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:10:32.875+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:10:32.874+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:10:32.876+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:10:32.886+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.393 seconds
[2023-10-26T22:11:03.353+0800] {processor.py:157} INFO - Started process (PID=1702) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:11:03.359+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:11:03.360+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:11:03.359+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:11:03.721+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:11:03.719+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:11:03.721+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:11:03.736+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.389 seconds
[2023-10-26T22:11:33.981+0800] {processor.py:157} INFO - Started process (PID=1731) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:11:33.985+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:11:33.990+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:11:33.989+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:11:34.406+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:11:34.405+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:11:34.416+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:11:34.444+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.469 seconds
[2023-10-26T22:12:04.656+0800] {processor.py:157} INFO - Started process (PID=1760) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:12:04.690+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:12:04.705+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:12:04.705+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:12:05.097+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:12:05.096+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:12:05.097+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:12:05.108+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.457 seconds
[2023-10-26T22:12:35.350+0800] {processor.py:157} INFO - Started process (PID=1789) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:12:35.355+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:12:35.357+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:12:35.357+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:12:35.735+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:12:35.733+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:12:35.735+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:12:35.752+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.426 seconds
[2023-10-26T22:13:05.868+0800] {processor.py:157} INFO - Started process (PID=1818) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:13:05.872+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:13:05.873+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:13:05.872+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:13:06.267+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:13:06.265+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:13:06.268+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:13:06.282+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.420 seconds
[2023-10-26T22:13:36.563+0800] {processor.py:157} INFO - Started process (PID=1847) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:13:36.567+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:13:36.568+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:13:36.567+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:13:36.939+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:13:36.935+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:13:36.940+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:13:36.955+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.400 seconds
[2023-10-26T22:14:07.616+0800] {processor.py:157} INFO - Started process (PID=1876) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:14:07.638+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:14:07.639+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:14:07.638+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:14:08.010+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:14:08.009+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:14:08.011+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:14:08.023+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.415 seconds
[2023-10-26T22:14:38.403+0800] {processor.py:157} INFO - Started process (PID=1904) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:14:38.410+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:14:38.415+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:14:38.415+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:14:38.829+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:14:38.828+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:14:38.830+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:14:38.844+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.448 seconds
[2023-10-26T22:15:09.355+0800] {processor.py:157} INFO - Started process (PID=1933) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:15:09.363+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:15:09.367+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:15:09.366+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:15:09.702+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:15:09.701+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:15:09.703+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:15:09.712+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.364 seconds
[2023-10-26T22:15:40.270+0800] {processor.py:157} INFO - Started process (PID=1961) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:15:40.278+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:15:40.281+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:15:40.281+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:15:40.631+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:15:40.629+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:15:40.631+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:15:40.644+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.381 seconds
[2023-10-26T22:16:10.790+0800] {processor.py:157} INFO - Started process (PID=1990) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:16:10.798+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:16:10.811+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:16:10.811+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:16:11.172+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:16:11.170+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:16:11.172+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:16:11.184+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.398 seconds
[2023-10-26T22:16:41.462+0800] {processor.py:157} INFO - Started process (PID=2020) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:16:41.473+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:16:41.485+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:16:41.485+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:16:41.852+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:16:41.851+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:16:41.852+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:16:41.862+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.408 seconds
[2023-10-26T22:17:12.517+0800] {processor.py:157} INFO - Started process (PID=2049) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:17:12.528+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:17:12.533+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:17:12.532+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:17:12.918+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:17:12.916+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:17:12.918+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:17:12.935+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.426 seconds
[2023-10-26T22:17:43.668+0800] {processor.py:157} INFO - Started process (PID=2078) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:17:43.681+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:17:43.682+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:17:43.681+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:17:44.110+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:17:44.109+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:17:44.111+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:17:44.122+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.459 seconds
[2023-10-26T22:18:14.922+0800] {processor.py:157} INFO - Started process (PID=2114) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:18:14.954+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:18:14.970+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:18:14.970+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:18:15.378+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:18:15.377+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:18:15.379+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:18:15.389+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.474 seconds
[2023-10-26T22:18:46.043+0800] {processor.py:157} INFO - Started process (PID=2143) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:18:46.048+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:18:46.049+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:18:46.048+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:18:46.445+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:18:46.444+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:18:46.445+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:18:46.462+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.424 seconds
[2023-10-26T22:19:16.860+0800] {processor.py:157} INFO - Started process (PID=2171) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:19:16.866+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:19:16.867+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:19:16.866+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:19:17.261+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:19:17.260+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:19:17.261+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:19:17.283+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.428 seconds
[2023-10-26T22:19:47.977+0800] {processor.py:157} INFO - Started process (PID=2200) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:19:47.985+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:19:47.986+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:19:47.985+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:19:48.367+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:19:48.366+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:19:48.368+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:19:48.389+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.437 seconds
[2023-10-26T22:20:18.970+0800] {processor.py:157} INFO - Started process (PID=2229) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:20:18.982+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:20:18.996+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:20:18.996+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:20:19.376+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:20:19.375+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:20:19.377+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:20:19.408+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.451 seconds
[2023-10-26T22:20:50.256+0800] {processor.py:157} INFO - Started process (PID=2258) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:20:50.272+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:20:50.305+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:20:50.305+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:20:50.719+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:20:50.717+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:20:50.719+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:20:50.739+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.500 seconds
[2023-10-26T22:21:21.450+0800] {processor.py:157} INFO - Started process (PID=2287) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:21:21.464+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:21:21.465+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:21:21.464+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:21:21.811+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:21:21.810+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:21:21.811+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:21:21.821+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.377 seconds
[2023-10-26T22:21:52.276+0800] {processor.py:157} INFO - Started process (PID=2316) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:21:52.290+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:21:52.305+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:21:52.305+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:21:52.651+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:21:52.650+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:21:52.651+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:21:52.662+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.391 seconds
[2023-10-26T22:22:22.861+0800] {processor.py:157} INFO - Started process (PID=2345) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:22:22.866+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:22:22.870+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:22:22.869+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:22:23.419+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:22:23.417+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:22:23.420+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:22:23.455+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.600 seconds
[2023-10-26T22:22:54.031+0800] {processor.py:157} INFO - Started process (PID=2373) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:22:54.045+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:22:54.060+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:22:54.059+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:22:54.515+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:22:54.513+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:22:54.515+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:22:54.528+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.503 seconds
[2023-10-26T22:23:25.248+0800] {processor.py:157} INFO - Started process (PID=2401) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:23:25.262+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:23:25.263+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:23:25.263+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:23:25.720+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:23:25.718+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:23:25.721+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:23:25.753+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.518 seconds
[2023-10-26T22:23:56.445+0800] {processor.py:157} INFO - Started process (PID=2430) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:23:56.479+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:23:56.498+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:23:56.498+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:23:56.895+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:23:56.893+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:23:56.895+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:23:56.916+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.478 seconds
[2023-10-26T22:24:27.542+0800] {processor.py:157} INFO - Started process (PID=2459) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:24:27.546+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:24:27.548+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:24:27.547+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:24:27.958+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:24:27.956+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:24:27.958+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:24:27.971+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.437 seconds
[2023-10-26T22:24:58.473+0800] {processor.py:157} INFO - Started process (PID=2488) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:24:58.478+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:24:58.479+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:24:58.479+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:24:58.898+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:24:58.897+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:24:58.899+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:24:58.914+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.448 seconds
[2023-10-26T22:25:29.550+0800] {processor.py:157} INFO - Started process (PID=2516) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:25:29.554+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:25:29.556+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:25:29.555+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:25:29.967+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:25:29.966+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:25:29.967+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:25:29.977+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.433 seconds
[2023-10-26T22:26:00.500+0800] {processor.py:157} INFO - Started process (PID=2545) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:26:00.513+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:26:00.516+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:26:00.516+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:26:00.877+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:26:00.876+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:26:00.878+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:26:00.890+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.395 seconds
[2023-10-26T22:26:31.450+0800] {processor.py:157} INFO - Started process (PID=2574) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:26:31.466+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:26:31.467+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:26:31.467+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:26:31.861+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:26:31.860+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:26:31.861+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:26:31.873+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.431 seconds
[2023-10-26T22:27:02.451+0800] {processor.py:157} INFO - Started process (PID=2603) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:27:02.468+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:27:02.469+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:27:02.468+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:27:02.856+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:27:02.855+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:27:02.857+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:27:02.868+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.424 seconds
[2023-10-26T22:27:33.465+0800] {processor.py:157} INFO - Started process (PID=2632) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:27:33.483+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:27:33.488+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:27:33.487+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:27:33.933+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:27:33.932+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:27:33.933+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:27:33.946+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.497 seconds
[2023-10-26T22:28:04.422+0800] {processor.py:157} INFO - Started process (PID=2660) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:28:04.426+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:28:04.427+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:28:04.426+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:28:04.754+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:28:04.753+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:28:04.754+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:28:04.766+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.348 seconds
[2023-10-26T22:28:35.236+0800] {processor.py:157} INFO - Started process (PID=2690) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:28:35.250+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:28:35.253+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:28:35.253+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:28:35.610+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:28:35.609+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:28:35.610+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:28:35.620+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.390 seconds
[2023-10-26T22:29:06.045+0800] {processor.py:157} INFO - Started process (PID=2719) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:29:06.059+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:29:06.063+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:29:06.062+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:29:06.422+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:29:06.421+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:29:06.422+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:29:06.433+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.392 seconds
[2023-10-26T22:29:36.945+0800] {processor.py:157} INFO - Started process (PID=2749) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:29:36.950+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:29:36.952+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:29:36.951+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:29:37.298+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:29:37.297+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:29:37.298+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:29:37.308+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.369 seconds
[2023-10-26T22:30:07.747+0800] {processor.py:157} INFO - Started process (PID=2778) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:30:07.752+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:30:07.753+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:30:07.753+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:30:08.116+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:30:08.115+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:30:08.117+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:30:08.127+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.386 seconds
[2023-10-26T22:30:38.637+0800] {processor.py:157} INFO - Started process (PID=2807) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:30:38.641+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:30:38.646+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:30:38.646+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:30:39.006+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:30:39.005+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:30:39.006+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:30:39.019+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.389 seconds
[2023-10-26T22:31:09.456+0800] {processor.py:157} INFO - Started process (PID=2836) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:31:09.467+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:31:09.469+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:31:09.468+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:31:09.828+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:31:09.826+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:31:09.828+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:31:09.851+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.400 seconds
[2023-10-26T22:31:40.521+0800] {processor.py:157} INFO - Started process (PID=2865) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:31:40.531+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:31:40.534+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:31:40.533+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:31:40.924+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:31:40.923+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:31:40.924+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:31:40.934+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.418 seconds
[2023-10-26T22:32:11.354+0800] {processor.py:157} INFO - Started process (PID=2894) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:32:11.358+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:32:11.359+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:32:11.359+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:32:11.682+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:32:11.681+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:32:11.682+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:32:11.691+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.342 seconds
[2023-10-26T22:32:42.168+0800] {processor.py:157} INFO - Started process (PID=2923) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:32:42.180+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:32:42.181+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:32:42.180+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:32:42.442+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:32:42.441+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:32:42.442+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:32:42.450+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.288 seconds
[2023-10-26T22:33:12.815+0800] {processor.py:157} INFO - Started process (PID=2952) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:33:12.827+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:33:12.829+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:33:12.828+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:33:13.113+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:33:13.112+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:33:13.113+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:33:13.124+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.314 seconds
[2023-10-26T22:33:43.615+0800] {processor.py:157} INFO - Started process (PID=2982) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:33:43.626+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:33:43.630+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:33:43.628+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:33:43.981+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:33:43.980+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:33:43.981+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:33:43.990+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.378 seconds
[2023-10-26T22:34:14.410+0800] {processor.py:157} INFO - Started process (PID=3011) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:34:14.421+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:34:14.422+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:34:14.422+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:34:14.851+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:34:14.851+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:34:14.852+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:34:14.860+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.453 seconds
[2023-10-26T22:34:45.248+0800] {processor.py:157} INFO - Started process (PID=3040) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:34:45.254+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:34:45.255+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:34:45.255+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:34:45.865+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:34:45.863+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:34:45.867+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:34:45.964+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.719 seconds
[2023-10-26T22:35:16.542+0800] {processor.py:157} INFO - Started process (PID=3079) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:35:16.548+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:35:16.549+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:35:16.548+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:35:17.051+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:35:17.050+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:35:17.052+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:35:17.065+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.525 seconds
[2023-10-26T22:35:47.742+0800] {processor.py:157} INFO - Started process (PID=3108) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:35:47.758+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:35:47.759+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:35:47.759+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:35:48.185+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:35:48.183+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:35:48.185+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:35:48.196+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.459 seconds
[2023-10-26T22:36:18.785+0800] {processor.py:157} INFO - Started process (PID=3144) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:36:18.796+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:36:18.797+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:36:18.797+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:36:19.218+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:36:19.216+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:36:19.218+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:36:19.229+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.449 seconds
[2023-10-26T22:36:49.367+0800] {processor.py:157} INFO - Started process (PID=3173) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:36:49.379+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:36:49.380+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:36:49.380+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:36:49.787+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:36:49.786+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:36:49.788+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:36:49.797+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.435 seconds
[2023-10-26T22:37:19.919+0800] {processor.py:157} INFO - Started process (PID=3202) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:37:19.929+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:37:19.929+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:37:19.929+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:37:20.344+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:37:20.343+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:37:20.345+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:37:20.357+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.442 seconds
[2023-10-26T22:37:50.452+0800] {processor.py:157} INFO - Started process (PID=3231) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:37:50.462+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:37:50.463+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:37:50.463+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:37:50.879+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:37:50.877+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:37:50.879+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:37:50.890+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.443 seconds
[2023-10-26T22:38:21.120+0800] {processor.py:157} INFO - Started process (PID=3260) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:38:21.125+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:38:21.127+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:38:21.126+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:38:21.519+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:38:21.517+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:38:21.519+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:38:21.530+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.416 seconds
[2023-10-26T22:38:51.691+0800] {processor.py:157} INFO - Started process (PID=3289) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:38:51.703+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:38:51.705+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:38:51.704+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:38:52.104+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:38:52.102+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:38:52.104+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:38:52.129+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.443 seconds
[2023-10-26T22:39:22.296+0800] {processor.py:157} INFO - Started process (PID=3318) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:39:22.307+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:39:22.308+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:39:22.308+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:39:22.738+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:39:22.737+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:39:22.739+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:39:22.755+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.463 seconds
[2023-10-26T22:39:52.832+0800] {processor.py:157} INFO - Started process (PID=3347) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:39:52.845+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:39:52.846+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:39:52.846+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:39:53.257+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:39:53.253+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:39:53.258+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:39:53.275+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.449 seconds
[2023-10-26T22:40:23.496+0800] {processor.py:157} INFO - Started process (PID=3375) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:40:23.513+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:40:23.514+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:40:23.513+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:40:23.913+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:40:23.911+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:40:23.913+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:40:23.927+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.436 seconds
[2023-10-26T22:40:54.070+0800] {processor.py:157} INFO - Started process (PID=3404) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:40:54.090+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:40:54.090+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:40:54.090+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:40:54.480+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:40:54.479+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:40:54.481+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:40:54.495+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.430 seconds
[2023-10-26T22:41:24.559+0800] {processor.py:157} INFO - Started process (PID=3433) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:41:24.571+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:41:24.572+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:41:24.572+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:41:24.964+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:41:24.962+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:41:24.964+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:41:24.977+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.424 seconds
[2023-10-26T22:41:55.080+0800] {processor.py:157} INFO - Started process (PID=3462) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:41:55.089+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:41:55.089+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:41:55.089+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:41:55.469+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:41:55.468+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:41:55.470+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:41:55.478+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.403 seconds
[2023-10-26T22:42:26.206+0800] {processor.py:157} INFO - Started process (PID=3491) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:42:26.213+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:42:26.214+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:42:26.213+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:42:26.650+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:42:26.649+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:42:26.651+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:42:26.673+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.472 seconds
[2023-10-26T22:42:56.728+0800] {processor.py:157} INFO - Started process (PID=3519) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:42:56.737+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:42:56.737+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:42:56.737+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:42:57.088+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:42:57.087+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:42:57.088+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:42:57.100+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.377 seconds
[2023-10-26T22:43:27.193+0800] {processor.py:157} INFO - Started process (PID=3548) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:43:27.198+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:43:27.199+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:43:27.198+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:43:27.556+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:43:27.555+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:43:27.557+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:43:27.565+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.377 seconds
[2023-10-26T22:43:57.991+0800] {processor.py:157} INFO - Started process (PID=3577) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:43:57.997+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:43:57.998+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:43:57.998+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:43:58.381+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:43:58.380+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:43:58.381+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:43:58.395+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.409 seconds
[2023-10-26T22:44:28.575+0800] {processor.py:157} INFO - Started process (PID=3605) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:44:28.581+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:44:28.583+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:44:28.582+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:44:28.985+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:44:28.984+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:44:28.985+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:44:28.997+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.431 seconds
[2023-10-26T22:44:59.211+0800] {processor.py:157} INFO - Started process (PID=3634) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:44:59.217+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:44:59.219+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:44:59.218+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:44:59.618+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:44:59.617+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:44:59.618+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:44:59.630+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.425 seconds
[2023-10-26T22:45:29.849+0800] {processor.py:157} INFO - Started process (PID=3663) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:45:29.859+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:45:29.860+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:45:29.859+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:45:30.245+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:45:30.244+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:45:30.246+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:45:30.260+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.416 seconds
[2023-10-26T22:46:00.485+0800] {processor.py:157} INFO - Started process (PID=3692) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:46:00.492+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:46:00.493+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:46:00.492+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:46:00.885+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:46:00.884+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:46:00.886+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:46:00.899+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.421 seconds
[2023-10-26T22:46:31.147+0800] {processor.py:157} INFO - Started process (PID=3721) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:46:31.156+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:46:31.157+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:46:31.157+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:46:31.561+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:46:31.560+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:46:31.562+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:46:31.578+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.437 seconds
[2023-10-26T22:47:01.790+0800] {processor.py:157} INFO - Started process (PID=3750) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:47:01.801+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:47:01.802+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:47:01.802+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:47:02.215+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:47:02.213+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:47:02.216+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:47:02.233+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.447 seconds
[2023-10-26T22:47:32.297+0800] {processor.py:157} INFO - Started process (PID=3779) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:47:32.308+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:47:32.309+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:47:32.308+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:47:32.707+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:47:32.705+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:47:32.707+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:47:32.724+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.431 seconds
[2023-10-26T22:48:02.983+0800] {processor.py:157} INFO - Started process (PID=3807) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:48:02.994+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:48:02.995+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:48:02.994+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:48:03.404+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:48:03.403+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:48:03.405+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:48:03.419+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.441 seconds
[2023-10-26T22:48:33.687+0800] {processor.py:157} INFO - Started process (PID=3836) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:48:33.702+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:48:33.703+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:48:33.702+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:48:34.105+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:48:34.103+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:48:34.105+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:48:34.119+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.437 seconds
[2023-10-26T22:49:04.452+0800] {processor.py:157} INFO - Started process (PID=3865) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:49:04.458+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:49:04.461+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:49:04.459+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:49:04.864+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:49:04.862+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:49:04.864+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:49:04.897+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.450 seconds
[2023-10-26T22:49:35.563+0800] {processor.py:157} INFO - Started process (PID=3894) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:49:35.569+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:49:35.570+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:49:35.569+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:49:35.943+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:49:35.942+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:49:35.943+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:49:35.954+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.397 seconds
[2023-10-26T22:50:06.065+0800] {processor.py:157} INFO - Started process (PID=3923) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:50:06.070+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:50:06.071+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:50:06.071+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:50:06.409+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:50:06.408+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:50:06.409+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:50:06.423+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.364 seconds
[2023-10-26T22:50:36.541+0800] {processor.py:157} INFO - Started process (PID=3952) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:50:36.551+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:50:36.552+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:50:36.552+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:50:36.777+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:50:36.776+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:50:36.778+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:50:36.788+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.252 seconds
[2023-10-26T22:51:06.965+0800] {processor.py:157} INFO - Started process (PID=3981) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:51:06.971+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:51:06.971+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:51:06.971+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:51:07.190+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:51:07.189+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:51:07.190+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:51:07.200+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.238 seconds
[2023-10-26T22:51:37.458+0800] {processor.py:157} INFO - Started process (PID=4010) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:51:37.464+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:51:37.465+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:51:37.465+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:51:37.743+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:51:37.742+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:51:37.744+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:51:37.754+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.300 seconds
[2023-10-26T22:52:07.909+0800] {processor.py:157} INFO - Started process (PID=4039) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:52:07.918+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:52:07.919+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:52:07.919+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:52:08.160+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:52:08.159+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:52:08.161+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:52:08.172+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.267 seconds
[2023-10-26T22:52:38.419+0800] {processor.py:157} INFO - Started process (PID=4068) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:52:38.426+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:52:38.427+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:52:38.427+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:52:38.651+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:52:38.650+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:52:38.651+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:52:38.661+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.245 seconds
[2023-10-26T22:53:08.841+0800] {processor.py:157} INFO - Started process (PID=4097) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:53:08.853+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:53:08.854+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:53:08.854+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:53:09.133+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:53:09.132+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:53:09.133+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:53:09.141+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.305 seconds
[2023-10-26T22:53:39.296+0800] {processor.py:157} INFO - Started process (PID=4126) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:53:39.304+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:53:39.305+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:53:39.305+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:53:39.555+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:53:39.554+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:53:39.556+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:53:39.566+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.273 seconds
[2023-10-26T22:54:09.667+0800] {processor.py:157} INFO - Started process (PID=4155) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:54:09.679+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:54:09.680+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:54:09.679+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:54:10.018+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:54:10.017+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:54:10.019+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:54:10.030+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.367 seconds
[2023-10-26T22:54:40.128+0800] {processor.py:157} INFO - Started process (PID=4184) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:54:40.134+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:54:40.135+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:54:40.134+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:54:40.405+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:54:40.404+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:54:40.405+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:54:40.415+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.292 seconds
[2023-10-26T22:55:10.582+0800] {processor.py:157} INFO - Started process (PID=4213) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:55:10.589+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:55:10.590+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:55:10.589+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:55:10.878+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:55:10.877+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:55:10.878+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:55:10.888+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.311 seconds
[2023-10-26T22:55:41.123+0800] {processor.py:157} INFO - Started process (PID=4242) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:55:41.131+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:55:41.132+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:55:41.131+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:55:41.477+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:55:41.476+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:55:41.478+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:55:41.487+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.370 seconds
[2023-10-26T22:56:11.577+0800] {processor.py:157} INFO - Started process (PID=4271) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:56:11.584+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:56:11.585+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:56:11.585+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:56:11.859+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:56:11.858+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:56:11.860+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:56:11.868+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.298 seconds
[2023-10-26T22:56:42.192+0800] {processor.py:157} INFO - Started process (PID=4300) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:56:42.198+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:56:42.198+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:56:42.198+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:56:42.570+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:56:42.569+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:56:42.571+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:56:42.581+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.392 seconds
[2023-10-26T22:57:12.637+0800] {processor.py:157} INFO - Started process (PID=4329) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:57:12.645+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:57:12.646+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:57:12.646+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:57:13.071+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:57:13.069+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:57:13.072+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:57:13.105+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.470 seconds
[2023-10-26T22:57:43.345+0800] {processor.py:157} INFO - Started process (PID=4358) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:57:43.353+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:57:43.354+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:57:43.354+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:57:43.675+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:57:43.673+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:57:43.675+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:57:43.687+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.346 seconds
[2023-10-26T22:58:13.815+0800] {processor.py:157} INFO - Started process (PID=4387) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:58:13.822+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:58:13.823+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:58:13.822+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:58:14.202+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:58:14.201+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:58:14.203+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:58:14.215+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.405 seconds
[2023-10-26T22:58:44.350+0800] {processor.py:157} INFO - Started process (PID=4417) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:58:44.358+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:58:44.359+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:58:44.358+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:58:44.746+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:58:44.744+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:58:44.747+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:58:44.758+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.415 seconds
[2023-10-26T22:59:14.986+0800] {processor.py:157} INFO - Started process (PID=4446) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:59:14.995+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:59:15.008+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:59:15.007+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:59:15.409+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:59:15.408+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:59:15.409+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:59:15.418+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.442 seconds
[2023-10-26T22:59:46.160+0800] {processor.py:157} INFO - Started process (PID=4475) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:59:46.167+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T22:59:46.172+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:59:46.172+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:59:46.646+0800] {logging_mixin.py:151} INFO - [2023-10-26T22:59:46.645+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T22:59:46.646+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T22:59:46.676+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.525 seconds
[2023-10-26T23:15:51.710+0800] {processor.py:157} INFO - Started process (PID=4489) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T23:15:51.716+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-26T23:15:51.717+0800] {logging_mixin.py:151} INFO - [2023-10-26T23:15:51.716+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T23:15:52.895+0800] {logging_mixin.py:151} INFO - [2023-10-26T23:15:52.870+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-26T23:15:52.896+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-26T23:15:53.037+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.344 seconds
[2023-10-27T00:01:45.150+0800] {processor.py:157} INFO - Started process (PID=4519) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-27T00:01:45.180+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-27T00:01:45.181+0800] {logging_mixin.py:151} INFO - [2023-10-27T00:01:45.181+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-27T00:01:46.710+0800] {logging_mixin.py:151} INFO - [2023-10-27T00:01:46.706+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-27T00:01:46.712+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-27T00:01:46.748+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.604 seconds
[2023-10-27T00:05:24.048+0800] {processor.py:157} INFO - Started process (PID=4549) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-27T00:05:24.051+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-27T00:05:24.053+0800] {logging_mixin.py:151} INFO - [2023-10-27T00:05:24.052+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-27T00:05:25.667+0800] {logging_mixin.py:151} INFO - [2023-10-27T00:05:25.650+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-27T00:05:25.669+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-27T00:05:25.717+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.679 seconds
[2023-10-27T01:29:16.812+0800] {processor.py:157} INFO - Started process (PID=4578) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-27T01:29:16.816+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-27T01:29:16.820+0800] {logging_mixin.py:151} INFO - [2023-10-27T01:29:16.818+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-27T01:29:18.425+0800] {logging_mixin.py:151} INFO - [2023-10-27T01:29:18.422+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-27T01:29:18.427+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-27T01:29:18.460+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.659 seconds
[2023-10-27T02:52:53.371+0800] {processor.py:157} INFO - Started process (PID=4611) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-27T02:52:53.391+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-27T02:52:53.398+0800] {logging_mixin.py:151} INFO - [2023-10-27T02:52:53.394+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-27T02:52:54.242+0800] {logging_mixin.py:151} INFO - [2023-10-27T02:52:54.241+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-27T02:52:54.243+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-27T02:52:54.268+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.947 seconds
[2023-10-27T04:33:54.372+0800] {processor.py:157} INFO - Started process (PID=4640) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-27T04:33:54.382+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-27T04:33:54.387+0800] {logging_mixin.py:151} INFO - [2023-10-27T04:33:54.387+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-27T04:33:55.843+0800] {logging_mixin.py:151} INFO - [2023-10-27T04:33:55.837+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-27T04:33:55.844+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-27T04:33:55.868+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.500 seconds
[2023-10-27T05:47:41.114+0800] {processor.py:157} INFO - Started process (PID=4669) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-27T05:47:41.122+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-27T05:47:41.129+0800] {logging_mixin.py:151} INFO - [2023-10-27T05:47:41.128+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-27T05:47:42.306+0800] {logging_mixin.py:151} INFO - [2023-10-27T05:47:42.304+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-27T05:47:42.307+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-27T05:47:42.331+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 1.241 seconds
[2023-10-27T06:19:00.061+0800] {processor.py:157} INFO - Started process (PID=4700) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-27T06:19:00.068+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-27T06:19:00.075+0800] {logging_mixin.py:151} INFO - [2023-10-27T06:19:00.070+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-27T06:19:02.009+0800] {logging_mixin.py:151} INFO - [2023-10-27T06:19:01.988+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-27T06:19:02.013+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-27T06:19:02.091+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 2.052 seconds
[2023-10-27T07:14:48.640+0800] {processor.py:157} INFO - Started process (PID=4732) to work on /opt/airflow/dags/stock_data_crawler.py
[2023-10-27T07:14:48.681+0800] {processor.py:829} INFO - Processing file /opt/airflow/dags/stock_data_crawler.py for tasks to queue
[2023-10-27T07:14:48.698+0800] {logging_mixin.py:151} INFO - [2023-10-27T07:14:48.697+0800] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_crawler.py
[2023-10-27T07:14:49.533+0800] {logging_mixin.py:151} INFO - [2023-10-27T07:14:49.530+0800] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/stock_data_crawler.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_crawler.py", line 9, in <module>
    from airflow_folder.src.crawler.stock_crawler import crawler_twse
ModuleNotFoundError: No module named 'airflow_folder'
[2023-10-27T07:14:49.533+0800] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_crawler.py
[2023-10-27T07:14:49.550+0800] {processor.py:179} INFO - Processing /opt/airflow/dags/stock_data_crawler.py took 0.992 seconds
